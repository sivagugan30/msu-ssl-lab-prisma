# A two-case study of coarticulation in stuttered speech. An articulatory approach

```
Clinical Linguistics & Phonetics

ISSN: 0269-9206 (Print) 1464-5076 (Online) Journal homepage: www.tandfonline.com/journals/iclp20

A two-case study of coarticulation in stuttered
speech. An articulatory approach

Ivana Didirková & Fabrice Hirsch

To cite this article: Ivana Didirková & Fabrice Hirsch (2020) A two-case study of coarticulation
in stuttered speech. An articulatory approach, Clinical Linguistics & Phonetics, 34:6, 517-535,
DOI: 10.1080/02699206.2019.1660913

To link to this article:  https://doi.org/10.1080/02699206.2019.1660913

Published online: 03 Sep 2019.

Submit your article to this journal 

Article views: 611

View related articles 

View Crossmark data

Citing articles: 6 View citing articles 

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=iclp20

CLINICAL LINGUISTICS & PHONETICS
2020, VOL. 34, NO. 6, 517–535
https://doi.org/10.1080/02699206.2019.1660913

A two-case study of coarticulation in stuttered speech. An
articulatory approach

Ivana Didirková

a,b and Fabrice Hirsch c

aEA 1569 TransCrit, Université Paris 8, Saint-Denis, France; bUMR 7018 Laboratoire de Phonétique et
Phonologie, CNRS, Université Sorbonne Nouvelle, Paris, France; cUniversité Paul-Valéry Montpellier 3, UMR
5267 Praxiling, CNRS, Montpellier, France

ARTICLE HISTORY
Received 16 May 2019
Revised 23 August 2019
Accepted 24 August 2019

KEYWORDS
Stuttering; coarticulation;
electromagnetic
articulography; adults who
stutter

ABSTRACT
This study aims to describe the coarticulatory behaviour in stuttered
speech from an articulatory point of view. Its purpose is to assess the
nature of transitions between a stuttered phone and preceding and
subsequent phones. Two persons who stutter were recorded by
means of an electromagnetic articulograph while reading a text.
The vertical movements of upper and lower lips, tongue body, ton-
gue tip and mandible were extracted. They were then analysed
during a stuttering moment and linked to the acoustic type of dis-
ﬂuency. Our ﬁndings showed several conﬁgurations of coarticulatory
behaviour in terms of supraglottic articulatory movements. While
disﬂuencies can be the result of a disrupted coarticulatory conﬁgura-
tion, no systematicity has been found. Moreover, all acoustic types of
disﬂuencies are represented in several coarticulatory conﬁgurations.
Therefore, a stuttering-like disﬂuency is not always due to
a coarticulatory disturbance, since correct coarticulatory patterns
can be observed both between the disﬂuent sound and its previous
and subsequent sounds. Furthermore, they suggest that the acoustic
classiﬁcation of disﬂuencies does not seem important for the coarti-
culatory behaviour.

Introduction

A brief history of studies dealing with coarticulation in people who stutter

Coarticulation can be deﬁned as the way one organises sequences of successive sounds in
speech. Indeed, speech production is not a simple succession of phonemes carried out one
after another: overlaps are necessary to carry out a sound sequence. Thus, gestures
inherent to each phoneme are inﬂuenced by gestures required for the production of the
preceding and following sounds. In other words, coarticulation consists of an interweaving
between diﬀerent articulatory gestures associated with diﬀerent sounds (Hardcastle &
Hewlett, 2006). For instance, when the consonant [t] is produced in isolation, no lip
protrusion is observed. Nevertheless, in the sequence [tu], the lips are generally rounded
before the beginning of the [t] and during the realisation of the stop consonant, showing
that speech depends on very precise articulatory timing where gestures proper to a sound
can start during the production of the previous phoneme or phonemes. In the literature,

CONTACT Ivana Didirková
TransCrit, Université Paris 8 Vincennes Saint-Denis, 2 rue de la Liberté, Saint-Denis 93526, France
Color versions of one or more of the ﬁgures in the article can be found online at www.tandfonline.com/iclp.
© 2019 Taylor & Francis Group, LLC

ivana.didirkova@univ-paris8.fr

Département d’études des pays anglophones, EA 1569

518

I. DIDIRKOVÁ AND F. HIRSCH

several researchers hypothesise that stuttering is due to a coarticulation alteration, but no
real consensus has been found. For instance, Wingate (1977) already considered stuttering
as a transition failure when he wrote that “whether we observe a repetition or prolonga-
tion, the diﬃculty is typically not manifested in the articulatory postures essential to that
sound, but instead in moving on the succeeding one”. In other words, he claimed that
disﬂuencies take place in the transition between two phonemes.

Some years later, Van Riper (1982) claimed that stuttering-like disﬂuencies (henceforth
SLDs) are due to coarticulation diﬃculties, and disﬂuent syllables are not produced in the
same way as ﬂuent ones. Other researches aimed to verify Wingate’s (1977) and Van
Riper’s (1982) assertions. Harrington (1987) used electropalatographic and acoustic data
to analyse coarticulation in disﬂuent speech. He did not observe the production of a schwa
during disﬂuencies, but according to his study, three coarticulatory conﬁgurations would
be present during disﬂuent speech:

● the acoustic beginning of the vowel in [CV] syllables is present, but the second

formant does not reach frequency values to correctly pronounce [V];

● the emergence of the vowel is stopped and F2 values are identical to those observed

for the consonant;

● in the case of repetitions, frequency values head for those that are necessary to repeat

the consonant.

Howell, Williams, and Vause (1987) conﬁrm Harrington’s ﬁndings by analysing F2 transitions
during pathological repetitions. They observe that disﬂuent vowels can be perceived as
a schwa because of the shorter duration of transitions. Yaruss and Conture (1993) also notice
a reduction of the transition duration in speech produced by people who stutter (PWS).

More recently, other researchers were interested in coarticulation in PWS. For instance,
the locus equation has been used to compare perceptually ﬂuent speech produced by PWS
and control speakers in diﬀerent languages (Dehqan, Yadegari, Blomgren, & Scherer,
2016; Frisch, Maxﬁeld, & Belmont, 2016; Hirsch, 2007; Maruthy, Feng, & Max, 2017;
Pendeliau-Verdurand, 2014; Robb & Blomgren, 1997; Zmarich, Balbo, Galata, Verdurand,
& Rossato, 2013). However, conclusions reached by these studies are not always identical.
Robb and Blomgren (1997) and Pendeliau-Verdurand (2014) found a weaker coarticula-
tion in perceptually ﬂuent speech in PWS in English, French and Italian. Furthermore,
Pendeliau-Verdurand (2014) shows that phonological complexity has an impact on
coarticulation behaviour in PWS. The other studies, on the contrary, failed to show any
diﬀerence between the two groups in other languages. Moreover, these studies, in addition
to being contradictory, seem to present a bias in that they are based on the locus equation.
Yet, the origins of the slope observed within this measure still remain unknown (Iskarous,
Fowler, & Whalen, 2010). For example, Löfqvist (1999) ﬁnds no support for the slope
being an index of the degree of coarticulation in a [CV] sequence, while Tabain (2000)
nuances this claim. Indeed, for Tabain (2000) the locus equation seems to provide
accurate information on the degree of coarticulation for stops, but not for fricatives. In
other studies, it is assumed that the locus equation indicates the degree of coarticulation
resistance (Bang, 2017). For this reason, diﬀerent acquisition techniques have been

CLINICAL LINGUISTICS & PHONETICS

519

proposed for coarticulation studies, such as palatography, MRI, X-ray, computed tomo-
graphy, electromyography and others (for a detailed review of imaging techniques, see
Hardcastle & Hewlett, 2006).

Using ultrasound, Belmont (2015) and Frisch et al. (2016) observed an articulatory
stability decrease in velar-vowel sequences embedded in a carrier phrase. Frisch et al.
(2016) claimed that articulatory maturation in young adults who stutter does not
generally diﬀer from typical young adults, except that some young adults who stutter
could be seen as having a less stable activation of articulatory subsystems. In other
words, there were no diﬀerences between the coarticulation in front versus non-front
velar-vowel contexts in PWS and in controls, which led Frisch et al. (2016) to exclude
the hypothesis of immature motor planning measured by anticipatory coarticulation
(Zharkova, Hewlett, & Hardcastle, 2011). On the other hand, the ﬁndings related to
a lack of stability could be, for the authors, consistent with the model of Max, Guenther,
Gracco, Ghosh, and Wallace (2004).

In 2004, Van Lieshout, Hulstijn, and Peters proposed an extensive review of literature
on speech motor skills in PWS. This review indicates that PWS would have limitations in
their speech motor skills, such as the ability to make use of proprioceptive information or
to respond to a speech rate modiﬁcation. However, the authors also underline the fact that
speech motor performance should be considered as a continuum where PWS and people
who do not stutter (PWNS) could sometimes be fairly close to each other, leaving the
question relatively open.

Thus the question is: can we, together with Van Lieshout, Hulstijn, and Peters (2004),
conclude this ﬁrst part by assuming that stuttering is the consequence of an innate
limitation in the speech motor control system which is momentarily not able to prepare
and organise the movements required for speech? In this perspective, disﬂuencies could be
considered as a disruption of the precisely timed and coordinated articulatory movements
required for ﬂuent speech.

Purpose and hypothesis

The aim of this work was to pursue studies dealing with coarticulation in speech produced
by PWS by using physiological data. More precisely, this research used data obtained by
means of an Electromagnetic Articulograph (EMA) to analyse articulatory transitions
during SLDs.

Several studies have been carried out on coarticulation and stuttering. Most are based
on perceptually ﬂuent speech produced by PWS; however, knowledge of what happens
during transition phases in SLDs is insuﬃcient, and sometimes contradictory.

The lack of consensus in the literature could be due to the diﬃculty for an acoustic
study to detect all types and degrees of coarticulation failure. In fact, numerous patterns of
coarticulatory failure should be observed in PWS. We should ﬁnd sequences where
coarticulation is not altered, and others where transition gestures are disrupted or go in
a false direction (Harrington, 1987). We do not expect SLDs to be due to one type of
coarticulation failure, in that we suppose that in stuttered prolongations and repetitions
the disﬂuent sound will be correctly anticipated, while this should not be the case for silent
blocks.

520

I. DIDIRKOVÁ AND F. HIRSCH

Material and methods

Data

Data used in this study were collected by means of an EMA Carstens AG501 3D at the
Lorraine Research Laboratory in Computer Science and its Applications (LORIA,
Nancy, France). The sampling rate of the machine is 250 Hz, and its accuracy is to
0.3 mm. The EMA allows the tracking of movements of the articulators (tongue root,
tongue body and tip, lower and upper lip, mandible) on three axes (x, y and z) and
two directional angles (phi and theta). All these data are stored in a .pos ﬁle and
synchronised with a sound recording (microphone t.bone EM 9600, 44.1 kHz, 16 bits)
in the .wav format.

Ten sensors (2 × 3 mm) per subject were used as follows: two were ﬁxed behind the
auricles and one on the forehead of each speaker to calibrate the subject’s head move-
ments (Figure 1). This neutralisation allowed subjects to move without any restriction
(Ouni, Mangeonjean, & Steiner, 2012). Two sensors were ﬁxed on the lips of each speaker:
one in the middle of the upper lip, the other in the middle of the lower lip. Three coils
were situated on the tongue: one on the tongue tip (0.5 mm from the tip), one on the
tongue body (2 cm from the ﬁrst coil), and one on the tongue back (approximatively 1 cm
from the second coil). One sensor was placed on the middle of each subject’s chin (Green,
Wilson, Wang, & Moore; 2007), allowing the mandible’s movements to be tracked. The
palate’s form was indicated by means of a tenth coil.

Participants were recorded in a soundproof room while reading two texts: an Alphonse
Daudet novel, La chèvre de Monsieur Seguin (Mister Seguin’s goat); and the French
adaptation of Aesop’s The North Wind and the Sun. Subjects were not familiar with the
text. They were asked to sit comfortably, the text then appeared on a computer screen and
they were asked to start reading when they felt ready. A pre-test exercise consisting of

Figure 1. Placement of sensors on the mandible, lips and tongue.

reading a diﬀerent short text and dialogue had been carried out prior to the recordings to
train participants in speaking with the sensors.

CLINICAL LINGUISTICS & PHONETICS

521

Participants

Two PWS and two control subjects were recruited for this study. They were all native
French speakers.

In this study, only the speech of PWS was analysed. This choice was made since
stuttering is considered as a motor speech disorder, where disﬂuencies would be due to
a deﬁciency in speech motor skill (Peters, Hulstijn, & Van Lieshout, 2000), while in PWNS
disﬂuencies are generally believed to be due to a momentary lack of availability of speech
content (Corley & Stewart, 2008). This led us to prefer not to compare these two types of
disﬂuencies in this investigation.

The PWS were one male and one female, aged 26 and 23 respectively. They both were
post-graduate students recruited with the help of speech therapists in Strasbourg and
Nancy (France). The subjects had not reported any other speech or language disorder such
as cluttering. The stuttering of both PWS was evaluated by their speech therapists as
severe on the Riley’s Stuttering Severity Instrument scale (Riley, 1994). Both PWS had not
seen a speech therapist in the previous two years. They agreed with and signed an
informed consent form before taking part in the study, and they were paid for their
participation.

Data analysis

General
Data analysis relied on the perceptual and acoustic identiﬁcation of SLDs. First, three
persons (both authors and a speech therapist specialising in stuttering) identiﬁed all SLDs,
based on perception and speech signal, without classifying the disﬂuencies. They then
discussed the cases on which they did not agree. To conﬁrm their annotations and identify
the perceptual class of each disﬂuency, a .wav ﬁle was extracted for each SLD, allowing
a perception test to be carried out using the freeware Perceval (André et al., 2003). This
freeware was used to present all the SLDs to a jury of ﬁve naïve listeners tasked to
(1) listen once to each stimulus and (2) indicate its category among 4 possibilities:
(a) a ‘bloc’; (b) a ‘repetition’; (c) a ‘prolongation’; or (d) a ‘combined disﬂuency’. The
latter corresponds to a combination of diﬀerent disﬂuencies immediately following each
other. As the jury members declared themselves not to be particularly familiar with
stuttering, they were trained on 10 samples of SLDs. Before the training session, they
were provided with deﬁnitions of:

(1) ‘blocks’ (Silent intervals between two sounds, two syllables or two diphones, such as

(2) ‘repetitions’ (Identical reproductions of a sound, a syllable or a word with or

without a silent pause in-between, such as “choc, choc, chocolat”).

(3) ‘prolongations’ (Elongations of a sound, whether a vowel or a consonant, such as

“pa … pa”).

“sssssssssssuis”).

(4) ‘combined disﬂuency’ (A combination of two or three of the above).

522

I. DIDIRKOVÁ AND F. HIRSCH

According to this analysis, 62 repetitions, 96 prolongations and 40 blocks were
identiﬁed (Fleiss’ kappa: 0.752). Disagreements were accounted for by inspecting the
acoustic signal until agreement was reached based on the following criteria:

(1) whenever the disﬂuency consisted of a silent portion placed in-between two sounds,
diphones or syllables and was accompanied by an audible tension, it was classiﬁed
as a ‘block’.

(2) when an identical structure of the formants typical of a sound during the whole

SDL was observed, the disﬂuency was classiﬁed as a ‘prolongation’.

(3) when the identical structure of the formants typical of a sound contained silent

interruptions, the disﬂuency was classiﬁed as a ‘repetition’.

(4) a ‘combined disﬂuency’ was then a random combination of at least two of the
above. For the sake of simpliﬁcation, it was not considered that a repetition could
be combined with a block. This choice was made so that we did not have to
introduce an arbitrary threshold for a silent sequence between two repetitions.

Repetitions of diphones, syllables, words and other sequences containing more than
one phone were excluded from the research to focus on disﬂuencies containing one sound
only. This choice was made to in order to work on disﬂuencies having the same structure
in terms of number of segments involved.

Sound ﬁles were then transcribed in Praat (Boersma & Weenink, 2017) and aligned
semi-automatically using EasyAlign (Goldman, 2011). The alignment was then corrected
manually, and completed for the annotation of all SLDs produced by PWS. 198 stuttering-
like disﬂuencies were annotated in the data and used for further analysis.

After this processing, the annotation was exported into the VisArtico software (Ouni
et al., 2012) allowing the visualisation of articulatory movements in diﬀerent conﬁgura-
tions: 3D or 2D with a midsagittal view.

For each annotated SLD, the vertical movements (the z axis) of the upper and lower
lip, the tongue tip, the tongue body and the mandible were visualised and analysed
(Figure 2).

Measures
We analysed gestures anticipating the disﬂuent sound, and gestures that prepare the sound
located immediately after the disﬂuency.

It is known that anticipatory gestures start very early in French compared to other
languages (Ma, 2008). Therefore, since the anticipatory coarticulation is not limited to the
CV sequence, we decided not to have an a priori temporal window. Instead, we made the
choice to identify the onset of articulators’ gestures.

Concerning the kinematics, even though several measures are possible,

including:
displacement; velocity; duration; and phases of movement (Recasens & Espinosa, 2010),
the choice was made to focus on displacement in this study. This decision can be
explained by our research goal, namely to investigate the presence/absence of coarticula-
tory behaviour without, for the moment, studying other kinematic parameters of coarti-
culation in PWS. Trajectories of each articulator were tracked throughout the disﬂuency

CLINICAL LINGUISTICS & PHONETICS

523

Figure 2. A screenshot of Visartico software (Ouni et al., 2012). From top to bottom: on the left side, the
3D visualisation of the coils’ position. On the right, the 2D midsagittal view of articulatory movements
and a frontal view of lips. On the bottom, spatial and temporal evolution of articulatory movement,
segmentation, speech signal.

and throughout the sounds preceding the SLD. More precisely, gestures allowing the
production of the disﬂuent sound, and the sound subsequent to the disﬂuency, were
studied starting from the beginning of the articulators’ movements, i.e. when the sound of
interest was a [t], we tracked the beginning of the tongue tip’s upward movement. Notice
that we controlled for homorganic places of articulation (sequences such as [st]). Such
cases, however, systematically contained non-speech movements in-between (probably
due to spasms), which allowed us to include those cases in the analysis. Indeed, each
sound requires a degree of constriction on the vertical axis (more or less important,
depending on the sound’s nature). This constriction is caused by one active articulator and
is represented in EMA data by the vertical movement of this articulator. Furthermore, we
know that there are overlaps in the production of speech sounds (Hirsch, Sock, Connan, &
Brock, 2003). Consequently, we analysed the main constriction movement at the origin of
each sound (the disﬂuent or the subsequent sound), and, more importantly, the start of
this sound and its timing. In other words, the objective was to know if the articulatory
movement required for the production of the disﬂuent sound and the subsequent sound
was ready on time for proper production.

As mentioned before, 198 SLDs were analysed, containing 62 repetitions, 96 prolongations
and 40 blocks. However, the distribution of acoustic disﬂuencies was not equal in the two
subjects, due to diﬀerences in their stuttering. Table 1 gives this distribution across subjects.
Further statistical treatment was done within the RStudioTeam (2015). Statistical tests

are detailed in Results.

Table 1. Distribution of SLDs across subjects.
Repetitions
Subject
FFS
FMS
Total

Prolongations

27
69
96

1
61
62

Blocks

14
26
40

Total

42
156
198

524

I. DIDIRKOVÁ AND F. HIRSCH

Results

Observations based on the articulatory data

Coarticulatory patterns between the disﬂuent sound and the preceding sound(s)
When not considering the acoustic/perceptive type of disﬂuencies, four coarticulatory
patterns have been observed in our data.

The Figure 3a shows an example of

the sequence [pɥisːasejɑ̃] which contains
a prolongation of the ﬁrst fricative [s]. The coarticulation is well observed: the tongue
tip starts the elevation movement in the sequence [pɥi], then it performs a straighter
upward movement during the short silence. The tongue tip stays in the position
reached at the issue of this elevation for the whole duration of the disﬂuency. Thus,
the disﬂuent sound has been correctly anticipated (D1, Table 2). The Figure 3b
represents the case of a prolongation of the second fricative in [seʃːɛvʀ]. We observed
a disruption of the coarticulatory gestures between the sounds preceding the disﬂuent
[ʃ] and the prolonged phone. To allow the pronunciation of the vowel [e], the tongue

Figure 3. Coarticulatory patterns observed between the sound preceding the disﬂuency and the
disﬂuent sound.

CLINICAL LINGUISTICS & PHONETICS

525

Table 2. Observed coarticulatory patterns between (1) the sound(s) preceding the SLD and the disﬂuent
sound, and (2) the disﬂuent sound and its subsequent sound.

With anticipation

Correct anticipation

Disrupted anticipation

D1
Disﬂuency on the steady phase of
the phone

51.41%
S1
Production of the sound stopped by
the disﬂuency
27.78%

D3

Inappropriate
amplitude

19.21%
S3
Inappropriate
amplitude
32.78%

D4

Rise-fall
cycles

26.55%
S4
Reversed
gesture
4.44%

Without anticipation

D2

No anticipation of the
disﬂuent sound
2.82%
S2
No anticipation of the
subsequent sound
35%

Disﬂuent sound
Subsequent
sound

tip went down after the apical fricative [s] and remained in this position during
a short pause. It then made a progressive ascending movement during the disﬂuency,
until it reached the expected position at the end. Hence, this conﬁguration represents
the pattern D2. The Figure 3c shows a case of a perceptive prolongation of the nasal
stop [m] in the sequence [səgɛ̃/mːəsjø]. The upper and the lower lips seemed to
correctly anticipate their movement to allow a closure for the stop; nevertheless,
both continued their movement with numerous rise-fall cycles until the end of the
disﬂuency (D4). Finally, the last pattern noticed in our data is shown in the Figure 3d,
in the sequence [//ty]. Here, a rise of the tongue tip at the beginning of the block was
observed. Nevertheless, the articulator stopped its movement and stayed at a level
lower than its position at the beginning of the [t] (D3).

Coarticulatory patterns between the disﬂuent sound and its subsequent sound
Patterns observed for the coarticulation between the disrupted sound and its sub-
sound
sequent phone are similar
(Table 3).

to the patterns described for

the disﬂuent

Figure 4a shows the case where the phone subsequent to the disﬂuent one seemed
to be anticipated, since the anticipatory gesture started before the emergence of
disﬂuency. However, the gesture is not appropriate as it will either not reach its target
zone or overpass it, compared to the subsequent ﬂuent production. In this example,
the sequence [twaty] was disrupted by a block after the [a]. We can observe an
elevation of
the [a]. The
the tongue back for the [y] during the production of
articulator overpassed its target zone (S3). The second case, with the sound [ø] in
the sequence [kuʀvøty], was one where no anticipation was observed (S2). The tongue
dorsum movement preparing the vowel starts during the disﬂuency (Figure 4b). The
third coarticulatory pattern is that of a correct anticipation of the subsequent sound
(S1). Here, the spatial and the temporal aspects of the gesture seem to be appropriate

Table 3. Inter-speaker frequencies of coarticulatory patterns.

Subject

FFS
FMS

D1
53.94%
69.87%

Disﬂuent sound
D3
D2

0%
1.92%

30.26%
12.18%

Subsequent sound

D4

15.79%
16.03%

S1

15.79%
33.33%

S2

21.05%
21.15%

S3
60.53%
42.31%

S4
2.63%
3.21%

526

I. DIDIRKOVÁ AND F. HIRSCH

Figure 4. Coarticulatory patterns observed between the disﬂuent sound and the sound subsequent to
the SLD.

for the production of the projected sound, as in Figure 4c where a prolongation of the
consonant [s] is noticed in the [ɥi/sa] sequence. Here, we can observe a downward
movement of the tongue dorsum during the pause following the [i]. The tongue
dorsum will be in the conﬁguration for the vowel [a] before its acoustic beginning.
Finally, Figure 4d shows the case of the vowel [e] in [mididete], interrupted by a block
between the second [i] and the second alveolar stop [d]. There seems to be an
anticipatory gesture of
instead of
a descending movement, the articulator rises. Therefore, the question is whether the
gesture is anticipated but reversed, or there is no anticipation (S4).

tongue dorsum during the

[i], but

the

It is worth noting that the frequency of these patterns is not equally distributed. As
shown in Figure 5, whereas the disﬂuent sound is often correctly anticipated (64.66%)
and only 3 cases of a lack of anticipation have been observed (1.29%), the subsequent
sound can often be characterised by an inadequate amplitude (48.28%). The frequency
of the lack of anticipation is more important here (21.12%).

CLINICAL LINGUISTICS & PHONETICS

527

Figure 5. Frequency of the coarticulatory patterns for the disﬂuent sound (left panel) and the
subsequent sound (right panel).

Moreover, the tendencies are the same across the two speakers for the more (in bold)
and the less (in italics) frequent conﬁgurations. Due to the small number of participants, it
however seems diﬃcult to reject the independence of these two variables, especially for the
subsequent sound (χ2 statistics: disﬂuent sound: p = .008, V = 0.24; subsequent sound:
p = .24, V = 0.21) (see Table 3).

Coarticulatory patterns according to the acoustic/perceptive type of disﬂuency

This section aims to illustrate some of the possible coarticulatory conﬁgurations according
to the perceptive types of SLDs.

Repetitions
The female subject only produced one repetition in the patterns D1 and S3. As for
the second subject, out of 61 repetitions produced, the disﬂuent sound was correctly
anticipated in 35 cases (57.38%). In 17 cases (27.87%), the articulatory gesture for the
disﬂuent
sound had inappropriate amplitude. 9 repetitions were produced with
a disrupted gesture (14.75%). Therefore, every repetition has been characterised by the
presence of anticipation of the repeated phone.

The most represented coarticulatory pattern for the sound subsequent to the disﬂuency
was the pattern S3 (42 cases, 68.85%). The conﬁgurations S1 and S2 were observed for 9
(14.75%) and 8 (13.11%) repetitions respectively. In two disﬂuencies (3.28%), the principal
articulator made a reversed gesture compared to the expected one (Figure 6).

When we combine the two phones we are interested in, i.e. the repeated sound and its
subsequent sound, in repetitions we observe that a correctly anticipated repeated sound
and an inappropriate amplitude of the gesture aiming to produce the subsequent sound
(25 repetitions, 40.32%) mostly characterise the repetitions (Figure 8). In 17.74% (11 repe-
titions), both the disﬂuent sound and the subsequent sound gestures have an inappropri-
ate amplitude. Finally, when the gesture of the principal articulator for the disﬂuent sound
production is disrupted, the subsequent sound often has an inappropriate amplitude as
well (11.29% of all repetitions).

528

I. DIDIRKOVÁ AND F. HIRSCH

Figure 6. Coarticulatory patterns observed in repetitions. Column width indicates the relative propor-
tion of the corresponding value.

Prolongations
In prolongations, the disﬂuent sound is mostly correctly anticipated (D1; 88 prolonga-
tions, 91.67%). Hence, the other conﬁgurations are in the minority, with three cases
(3.13%) for the D2 and D4 patterns and two cases (2.08%) for the D3 pattern.

Most of the time (in 49 prolongations, representing 51.04%), the subsequent sound is
correctly anticipated as well (S1). However, in 19 cases (19.79%), no anticipation of the
subsequent sound (S2) has been observed during prolongations. In 23 disﬂuencies, the
subsequent phone has been planned but with an insuﬃcient amplitude. Finally, in 5 cases
(5.21%), the gesture has been reversed.

When looking at both sounds, there seem to be three major patterns in prolongations.
In 46.88% of cases, the disﬂuent sound and its subsequent sound are correctly anticipated
(with the right amplitude and on time). In 23 disﬂuencies, the disﬂuent sound remains
correctly anticipated, but the amplitude of the gesture aiming to produce the subsequent

CLINICAL LINGUISTICS & PHONETICS

529

sound is not correct (21.88%). Finally, in 19 prolongations (19.79% of all prolongations),
the prolongation comes on the steady phase of the phone, without any anticipation of the
subsequent sound. Every other combination of patterns represents less than 4%, with 6
not being represented (see the Figure 7).

Blocks
This category is the least represented in our corpus, with 40 occurrences. Moreover, the
inter-subject diﬀerences are present for both studied phones, making it impossible to
the female speaker does not seem to have
conclude with a generalisation. Thus,
a preference for either the coarticulatory pattern of the disﬂuent sound, or for the
conﬁguration of the subsequent sound preparation. She produced 6 blocks (42.86%)
with the patterns D1, and 6 blocks with the pattern D3. For the subsequent sound, she
did not anticipate it in 8 of her blocks (57.14%). The last 6 blocks are divided into 3 cases
with a correct anticipation, and 3 cases with an inappropriate amplitude (21.43% each).

Figure 7. Coarticulatory patterns observed in prolongations.

530

I. DIDIRKOVÁ AND F. HIRSCH

Figure 8. Coarticulatory patterns observed in blocks.

The second subject’s blocks were mostly characterised by the D4 pattern (15 cases,
57.69%). In 9 cases, the blocked phone seemed to be correctly anticipated (D1; 34.62%).
In one block, he did not anticipate the subsequent sound (D2; 3.85%), and in the last block
the amplitude is inappropriate (D3; 3.85%). Subsequent sounds are mostly characterised
by the S2 pattern (12 cases, 46.15%). However, in 8 blocks (30.77%), the subsequent sound
was correctly anticipated (S1).

Thus, these important inter-subject diﬀerences make it diﬃcult to deﬁne the most used
combination of coarticulatory patterns. The coarticulation of the sound subsequent to the
disﬂuency seems to be more robust, since there is mostly no anticipation of this sound
observed in blocks (Figure 8).

A chi-squared test was then performed to determine if the coarticulatory pattern is
dependent on the acoustic type of disﬂuency. Table 4 shows that blocks behave diﬀerently
from repetitions and prolongations, both in the coarticulation between the sound preced-
ing the disﬂuency and the disﬂuent sound (p = .000, V = 0.40), and between the disﬂuent

CLINICAL LINGUISTICS & PHONETICS

531

Table 4. Coarticulatory patterns based on acoustic type of SLDs.

Disﬂuency
Repetition
Prolongation
Block

D1
56.45%
76.92%
37.50%

Disﬂuent sound
D3
D2
27.42%
0%
13.85%
1.54%
17.50%
2.50%

Subsequent sound

D4
16.13%
7.69%
42.50%

S1
14.52%
33.85%
27.50%

S2
12.90%
16.15%
50%

S3
69.35%
46.92%
20%

S4
3.23%
3.08%
2.50%

sound and the subsequent sound (p = .000, V = 0.46). Whereas repetitions and prolonga-
tions were more likely to have the disﬂuent sound correctly anticipated, this was not the
case in blocks where the principal articulator was doing upward and downward move-
ments before stabilisation and production of the sound. As for the subsequent sound, it
was mostly characterised by a gesture with an inadequate amplitude in repetitions and
prolongations, but it is worth noting that in blocks the subsequent sound had not been
anticipated in 50% of cases. However, in both the disﬂuent and subsequent sound, the less
encountered conﬁgurations seem to be identical among disﬂuencies (Table 4).

Discussion

The purpose of this study was threefold. Our research questions dealt with stuttering as
a coarticulation problem; with coarticulatory patterns; and with diﬀerences in coarticula-
tion based on acoustic types of disﬂuency. The Discussion will thus be divided into three
parts, dealing with each of these questions.

Stuttering as a coarticulation problem

The ﬁrst aim of this paper was to complete researches on coarticulation in stuttering
by studying coarticulatory movements using an EMA. For this two-case study, 198
disﬂuencies were extracted from a corpus of read speech and analysed in order to
determine if SLDs were systematically characterised by a disruption of sound transi-
tion. Up to now, most studies dealing with the topic have focussed on perceptually
ﬂuent speech in PWS (Belmont, 2015; Frisch et al., 2016; Hirsch, 2007; Pendeliau-
Verdurand, 2014; Robb & Blomgren, 1997). Our contribution aimed to lead a systemic
study of SLD.

The results show that cases without correct anticipation of the disﬂuent sound are in
the minority. In general, coarticulation is observed even though gestures can be disrupted.
Both disﬂuent and subsequent sounds were correctly prepared in 25% of all cases.

Although this conﬁguration was in the minority in our corpus, it clearly shows that
stuttering is not exclusively a problem of coarticulation. Unlike Van Riper (1982), we
conclude that SLDs are not exclusively due to a coarticulatory disruption. The weak
percentage of this conﬁguration in our study still makes it possible to support the idea
of a motor control disruption in this speech pathology (Kent, 2000; Kleinow & Smith,
2000; Ludlow & Loucks, 2003; Neilson & Neilson, 1987).

Finally, our ﬁndings on sequences where the articulator reaches its target zone two or
more times progressively seem to support theories and models based on feedback and
proprioception in PWS, such as the Theoretical Model (Max et al., 2004) or the Dual
Premotor Model of Cluttering and Stuttering (Alm, 2007). Indeed, we can suppose that

532

I. DIDIRKOVÁ AND F. HIRSCH

these progressive movements, as well as repetitions of movements, are due to an inade-
quate acoustic or proprioceptive feedback. In other terms, the subject would not be
satisﬁed with the preceding movement and would try to reproduce it in a way that
would respond to his/her expectations.

Coarticulatory patterns in stuttering

SLDs were, most of the time, accompanied by a coarticulatory disruption. This disruption
takes diﬀerent forms and occurs at diﬀerent moments in the disﬂuency. This result
corresponds to the one described by Harrington (1987), who points out three scenarios
in coarticulation in [CV] sequences by analysing the second formant during disﬂuencies,
suggesting that there could be several articulatory patterns concerning coarticulation in
stuttered speech. The present study conﬁrms this hypothesis, since four conﬁgurations
were observed in coarticulation between the sound preceding the disﬂuency and the
disﬂuency itself, as well as in coarticulation between the disﬂuency and the next sound.
This observation underlines the random characteristics of disﬂuencies, which can occur

anywhere in the preparation or the production of a sound.

Coarticulation and acoustic types of disﬂuency

The last point of our study concerns the relationship between acoustic types of disﬂuencies
and coarticulatory patterns. While data presented in this study do not allow us to conclude
that stuttering can be presumed to be a coarticulation problem, an eﬀect linked to the
acoustic type of disﬂuency has been observed. We noticed that coarticulation is generally
well executed just before a sound prolongation, which can be considered as normal since
the phoneme which is abnormally prolonged is correctly carried out. In this case, the
anticipation of the sound which follows the disﬂuency is, most of the time, correct.

The coarticulation just before a sound repetition is more variable, since several patterns
have been observed. Indeed, it has been noticed that anticipatory coarticulation can be
either well executed or perturbed. In this second case,
inappropriate amplitudes or
disruptions of the coarticulatory movement have been pointed out. As for the transition
between the disﬂuency and the following sound, the movement is mainly characterised by
an abnormal amplitude.

Finally, in blocks the results are more contrasted: the two PWS either anticipate
correctly the disﬂuent sound, or produce a (series of) movement(s) with an inappropriate
amplitude. Generally, the subsequent sound is not anticipated, but when it is, the gesture
is not correctly produced. Moreover, we can suppose that when present, these chaotic
movements are a result of spasms aﬀecting facial muscles.

However, it is necessary to emphasise that we need to consider the fact that almost every
conﬁguration can be found in every perceptual type of disﬂuency, which brings us to the
question of phonatory and articulatory similarities and dissimilarities between the disﬂuencies.
Furthermore, our results bring a partial response to the question of the notion of the
disﬂuent sound. When talking about prolongations, can we consider the prolonged sound
as being disﬂuent because the articulatory posture is maintained? Or, is it the subsequent
sound that is not ‘ready’ to be produced, thus leading to the maintaining of the articu-
latory posture? Our results indicate that the answer is not obvious, since diﬀerent patterns

CLINICAL LINGUISTICS & PHONETICS

533

issues are possible during
can be observed, allowing us to suppose that several
a disﬂuency. Either the ‘disﬂuent’ sound is the prolonged one, because of a blockage of
the principal articulator; or the “disﬂuent” sound is the subsequent one and its production
has not been prepared by the speaker. If this is the case, this result would help studies
led on problematic (stuttered) sounds in diﬀerent languages.

Limits and perspectives

The aim of this work was to investigate the question of coarticulatory disruption in stuttering.
The results reveal that diﬀerent patterns of transition disruption can be found, and that
coarticulation can be correct in certain cases. However, it would be interesting to record
other PWS in order to discover if other types of transition can be observed.

The type of the corpus can also be discussed. Read speech was used to carry out this
research, yet it is known that spontaneous speech is produced at a faster rate, which can
partially explain an increase of disﬂuencies in this type of elocution (Pinto, Schiefer, & de
Avila, 2013). Consequently, the question arises: would the same patterns be observed
when speech is less controlled than in reading?

Furthermore, only the vertical movements of the diﬀerent articulators have been
analysed for this work. This choice has been made because variations of the z-axis are
responsible for the degree of closure/constriction that allow the production of either
a consonant or a vowel. Nevertheless, horizontal movements should also be considered,
since they have obvious consequences on the quality of the pronounced sound.

In the same vein, it seems necessary to continue this study by expanding it to all
disﬂuencies, including more than one phone; and by research on coarticulation between two
or more repetitions or, more generally, two or more diﬀerent disﬂuencies in order to make
a comparison with coarticulation between a disﬂuency and the subsequent ﬂuent production.
It would also be interesting to expand this type of study into the examination of the
biomechanical properties of muscular movements. Such studies could lead to a better
understanding of the causes and the muscular origins of observed coarticulatory patterns
in stuttered speech.

Acknowledgments

We would like to thank the two subjects, A. and I., for their participation to this study. We are also
grateful to Slim Ouni and the Equipex Ortolang for their help with the acquisition. This study was
funded by the project BENEPHIDIRE, project number (ANR-18-CE36-0008) of the Agence
Nationale de la Recherche and the Caisse Nationale de Solidarité pour l’Autonomie.

Declaration of Interest
The authors report no conﬂicts of interest.

Funding

This work was supported by the Agence Nationale de la Recherche [ANR-18-CE36-0008];Caisse
Nationale de Solidarité pour l’Autonomie [ANR-18-CE36-0008].

534

I. DIDIRKOVÁ AND F. HIRSCH

ORCID

Ivana Didirková
Fabrice Hirsch

http://orcid.org/0000-0001-8107-2361

http://orcid.org/0000-0002-5646-4651

References

Alm, P. A. (2007). The dual premotor model of cluttering and stuttering: A neurological framework. In

Proceedings of the 1st World Conference on Cluttering. Katarino, Bulgaria.

André, C., Ghio, A., Cavé, C., & Teston, B. (2003). PERCEVAL: A Computer-Driven System for
Experimentation on Auditory and Visual Perception. In Proceedings of XVth ICPhS (pp.
1421–1424). Barcelona, Spain.

Bang, H.-Y. (2017). The acoustic counterpart to coarticulation resistance and aggressiveness in locus
equation metrics and vowel dispersion. The Journal of the Acoustical Society of America, 141(4),
EL345. doi:10.1121/1.4979301

Belmont, A. (2015). Anticipatory coarticulation and stability of speech in typically ﬂuent speakers and
people who stutter across the lifespan: An ultrasound study (Master of Science). University of
South Florida.

Boersma, P., & Weenink, D. (2017). Praat: Doing phonetics by computer. Retrieved from http://

www.praat.org

Corley, M., & Stewart, O. W. (2008). Hesitation disﬂuencies in spontaneous speech: The meaning of

Um. Language and Linguistics Compass, 589–602. doi:10.1111/j.1749-818X.2008.00068.x

Dehqan, A., Yadegari, F., Blomgren, M., & Scherer, R. C. (2016). Formant transitions in the ﬂuent
speech of Farsi-speaking people who stutter. Journal of Fluency Disorders, 48, 1–15. doi:10.1016/j.
jﬂudis.2016.01.005

Frisch, S. A., Maxﬁeld, N., & Belmont, A. (2016). Anticipatory coarticulation and stability of speech
in typically ﬂuent speakers and people who stutter. Clinical Linguistics & Phonetics, 30(3–5),
277–291. doi:10.3109/02699206.2015.1137632

Goldman,

J.-P. (2011). EasyAlign: An automatic phonetic alignment

tool under Praat. In

Proceedings of InterSpeech. Firenze, Italy.

Green, J. R., Wilson, E. M., Wang, Y.-T., & Moore, C. A. (2007). Estimating mandibular motion
based on chin surface targets during speech. Journal of Speech, Language, and Hearing Research,
50(4), 928–939. doi:10.1044/1092-4388(2007/066)

Hardcastle, W. J., & Hewlett, N. (2006). Coarticulation: Theory, data and techniques. Cambridge,

UK: Cambridge University Press.

Harrington, J. (1987). Coarticulation and Stuttering: An Acoustic and Electropalatographic Study.
In H. F. M. Peters & W. Hulstijn (Eds.), Speech motor dynamics in stuttering (pp. 381–392).
Vienna, Austria: Springer.

Hirsch, F. (2007). Le bégaiement: Perturbation de l’organisation temporelle de la parole et

conséquences spectrales (PhD thesis). University of Strasbourg, France, p. 282.

Hirsch, F., Sock, R., Connan, P.-Y., & Brock, G. (2003). Auditory eﬀects of anticipatory rounding in
relation with vowel height in French. Proceedings of XVth ICPhS (pp. 1445–1448). Barcelona, Spain.
Howell, P., Williams, M., & Vause, L. (1987). Acoustic analysis of repetitions in stutterers’ speech.
In H. F. M. Peters & W. Hulstijn (Eds.), Speech motor dynamics in stuttering (pp. 371–380).
Vienna, Austria: Springer.

Iskarous, K., Fowler, C., & Whalen, D. (2010). Locus equations are an acoustic expression of
articulator synergy. Journal of the Acoustical Society of America, 127, 2021–2032. doi:10.1121/
1.3365253

Kent, R. D. (2000). Research on speech motor control and its disorders: A review and prospective.

Journal of Communication Disorders, 33(5), 391–428. doi:10.1016/S0021-9924(00)00023-X

Kleinow, J., & Smith, A. (2000). Inﬂuences of length and syntactic complexity on the speech motor
stability of the ﬂuent speech of adults who stutter. Journal of Speech, Language, and Hearing
Research, 43(2), 548–559. doi:10.1044/jslhr.4302.548

CLINICAL LINGUISTICS & PHONETICS

535

Löfqvist. (1999). Interarticulator phasing, locus equations, and degree of coarticulation. Journal of

the Acoustical Society of America, 106, 2022–2030. doi:10.1121/1.427948

Ludlow, C. L., & Loucks, T. (2003). Stuttering: A dynamic motor control disorder. Journal of

Fluency Disorders, 28, 273–295. doi:10.1016/j.jﬂudis.2003.07.001

Ma, L. (2008). La coarticulation en français et en chinois : Étude expérimentale et modélisation.

TIPA. Travaux Interdisciplinaires Sur La Parole et Le Langage, 27, 212[Online].

Maruthy, S., Feng, Y., & Max, L. (2017). Spectral coeﬃcient analyses of word-initial stop consonant
productions suggest similar anticipatory coarticulation for stuttering and nonstuttering adults.
Language and Speech, 61(1), 31–42. doi: 10.1177/0023830917695853

Max, L., Guenther, F. H., Gracco, V. L., Ghosh, S. S., & Wallace, M. E. (2004). Unstable or
insuﬃciently activated internal models and feedback-biased motor control as sources of dys-
ﬂuency: A theoretical model of stuttering. Contemporary Issues in Communication Science and
Disorders, 31, 105–122. doi:10.1044/cicsd_31_S_105

Neilson, M. D., & Neilson, P. D. (1987). Speech motor control and stuttering: A computational
model of adaptive sensory-motor processing. Speech Communication, 6(4), 325–333. doi:10.1016/
0167-6393(87)90007-0

Ouni, S., Mangeonjean, L., & Steiner, I. (2012). VisArtico: A visualization tool for articulatory data.
the International Speech Communication

Presented at
Association - Interspeech 2012, Portland, OR, United States.

the 13th Annual Conference of

Pendeliau-Verdurand, M. (2014). Parole disﬂuente : Aspects phonétiques et phonologiques (Thèse de

doctorat). Université de Grenoble, Grenoble, France.

Peters, H., Hulstijn, W., & Van Lieshout, P. (2000). Recent developments in speech motor research

into stuttering. Folia Foniatrica Et Logopedia, 52, 1–3.

Pinto, J. C. B. R., Schiefer, A. M., & de Avila, B. C. R. (2013). Disﬂuencies and speech rate in
spontaneous production and in oral reading in people who stutter and who do not stutter.
Audiology - Communication Research, 18, 2.

Recasens, D., & Espinosa, A. (2010). Lingual kinematics and coarticulation for alveolopalatal and
velar consonants in Catalan. The Journal of the Acoustical Society of America, 127(5), 3154–3165.
doi:10.1121/1.3372631

Riley, G. (1994). The stuttering severity instrument for adults and children (SSI-3) (3rd ed.). Austin,

TX: PRO-ED.

Robb, M., & Blomgren, M. (1997). Analysis of F2 transitions in the speech of stutterers and

nonstutterers. Journal of Fluency Disorders, 22, 1–16. doi:10.1016/S0094-730X(96)00016-2

RStudio Team. (2015). RStudio: Integrated development for R. RStudio, Inc., Boston, MA. Retrieved

from http://www.rstudio.com/.

Tabain, M. (2000). Coarticulation in CV syllables: A comparison of locus equation and EPG data.

Journal of Phonetics, 28(2), 137–159. doi:10.1006/jpho.2000.0110

Van Lieshout, P., Hulstijn, W., & Peters, H. (2004). Searching for the weak link in the speech
production chain of people who stutter: A motor skill approach. In B. Maassen, R. Kent,
H. Peters, P. Van Lieshout, & W. Hulstijn (Eds.), Speech motor control in normal and disordered
speech (pp. 313–355). Oxford, UK: Oxford University Press.

Van Riper, C. (1982). The nature of stuttering (2nd ed., pp. 468). Englewood Cliﬀs, NJ: Prentice-Hall.
Wingate, M. E. (1977). Immediate Source of Stuttering. In R. W. Rieber & J. Wollock (Eds.), The
problem of stuttering: Theory and therapy (pp. 211). New York, NY: Elsevier, North Holland Inc.
Yaruss, J., & Conture, E. (1993). F2 transitions during sound/syllable repetitions of children who
stutter and predictions of stuttering chronicity. Journal of Speech, Language, and Hearing
Research, 36, 883–896. doi:10.1044/jshr.3605.883

Zharkova, N., Hewlett, N., & Hardcastle, W. J. (2011). Coarticulation as an indicator of speech
motor control development in children: An ultrasound study. Motor Control, 15, 118–140.
doi:10.1123/mcj.15.1.118

Zmarich, C., Balbo, D., Galata, V., Verdurand, M., & Rossato, S. (2013). The production of syllables
in stuttering adults under normal
In Multimodalità
e multilingualità: La sﬁda più avanzata della comunicazione orale (pp. 463–474). Venezia, Italy:
Bulzoni.

and altered auditory feedback.
```