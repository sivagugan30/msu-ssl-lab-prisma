# 1-s2.0-S0094730X18300238-main

```
Journal of Fluency Disorders 58 (2018) 47–60

Contents lists available at ScienceDirect

Journal of Fluency Disorders

journal homepage: www.elsevier.com/locate/jﬂudis

Envelope modulation spectral (EMS) analyses of solo reading and
choral reading conditions suggest changes in speech rhythm in
adults who stutter
Deepthi Dechammaa, Santosh Maruthyb,⁎

T

a Samvaad Institute of Speech and Hearing, Bengaluru, Karnataka, 560024, India
b All India Institute of Speech and Hearing, Mysuru, Karnataka, India

A R T I C L E I N F O

A B S T R A C T

Keywords:
Stuttering
Speech rhythm
Choral reading
Adults who stutter
Envelope modulation spectrum

Purpose: A longstanding ﬁnding in persons who stutter is that stuttering frequency signiﬁcantly
reduces during choral reading when compared to the solo reading condition. Here, we tested the
hypothesis that this decrease in stuttering frequency may be because speech of the normal
speaker dictates the speech rhythm of a person who stutters. We used an automated, sensitive
acoustic technique—Envelope Modulation Spectral (EMS) analysis— that allowed us to docu-
ment speech rhythm.
Method: Seventeen adults who stutter (AWS) read sentences under two conditions: solo reading
and choral reading. Percentage of syllables stuttered (%SS), the rate of speech, and speech
rhythm were calculated from the recorded sentences from AWS. Further, AWS speech rhythm
during solo reading was compared with typical adults. EMS was extracted for the full signal and
seven-octave bands. From the extracted envelope six predictor variables (peak frequency, peak
amplitude, energy in the spectrum 3–6 Hz, energy in the spectrum from 0 to 4 Hz, energy in the
spectrum from 4 to 10 Hz, and the ratio of energy below4 Hz/above 4 Hz) were computed.
Results: Signiﬁcant decrease in stuttering frequency and rate of speech was noticed in choral
reading when compared to the solo reading condition. Further, analysis of EMS results suggested
the statistically signiﬁcant diﬀerence between two reading conditions (for peak frequency and
peak amplitude), and between two groups for all predictor variables.
Conclusion: Overall, current results highlight that decreases in stuttering during the choral
reading is characterized by a decrease in rate and changes in some aspects of speech rhythm in
Kannada speaking AWS.

1. Introduction

Stuttering is characterized by speech disruptions that result in the overt symptoms of sound and syllable repetitions and audible
and inaudible sound prolongations (Bloodstein & Bernstein Ratner, 2008). It is well documented that improvements in speech ﬂuency
occur when persons who stutter (PWS) speak while hearing delayed auditory feedback (DAF), frequency-altered auditory feedback
(FAF), masking noise, or the simultaneous presentation of a second speaker’s voice (unison or choral speech) (Ingham & Pakman,
1979; Kiefte & Armson, 2008; Macleod, Kalinowski, Stuart, & Armson, 1995; Martin & Haroldson, 1979; Martin, Johnson, Siegel, &

⁎

Corresponding author at: Department of Speech-Language Sciences, All India Institute of Speech and Hearing, Manasagangothri, Mysuru,

570006, India.

E-mail address: santoshm79@gmail.com (S. Maruthy).

https://doi.org/10.1016/j.jﬂudis.2018.09.002
Received 3 March 2018; Received in revised form 26 July 2018; Accepted 6 September 2018

Available online 08 September 2018
0094-730X/ © 2018 Elsevier Inc. All rights reserved.

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

Haroldson, 1985; Max, Caruso, & Vandevenne, 1997; Soderberg, 1969; Stuart, Kalinowski, Armson, Stenstrom, & Jones, 1996; Stuart,
Frazier, Kalinowski, & Vos, 2008). Among the diﬀerent ﬂuency-inducing conditions, when PWS indulge in choral reading either with
memorized passages or have to read prepared texts in close approximation with a second speaker, their stuttering behaviors decline
by almost 90–100% regardless of the degree of severity (Andrews et al., 1983; Ingham, 1984).

The studies related to the eﬀects of choral reading on dysﬂuent speech date back to the 1930′s. Johnson and Rosen (1937) studied
the eﬀect of diﬀerent ﬂuency-inducing conditions such as speaking slowly, speaking fast, whispering, speaking at low intensity,
speaking at high intensity, choral reading, etc., and the ﬁndings reported no stuttering during choral reading. Similar results were
reported by Barber (1939) who studied the eﬀect of 14 diﬀerent altered conditions (for example, two PWS and one typical individual
read with participant, one PWS reads same material with participant, one typical individual reads a diﬀerent passage from that of the
participant) on the speech ﬂuency of adults who stutter. Since then, many other studies have conﬁrmed a signiﬁcant decrease in
stuttering during choral reading when compared to solo reading (Andrews, Howie, Dozsa, & Guitar, 1982; Freeman & Armson, 1998;
Guntupalli, Kalinowski, Saltuklaroglu, & Nanjundeswaran, 2005; Howell & Powell, 1987; Ingham, Warner, Byrd, & Cotton, 2006;
Park & Logan, 2015; Rami, Kalinowski, Rastatter, Holbert, & Allen, 2005). Although consistently all the studies have reported that
there is a signiﬁcant reduction in stuttering frequency during choral reading, there is still no valid explanation for the same. In the
past, several hypotheses have been proposed to explain the underlying mechanism behind choral reading.

1.1. Hypotheses on choral reading

Multiple theories and explanations have been put forth in an attempt to understand the mechanism with which choral reading
successfully alleviates stuttering. Some of the explanations point out that during choral reading, PWS experiences a lack of re-
sponsibility during communication which in turn improves speech production (Eisenson & Wells, 1942). In Eisenson and Wells' study,
investigations about the inﬂuence of reduced load during communication were made by indulging the PWS in a choral reading task
with and without an audience. The results indicated that the group exposed to an audience performed poorer than the group without
an audience suggesting that the presence of the audience increased the communicative load on the participants causing a breakdown
in ﬂuency. Another explanation revolves around the psychological viewpoint and is based on the distraction hypothesis. This hy-
pothesis explains that the reduction in stuttering occurs as a result of distractions provided by the choral speech itself (Barber, 1939;
Bloodstein, 1995). Contradicting this, another explanation is that during choral reading PWS focus their attention on the act of
speaking and the increased focus of attention induces ﬂuency (De Nil, Kroll, Lafaille, & Houle, 2003; Kroll, De Nil, Kapur, & Houle,
1997).

On the other hand, Webster and Lubker (1968) mentioned that choral reading, rhythmic speech, masking noise, prolonged
speech, whispering, and delayed auditory feedback tend to reduce stuttering and improve ﬂuency in PWS because they provide
sensory stimulation which enables the PWS to produce speech that has little or no interference from the secondary signal. They
consider the external signal to override the interference that may be caused due to auditory feedback. Wingate (1969, 1970) in his
research has suggested that while reading in unison, the continuity of speech is achieved by emphasizing on vocalization during
choral reading which is triggered by the prompts one receives from the second speaker. The ﬁndings emphasized the changed
phonation in the speech of the person involved in choral reading. Another explanation revolved around the slower rate of speech
exhibited during choral reading (Wingate, 1976). However, few other studies which looked into changes in the rate of speech
reported contradictory ﬁndings. Two studies found no change in rate (Andrews et al., 1982; Park & Logan, 2015) whereas another
study reported that speech rate increased during choral reading when compared to solo reading (Ingham & Carroll, 1977). With
advances in research, the use of the terms ‘second speech signal’ (Andrews et al., 1982; Cherry & Sayers, 1956; Kalinowski,
Guntupalli, Stuart, & Saltuklaroglu, 2004) highlighted that the presence of a second speech signal with normal ﬂuency, that the
speaker pays attention to while reading in unison, results in a marked reduction in stuttering. Rami and Diederich (2005), supported a
claim made by Pattie and Knight (1944) that the external signal contributes as a pace-setting/ altering mechanism based on which the
PWS sets his or her speech rhythm to that of the other speaker. The imposition of a steady rhythm by the external speech seemed to
result in well-paced and slower speech in a PWS.

Kiefte and Armson (2008) by the previous studies highlighted that during a choral speech the subject has to keep pace with
another speaker and this inﬂuences a change in stuttering frequency. Thus, the discriminating feature of choral reading has been
identiﬁed as an intoning pattern or change in rhythm that inﬂuences one’s speech (Wingate, 1969). Therefore, the role of rhythm and
timing in speech and its eﬀects on dysﬂuent speech production can be questioned. Rami et al. (2005) and Guntupalli et al. (2005)
manipulated the temporal characteristics of choral signal (ﬁltering, time compressing and temporally expanding the signal) and
suggested that temporal characteristics are relevant for inducement of ﬂuency. Recently, Park and Logan (2015) conducted a study on
choral reading to understand how the intactness of temporal cues in speech inﬂuences ﬂuency in PWS. Their results refuted the
theories regarding temporal models, and they showed that ﬂuent speech was achieved even in conditions wherein the temporal
aspects of speech and prosody of the second speech signal were altered.

As stated, literature has provided various explanations when it comes to an understanding of the underlying cause of choral
reading and its ameliorative eﬀects. Although previous studies have investigated the role of temporal cues available on the choral
signal on the inducement of ﬂuency, there has been no published study that quantitatively compares the speech rhythm between solo
and choral reading conditions in PWS to support the claim that choral speech brings about alternations in speech because of a pace-
setting mechanism. Here, we hypothesize that one of the main factors for the inducement of ﬂuency during choral reading could be
that the speech rhythm of PWS is dictated by the speech of a normal speaker. To test this, we investigated (a) whether there is any
change in speech rhythm during choral reading when compared to the solo reading condition in adults who stutter, and (b) whether

48

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

there is any diﬀerence in speech rhythm between the solo reading of AWS and typical adults. Speech rhythm was measured using a
novel, automated, acoustic method called Envelope Modulation Spectrum (EMS).

1.2. Speech rhythm

Rhythmic speech has been deﬁned by Schane (1979) to have successively placed strong and weak components. The rhythm class
hypothesis by Pike (1945) and Abercrombie (1967) to classify languages based on their rhythm hypothesized that each language
belongs to one of the rhythmic patterns of speech: ‘stress-timed’ wherein the duration between successive stressed segments are said
to be equal; ‘syllable-timed’ wherein the successive syllables have the same duration and ‘mora-timed’ wherein the successive morae
are said to be nearly equal in duration and variability in terms of duration is low. Few methods to study changes in speech rhythm
have been developed in the past which include duration based metrics and interval based measures (Dellwo, 2006; Ling, Grabe, &
Nolan, 2000; Ramus, Nespor, & Mehler, 1999). One of the most popular measures developed to document speech rhythm is called the
Pairwise variability index (PVI) (Grabe & Low, 2002). PVI is a metric measured by calculating the variability in the duration of
vocalic and consonantal intervals in speech, and the scores are used to place a language in one of the rhythm classes. PVI has been
used to explore how eﬀectively it can be used as a tool to analyze the complexity of musical rhythms (Toussaint, 2012). Over the
years, PVI has helped to successfully identify the rhythm patterns in both normal and disordered speech.

1.3. Rhythm in disordered population

Some of the disorders on which studies on speech rhythm have been done are stuttering, learning disability, apraxia, aphasia, and
dysarthria. Most rhythm measures have been carried out using PVI and interval based metrics as they have been the most readily
available and convenient method of measuring rhythm. Dahmani, Selouani, O’Shaughnessy, Chetouani, and Doghmane, (2013) used
both PVI with raw and normalized scores in dysarthric speech. The results showed that these metrics could not be used as a reliable
measure to assess the degree of impairment in dysarthric speech and also concluded that classifying even those with mild impairment
is diﬃcult using these metrics. Ballard, Robin, McCabe, and McDonald, (2010) studied speech rhythm using PVI in a group of adults
with apraxia (AOS), aphasia, and controls. Although they obtained promising results indicating a signiﬁcant diﬀerence in the rhythm
of speech in the AOS group (PVI values being smaller) when compared to aphasia and controls, they concluded that PVI of vowel
duration might not be sensitive enough to identify the diﬀerences in speech rhythm in the AOS group. Maruthy, Venugopal, and
Parakh, (2017) used the rhythm metrics such as the PVI, and interval-based metrics such as variable coeﬃcients of vocalic intervals
(Varco V) and variable coeﬃcients of consonantal intervals (Varco C) among others, to study speech rhythm in Kannada speaking
adults who stutter (AWS). The ﬁndings suggested that interval based measures showed a signiﬁcant deviation in AWS when com-
pared to adults who do not stutter (AWNS). Greater PVI values obtained for AWS indicated that these individuals exhibit greater
variability in speech rhythm due to speech timing errors. Despite there being a handful of studies on the production of speech rhythm
most authors ﬁnd them to be unreliable measures in disordered speech. Some of the shortcomings of these measures are that they
were initially developed as a means to classify languages based on their rhythm, these measurements are carried out manually, and
despite the normalization done in PVI, the scores are strongly inﬂuenced by speaking rate (White & Mattys, 2007). Hence, to
overcome these drawbacks the use of an automated method to measure speech rhythm is warranted. The use of the Envelope
Modulation Spectra (EMS) is one such method that has been successfully used in both normal and disordered population (Drullman,
Festen, & Plomp, 1994; Greenberg, Arai, & Silipo, 1998).

1.4. Envelope Modulation Spectra (EMS)

Envelope Modulation Spectrum (EMS) is an automated representation of the slow amplitude modulations (up to 10 Hz) in a signal
(Liss, Legendre, & Lotto, 2010). It represents the power spectrum of the signal’s amplitude envelope and the amplitude variations
across frequencies. In other words, modulation here is a depiction of the energy distribution in amplitude ﬂuctuations across the
frequencies present in the sample. EMS is an acoustic measure that does not consider the linguistic content of the signal. It is
suggested that these temporal variations in the amplitude envelope correspond to the syllables in the speech sample. EMS can manage
the non-linguistic parts of speech such as pauses, noise, without altering the analysis and thus it is more suitable while analyzing
disordered speech (Liss et al., 2010). Also, EMS provides information regarding the rhythm of speech, regardless of the rate of speech
(Greenberg, Arai, & Grant, 2006; Houtgast & Steeneken, 1985; Leong & Goswami, 2014; Shannon, Zeng, Kamath, Wygonski, & Ekelid,
1995).

The initial use of EMS was to quantify the eﬀects of room acoustics on speech Steeneken and Houtgast (1980). Originally,
diﬀerences in the speaker’s fundamental frequency were considered to cue the rhythmic changes in one’s speech. However, more
recent studies have indicated that amplitude and duration related cues aid in better discrimination of rhythm-related information in
speech (Greenberg, 1999; Kochanski, Grabe, Coleman, & Rosner, 2005). Although several studies have utilized EMS to analyze
rhythm, it is not possible to identify exactly which frequency bands correspond to which rhythmic component in speech. However,
some researchers have been able to isolate relationships between the rhythm properties of the sample and the frequency bands. Tilsen
and Johnson (2008) recommended analyzing the 700 Hz to 1300 Hz region to determine the perceptual units of stress in English as
they could help to examine the vowel nuclei, bursts, voicing, and frication to understand rhythmic patterns in disordered speech.
Greenberg et al. (1998) showed that the intelligibility of speech might directly correlate with the integrity of the EMS amplitude in
the 3‐8 Hz region. However, the integrity of the measure does not get aﬀected even in unintelligible speech unlike in the PVI

49

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

Table 1
The six variables calculated from the EMS.

Peak Frequency
Peak Amplitude
Energy 3–6Hz
Energy 0–4 Hz
Energy 4–10 Hz
Energy ratio

Frequency in Hz of the highest peak
The amplitude of the highest peak
Average energy between 3–6 Hz normalized
Summed energy (normalized) below 4 Hz
Summed energy (normalized) above 4 Hz
The ratio of energy 0–4 Hz/energy 4–10 Hz

measures. The EMS has gained popularity because of its automated process of measuring temporal irregularities without segmen-
tation of syllables, removal of pauses or dysﬂuencies, and no linguistic dependency. It was also used by Liss et al. (2010) to dis-
criminate between dysarthria types using six parameters deﬁning rhythm (Peak frequency, Peak amplitude, Energy 3–6 Hz, Energy
below 40, Energy above 40 and Ratio of energy below and above 40). These six parameters were extracted for the full signal as well as
the seven-octave bands (center frequencies of 125 Hz, 250 Hz, 500 Hz, 1 kHz, 2 kHz, 4 kHz, and 8 kHz). Table 1 deﬁnes each of the six
variables obtained from the amplitude envelope of the speech sample.

The frequency at the peak with the largest amplitude is considered as the “peak frequency” of the speech signal, whereas, peak
amplitude is the amplitude of this peak normalized to the total energy in the spectrum (up to 10 Hz). These measures highlight the
dominant rate (of modulation in the signal) and the extent of this rate’s inﬂuence on the signal (Liss et al., 2010). The third variable is
the amount of normalized energy in the region of 3–6 Hz (E3–6). These rates capture the majority of syllable durations in normal
productions of English and Japanese (Arai & Greenberg, 1997). This region also includes the 4-Hz rate (250-ms period), which has
been considered the dominant rate for normal speech (Drullman et al., 1994; Houtgast & Steeneken, 1985). The upper cut oﬀ was
taken as 10 Hz (100-ms period) for the above four variables (instead of the entire power spectrum) because the focus is on the
suprasegmental variations in rhythm. The use of EMS in this study was based on the variables mentioned above and the parameters
used in the study done by Liss et al. (2010).

The focus of the current study was to investigate whether there are changes in the frequency of stuttering across two reading
conditions, solo and choral reading; changes in speech rate between conditions and to determine if there are changes in the speech
rhythm across the two conditions using the EMS. Further, we also compared the speech rhythm between the solo reading of AWS and
typical adults. The frequency of stuttering was calculated as percentage of syllables stuttered, rate of speech was measured by
dividing the number of syllables in an utterance by the duration of the utterance, and the rhythm was calculated using a MATLAB
program that derives the EMS variables, and these variables were compared between conditions to identify the most dominant
variable in PWS.

2. Method

2.1. Participants

Seventeen Kannada (a Dravidian language spoken in Karnataka state, India) speaking adults who stutter participated in the study.
All the participants were males. The participants were aged between 13 to 33 years (Mean = 21.05 years, SD = 5.21). A self-reporting
questionnaire was used to obtain the demographic details such as their native language, the age of onset of stuttering, handedness,
treatment-related history, presence or absence of any associated problems, and family history of stuttering. Based on the ques-
tionnaire, it was observed that none of the participants reported any history of audiological, psychological, neurological, or other
communication disorders. All the participants had their development of stuttering in early childhood. All the participants were right-
handed individuals. Further, none had taken any kind of speech therapy for their stuttering. Stuttering Severity Instrument for Adults
and Children-Fourth Edition (SSI-4; Riley, 2009) was administered to each participant before the initiation of the study. By calcu-
lating frequency, duration, and physical concomitant behaviors, the severity of stuttering was determined. Across the participants,
severity was found to range from mild to very severe (mild = 3; moderate = 6; severe = 6; very severe = 2). Behavioral pure tone
hearing testing at all octave frequencies from 250 to 8000 Hz revealed that all participants had bilateral hearing thresholds at or
below 25 dB HL. The participants provided their written consent to complete participation in the study. The study was approved by
the Ethical Committee of All India Institute of Speech and Hearing, Mysuru, India. The demographic details of the participants are
provided in Table 2. For the comparison purposes, we also included 14 Kannada-speaking typical adults. Their mean age was 26.64
years (S.D = 3.8, range = 22–33 years). All the typical adults did not have any history of audiological, psychological, or any com-
munication disorders.

2.2. Sentence stimuli

Forty-ﬁve meaningful Kannada sentences with an average length of eight words (ranging from 7 to 11 words) were framed. Few
sentences were constructed by translating English sentences from a study by Park and Logan (2015), and the rest by adapting and
appropriately editing sentences from Kannada books and newspapers. Five native speakers of Kannada rated the sentences based on
their familiarity using a 3-point rating scale ranging from not familiar, slightly familiar, and most familiar. Following the familiarity
ratings, twenty-two sentences rated as most familiar were accepted as the material for the solo reading and choral reading tasks.

50

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

Table 2
Individual participant information for adults who stutter (SSI score = Stuttering Severity Instrument 4th ed overall score). Handedness is based on
self-report. Hearing status was determined with pure tone behavioral testing at all octave frequencies from 250 to 8000 Hz for both ears separately
(when a speciﬁc threshold is listed for a given frequency, all other thresholds were ≤ 25 dB HL).

S.No

Age

Gender

Severity of stuttering

SSI score

Handedness

Hearing status

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.

23
25
23
24
33
20
28
18
17
16
16
19
15
24
19
13
25

Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male

Severe
Mild
Moderate
Moderate
Severe
Moderate
Severe
Moderate
Mild
Very severe
Very severe
Moderate
Severe
Severe
Mild
Severe
Moderate

32
20
27
28
33
26
33
23
21
41
44
25
35
34
17
31
26

Right
Right
Right
Right
Right
Right
Right
Right
Right
Right
Right
Right
Right
Right
Right
Right
Right

all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL
all ≤ 25 dB HL

These twenty-two sentences had similar prosodic patterns.

For the external speech signal used in the choral reading condition, a Kannada-speaking adult male with normal ﬂuency read the
sentences as naturally as possible, and a voice recording of the same was taken. The twenty-two sentences were read aloud into a
microphone placed at a distance of 15 cm, which was recorded using the PRAAT software (Boersma & Weenink, 2017). The recording
was conducted in a sound-attenuated booth. All the audio ﬁles were then saved in. WAV format. The recorded samples were analyzed
by the ﬁrst author to remove extraneous noises, intervals of silence and unnecessary pauses/ sounds at the beginning and end of the
sentence. These digital recordings were used as the choral speech stimuli in the experiment.

2.3. Procedure

As mentioned previously, the study included two conditions, solo reading and choral reading. In solo reading condition, to help
the participants familiarise themselves with the task and stimuli, each participant was asked to ﬁrst silently read all 22 sentences. The
sentences were typed in a 14-point Calibri font and saved as. bmp (image ﬁles), and inserted in a Microsoft PowerPoint ﬁle for
presentation, where each sentence appeared on screen individually after the press of a button controlled by the examiner. The stimuli
were presented using a Sony VAIO laptop kept at an approximate distance of 60 cm from the participants’ body. The participants were
instructed to read each sentence without the use of any ﬂuency enhancing techniques or change in their manner of speaking to avoid
reductions or inhibition of stuttering (Park & Logan, 2015). The presentation of the sentences was randomized for each participant.
Similar to AWS, the typical adults read the 22 sentences with natural stress and intonation only during the solo reading condition.
For the choral reading condition, the audio recorded sentences read by the normally ﬂuent speaker served as the second speech
signal, and they were inserted as audio ﬁles along with a written form of the sentence in a Microsoft PowerPoint ﬁle. Each sentence
appeared for 6 s (i.e., the average duration of the audio ﬁles) with an inter-stimulus interval of 3 s. Between two consecutive sen-
tences, a countdown of 3 s appeared to prepare the participant for the appearance of the following sentence. The recorded voice (the
second speech signal) was played back to the participant using headphones (Tag- 100 stereo headphones) wherein the sound levels of
the headphones’ output was adjusted before the presentation of the stimuli to a level that was considered comfortable to the patient,
and was still audible (Kiefte & Armson, 2008). The participants were ﬁrst given a trial to prepare them for the task. Participants were
asked to read along with the recorded voice when they began to hear the second speaker and were instructed to keep pace with the
speaker. They were asked to attempt to read the same words at the same time and to read every word if possible (Ingham & Pakman,
1979). In the event of being unable to keep up with the second speaker, the participants were asked to skip to the part being heard
and continue reading. The participants' reading sample in both the conditions was recorded and saved in WAV format at a rate of
44,100 Hz.

2.4. Data analysis

The analysis of the speech samples was conducted in step by step process in the following ways:

2.4.1. Frequency of stuttering

The ﬁrst author listened to the recorded sentences obtained from the participants from both solo reading and choral reading
conditions and orthographically transcribed them. Each syllable was analyzed for the presence of dysﬂuencies. Part-word repetitions,
monosyllable whole word repetitions, broken words, and prolongations were marked according to the classiﬁcation by Conture

51

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

Fig. 1. a) Amplitude envelope of the waveform; b) speech waveform of the sentence read by one participant.

(1990). The number of syllables stuttered per sentence was tallied and averaged across 22 sentences to derive the total percent of
syllables stuttered (%SS) in the solo reading and choral reading conditions.

2.4.2. Rate of speech

The rate of speech of each participant was measured separately for both solo reading and choral reading conditions. The analysis
of each sentence was carried out in PRAAT software, wherein the pauses that followed dysﬂuencies were manually deleted. To
calculate the rate of speech the number of syllables in the sentence was divided by duration taken to utter the sentence (i.e., after the
pauses have been deleted) (Park & Logan, 2015). These values were averaged across twenty-two sentences in each condition to arrive
at the rate of speech for each participant.

2.4.3. Analysis of rhythm

The study attempted to calculate modulation spectra for amplitude envelopes extracted from the full signal and seven-octave
bands (center frequencies of 125, 250, 500, 1000, 2000, 4000, and 8000 Hz). From each of these eight modulation spectra, six
variables, namely, Peak frequency, Peak amplitude, Energy 3–6 Hz, Energy 0–4 Hz, Energy 4–10 Hz and Energy ratio were computed.
These yielded a total of 48 variables (8 envelopes x 6 metrics) which can be calculated from any signal using a fully automated
program developed in MATLAB (Mathworks). Using a MATLAB program (Liss et al., 2010) each participant’s recording of the 44
sentences (22-solo reading and 22- choral reading) were processed, wherein the MATLAB code generated all 48 variables for each
sentence in both conditions. To obtain these variables, the speech signal was ﬁltered into its constituent octave bands using a pass-
band eighth-order Chebyshev digital ﬁlters, following which the amplitude envelope of the entire signal was extracted (Fig. 1 a) by
half-wave rectiﬁcation, and ﬁltered using a 30-Hz low-pass fourth-order Butterworth ﬁlter. It is then down-sampled (to 80 Hz, mean
subtracted). The power spectrum of the down-sampled envelope is calculated using a 512-point fast Fourier transform with a Tukey
window and converted to decibels for frequencies up to 10 Hz (normalized to maximum autocorrelation). The result is the six EMS
metrics which are computed from the resulting spectrum for each band and also the full signal resulting in a total of 8 frequency
bands. For each speaker, the average values obtained for the twenty-two sentences in both conditions were calculated across eight
envelopes for six variables (totally yielding 48 variables for each subject in solo and choral reading conditions).

2.5. Intra-judge and inter-judge reliability of stuttering frequency and rate of speech

Intra-judge and inter-judge reliability measures were obtained for 20 percent of the recorded samples. The ﬁrst examiner re-
analyzed the data and identiﬁed dysﬂuencies and measured rate of speech for intra-judge reliability. For the inter-judge reliability
another Speech Language Pathologist, with a minimum experience of ﬁve years in dysﬂuency analysis, analyzed the samples and
Cronbach’s alpha value was calculated for both intra-judge and inter-judge reliability. The Cronbach’s alpha value was found to be
0.99 for intra-judge reliability and 0.98 for inter-judge reliability indicating good consistency as the values are closer to 1. Similarly,
ten percent of the samples were used for reliability measures for the rate of speech in the same manner described above. Cronbach’s
alpha value was computed, and inter-judge and intra-judge reliability were found to be 0.97 and 0.99 respectively thus indicating
good reliability/consistency across rate of speech measurements.

2.6. Statistical analyses

All the statistical analyses were carried out using the IBM SPSS statistics software (version 20.0). The Shapiro-Wilk test (Field,
2005) of normality revealed that the data were normally distributed (P > 0.05) and hence parametric tests were done. The stuttering
frequency and rate of speech were compared between the two reading conditions using the paired sample t-test. For the analysis of
rhythm in both conditions, six dependent variables were taken into consideration, namely, Peak frequency, Peak amplitude, Energy
3–6 Hz, Energy 0–4 Hz, Energy 4–10 Hz, and Energy ratio across 8-octave bands. Two-way repeated measures ANOVA (with the
condition and octave bands as within-subject factors) was done to study the main eﬀects of the condition, octave bands, and in-
teraction between condition and octave bands. Further, to compare between the solo reading of AWS and typical adults multivariate
ANOVA (MANOVA) was done. The statistical alpha corrected p-value was considered to be p = 0.05, and the eﬀect sizes were
reported as partial eta square for ANOVA.

52

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

Fig. 2. Comparison of mean percentage of syllables stuttered (%SS) between solo reading and choral reading conditions. Error bars indicate
standard deviation values.

3. Results

3.1. Frequency of stuttering

The mean values of percentage of syllables stuttered (%SS) were obtained for each participant for both solo and choral reading
conditions. The ﬁndings revealed a signiﬁcant decrease [t (33) = 5.65; p < 0.01] in mean %SS during the choral reading (3.38%)
when compared to the solo reading (9.33%). Fig. 2 shows a comparison of the mean percentage of syllables stuttered (%SS) between
solo reading and choral reading conditions. In Fig. 2, %SS is on the Y-axis and the solo reading and choral reading conditions on the
X-axis. Error bars indicate standard deviation values.

3.2. Rate of speech

The rate of speech was calculated regarding syllables per second. The rate of speech decreased from solo reading condition to
choral reading condition. The paired t-test was done to determine whether there was a statistically signiﬁcant diﬀerence between the
rates of speech of both conditions. The results suggested a statistically signiﬁcant decrease in the rate of speech during choral reading
when compared to solo reading (t (33) = 23.66, p < 0.01). Fig. 3 shows the comparison of mean syllables per second between solo
reading and choral reading conditions. In Fig. 3, syllables per second are on the Y-axis and the solo reading and choral reading
conditions on the X-axis. Error bars indicate standard deviation values.

3.3. Analysis of rhythm

The descriptive data (Mean and S.D) for six variables, namely, Peak frequency, Peak amplitude, Energy 3–6 Hz, Energy 0–4 Hz,

Fig. 3. Comparison of rate of speech (syllables per second) between solo reading and choral reading conditions. Error bars indicate standard
deviation values.

53

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

Table 3
Means and standard deviations for all six EMS variables (peak frequency, peak amplitude, Energy 3–6 Hz, Energy 0–4 Hz, Energy 4–10 Hz, Energy
Ratio) across eight frequency bands (Full band, 125 Hz, 250 Hz, 500 Hz, 1 kHz, 2 kHz, 4 kHz, and 8 kHz) for both solo reading and choral reading
conditions for AWS and for solo reading condition in typical adults.

Variable

Octave band

Solo reading (AWS)

Choral reading(AWS)

Solo reading (typical adults)

Mean

S.D

Mean

S.D

Mean

Peak frequency

Peak Amplitude

Energy 3-6 Hz

Energy 0-4 Hz

Energy 4-10 Hz

Energy Ratio

Full band
125
250
500
1 k
2 k
4 k
8 k
Full band
125
250
500
1 k
2 k
4 k
8 k
Full band
125
250
500
1 k
2 k
4 k
8 k
Full band
125
250
500
1 k
2 k
4 k
8 k
Full band
125
250
500
1 k
2 k
4 k
8 k
Full band
125
250
500
1 k
2 k
4 k
8 k

0.59
0.53
0.54
0.68
0.65
0.66
0.64
0.73
1.54
2.09
1.76
1.60
1.75
1.71
2.12
2.84
0.30
0.30
0.30
0.30
0.31
0.43
0.31
0.28
0.45
0.56
0.49
0.44
0.48
0.60
0.62
0.17
0.54
0.43
0.50
0.55
0.51
0.39
0.37
0.82
0.82
1.27
1.02
0.81
0.95
1.09
0.34
1.63

0.26
0.21
0.21
0.33
0.25
0.24
0.27
0.36
0.14
1.36
0.47
0.19
0.26
0.94
1.10
1.76
< 0.00
0.01
< 0.00
< 0.00
< 0.00
0.51
0.02
0.21
0.01
0.09
0.03
0.01
0.03
0.46
0.58
1.15
0.01
0.09
0.03
0.01
0.03
0.46
0.58
1.15
0.05
0.42
0.19
0.06
0.14
0.42
2.72
2.42

1.21
1.02
0.92
1.40
1.22
1.29
1.27
1.40
1.33
2.03
1.46
1.34
1.44
1.49
1.63
1.43
0.30
0.31
0.31
0.30
0.31
0.30
0.30
0.30
0.42
0.50
0.45
0.41
0.44
0.44
0.45
0.40
0.57
0.49
0.54
0.57
0.57
0.55
0.54
0.59
0.74
1.01
0.84
0.73
0.80
0.90
0.84
1.03

0.50
0.29
0.20
0.59
0.30
0.39
0.36
0.34
0.03
0.91
0.26
0.04
0.05
0.07
0.15
1.49
< 0.00
< 0.00
< 0.00
< 0.00
< 0.00
< 0.00
< 0.00
0.04
< 0.00
0.03
0.01
0.02
0.01
< 0.00
0.01
0.31
< 0.00
0.03
0.01
< 0.00
0.07
< 0.00
0.01
0.31
0.02
0.20
0.03
0.01
0.04
0.47
0.06
0.22

0.73
1.37
0.30
0.43
0.56
0.76
0.71
2.13
0.30
0.53
0.46
1.18
0.73
1.63
0.30
0.46
0.53
0.88
1.29
1.38
0.30
0.42
0.57
0.75
1.10
1.45
0.31
0.45
0.54
0.83
1.02
1.49
0.30
0.44
0.55
0.81
1.02
1.81
0.30
0.48
0.51
0.98
1.14
1.80
0.31
0.49
0.50
1.03

S.D

0.30
0.60
< 0.00
< 0.00
< 0.00
0.02
0.35
0.48
0.01
0.06
0.06
0.45
0.27
0.11
< 0.00
0.01
0.01
0.05
0.60
0.05
< 0.00
< 0.00
< 0.00
0.02
0.37
0.06
< 0.00
0.01
0.01
0.04
0.37
0.07
< 0.00
0.01
0.01
0.04
0.44
0.32
< 0.00
0.04
0.04
0.28
0.22
0.92
0.01
0.08
0.08
0.18

Energy 4–10 Hz and Energy ratio across 8-octave bands in both reading conditions in AWS and during solo reading for typical adults
are given in Table 3. Table 4 shows F values, uncorrected p values, and partial eta-squared eﬀect sizes (ηp
2) for all inferential statistical
analyses for all variables (peak frequency, peak amplitude, Energy 3–6 Hz, Energy 0–4 Hz, Energy 4–10 Hz, Energy Ratio) between
conditions in AWS. Table 5 shows F values, uncorrected p values, and partial eta-squared eﬀect sizes (ηp
2) for all inferential statistical
analyses for all variables (peak frequency, peak amplitude, Energy 3–6 Hz, Energy 0–4 Hz, Energy 4–10 Hz, Energy Ratio) between
AWS and typical adults for solo reading condition.

The mean peak frequency values were found to be higher in the choral reading condition when compared to solo reading,
however the results of the mean peak amplitude were vice versa. Comparable results were obtained between two reading conditions
for the remaining four variables (Energy 3–6 Hz, Energy 0–4 Hz, Energy 4–10 Hz and Energy ratio). Repeated measures ANOVA
showed statistically signiﬁcant (p < 0.05) main eﬀect for condition and octave bands for two variables only, namely Peak frequency
and Peak amplitude. Further, a signiﬁcant interaction eﬀect between condition and octave bands (p < 0.05) was established only for
Peak amplitude (Table 4). Further, paired t tests were done to compare between two conditions across eight octave bands. The results

54

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

Table 4
F values, uncorrected p values, and partial eta-squared eﬀect sizes (ηp
2) for all inferential statistical analyses for all variables between conditions in
AWS (peak frequency, peak amplitude, Energy 3–6 Hz, Energy 0–4 Hz, Energy 4–10 Hz, Energy Ratio). Condition: Solo Reading vs. Choral Reading.
Octave band: Full band, 125 Hz, 250 Hz, 500 Hz, 1 kHz, 2 kHz, 4 kHz, and 8 kHz. *p ≤ 0.05, ** p ≤ 0.001.

Factor

Condition

Octave band

Condition x Octave band

Variables

df, F

Peak frequency
Peak Amplitude
Energy 3-6 Hz
Energy 0-4 Hz
Energy 4-10 Hz
Energy Ratio
Peak frequency
Peak amplitude
Energy 3-6 Hz
Energy 0-4 Hz
Energy 4- 10 Hz
Energy ratio
Peak frequency
Peak amplitude
Energy 3-6 Hz
Energy 0-4 Hz
Energy 4-10 Hz
Energy ratio

F(1,16) = 90.6
F(1,16) = 14.0
F(1,16) = 0.3
F(1,16) = 0.8
F(1,16) = 0.9
F(1,16) = 3.9
F(7,112) = 7.6
F(7,112) = 4.1
F(7,112) = 0.9
F(7,112) = 1.8
F(7,112) = 1.7
F(7,112) = 1.8
F(7,112) = 1.7
F(7,112) = 2.2
F(7,112) = 0.8
F(7,112) = 0.9
F(7,112) = 0.9
F(7,112) = 0.8

Sig.

0.00**
0.00*
0.54
0.36
0.34
0.06
0.00**
0.00**
0.50
0.09
0.09
0.07
0.10
0.03*
0.51
0.45
0.44
0.56

η 2p

0.85
0.46
–
–
–
–

0.32
0.20
–
–
–
–
–

0.12
–
–
–
–

suggested statistical signiﬁcant diﬀerence between conditions for full band, 250 Hz, 1 kHz and 8 kHz octave band conditions. {full
band[t(16) = 6.87, p < 0.01], 125 Hz [t (16) = 0.17, p = 0.86], 250 Hz [t (16) = 2.66, p < 0.01], 500 Hz [t (16) = 1.18,
p = 0.25], 1 kHz [t (16) = 5.26, p < 0.01], 2 kHz [t (16) = 0.97, p = 0.34], 4 kHz [t (16) = 1.87, p = 0.08], 8 kHz [t (16) = 2.20,
p = 0.04]. Further, repeated measures ANOVA was done to compare octave bands separately in each condition. The results of
ANOVA suggested statistically signiﬁcant diﬀerence between octave bands in both the reading conditions {solo reading [F (7,
2 = 0.12]}. The Comparison of speech
112) = 3.49, p < 0.01, ηp
rhythm between AWS and typical adults during solo reading also suggested signiﬁcant main eﬀect between two groups for all the
2 = 0.97], peak amplitude [F(8,22) = 179.6, p < 0.01,
predictor variables {peak frequency [F (8,22) = 101.2, p < 0.01, ηp
2 = 0.98], Energy 3–6 Hz [F (8,22) = 6023.2, p < 0.01, ηp
2 = 0.98],
ηp
Energy 4–10 Hz [F (8,22) = 2185.0, p < 0.01, ηp
2 = 0.94]}. Further, for
all the predictor variables in at least 4 octave bands there was signiﬁcant diﬀerence (p < 0.05) between two groups (Table 5).

2 = 0.17], choral reading condition [F (7, 112) = 2.23, p = 0.03, ηp

2 = 1.00], Energy 0–4 Hz [F (8,22) = 251.4, p < 0.01, ηp

2 = 0.99], and Energy Ratio [F (8,22) = 46.1, p < 0.01, ηp

4. Discussion

The objectives of this study were to compare the solo reading and choral reading conditions in Kannada speaking adults who
stutter concerning a) stuttering frequency, b) speech rate, and c) speech rhythm. Also, we compared the solo reading samples of AWS
and typical adults about speech rhythm. Speech rhythm was measured using a novel, automatized approach, i.e., envelope mod-
ulation spectra (EMS). We hypothesized that one of the main factors for the inducement of ﬂuency during choral reading could be
that the speech rhythm of AWS is dictated by the speech of a normal speaker. The results revealed several points of interest.

4.1. Frequency of stuttering

First, results showed a signiﬁcant reduction in the percentage of syllables stuttered in choral reading condition when compared to
the solo reading condition. The results of this study corroborated with the ﬁndings of the multiple studies done on choral reading
(Andrews et al., 1983; Freeman & Armson, 1998; Guntupalli et al., 2005; Howell & Powell, 1987; Ingham & Carroll, 1977; Ingham &
Pakman, 1979; Kiefte & Armson, 2008; Park & Logan, 2015; Rami et al., 2005; Wingate, 1976). Choral speech is a condition where
one or more individuals read matching texts aloud, together. The eﬀect it has on stuttering has been highly consistent across groups of
PWS (Barber, 1939; Cherry & Sayers, 1956; Johnson & Rosen, 1937; Pattie & Knight, 1944) and in individual studies as well (Andrews
et al., 1982; Freeman & Armson, 1998). Its eﬀects have also been described as dramatic and as observed the reduction in stuttering
occurs immediately. Thus the ﬁrst conclusion which can be drawn from this work is that choral reading signiﬁcantly reduces stut-
tering even in Kannada speaking AWS.

4.2. Rate of speech

Second, a signiﬁcant reduction in the rate of speech from solo reading to choral reading condition was found. Current results do
not support the ﬁndings of previous studies where they compared the rate of speech between two reading conditions (Andrews et al.,
1982; Ingham & Carroll, 1977; Park & Logan, 2015). As mentioned before, Andrews et al. (1982) and Park and Logan (2015) found no
signiﬁcant changes in speech rate between solo reading and choral reading conditions, whereas Ingham and Carroll (1977) found an

55

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

Table 5
F values, uncorrected p values, and partial eta-squared eﬀect sizes (ηp
2) for all inferential statistical analyses for all variables (peak frequency, peak
amplitude, Energy 3–6 Hz, Energy 0–4 Hz, Energy 4–10 Hz, Energy Ratio) between AWS versus typical adults during solo reading. *p ≤ 0.05, **
p ≤ 0.001.

Variable

Peak frequency

Peak amplitude

Energy 3-6 Hz

Energy 0-4 Hz

Energy 4-10 Hz

Energy ratio

Octave band

df, F

Full band
125
250
500
1 kHz
2 kHz
4 kHz
8 kHz
Full band
125
250
500
1 kHz
2 kHz
4 kHz
8 kHz
Full band
125
250
500
1 kHz
2 kHz
4 kHz
8 kHz
Full band
125
250
500
1 kHz
2 kHz
4 kHz
8 kHz
Full band
125
250
500
1 kHz
2 kHz
4 kHz
8 kHz
Full band
125
250
500
1 kHz
2 kHz
4 kHz
8 kHz

F(1,29) = 2.0
F(1,29) = 200.6
F(1,29) = 17.0
F(1,29) = 7.6
F(1,29) = 1.5
F(1,29) = 2.4
F(1,29) = 0.3
F (1,29) = 82.6
F(1,29) = 993.4
F(1,29) = 18.3
F(1,29) = 102.3
F(1,29) = 11.9
F(1,29) = 110.6
F(1,29) = 0.1
F(1,29) = 37.5
F (1,29) = 25.3
F(1,29) = 3159.2
F(1,29) = 1545.1
F(1,29) = 47.1
F(1,29) = 5710.4
F(1,29) = 8.1
F(1,29) = 0.0
F(1,29) = 1159.4
F (1,29) = 66.5
F(1,29) = 52.1
F(1,29) = 914.9
F(1,29) = 403.2
F(1,29) = 0.5
F(1,29) = 41.1
F(1,29) = 3.2
F (1,29) = 4.7
F (1,29) = 18.0
F(1,29) = 2516.1
F(1,29) = 0.1
F(1,29) = 24.7
F(1,29) = 396.9
F(1,29) = 22.3
F(1,29) = 93.7
F (1,29) = 0.1
F (1,29) = 1.2
F(1,29) = 251.5
F(1,29) = 4.6
F(1,29) = 2.6
F(1,29) = 19.0
F(1,29) = 249.8
F(1,29) = 26.7
F (1,29) = 0.0
F (1,29) = 0.8

Sig.

0.16
0.00**
0.00**
0.01*
0.22
0.12
0.53
0.00**
0.00**
0.00**
0.00**
0.00**
0.00**
0.73
0.00**
0.00**
0.00**
0.00**
0.00**
0.00**
0.00**
0.98
0.00**
0.00**
0.00**
0.00**
0.00**
0.48
0.00**
0.08
0.03*
0.00**
0.00**
0.68
0.00**
0.00**
0.00**
0.00**
0.67
0.28
0.00**
0.04*
0.11
0.00**
0.00**
0.00**
0.83
0.36

η 2p

–

0.87
0.37
0.20
–
–
–

0.74
0.97
0.38
0.77
0.29
0.79
–

0.56
0.46
0.99
0.98
0.61
0.99
0.22
–

0.97
0.69
0.64
0.96
0.93
–

0.58
0.10
0.14
0.38
0.98
–

0.46
0.93
0.43
0.76
–
–

0.89
0.13
–

0.39
0.89
0.48
–
–

increased rate of speech in choral reading than the solo reading condition. The diﬀerences between current ﬁndings and previous
studies could be due to diﬀerences in the linguistic (syllabic) and rhythmic structure of the languages. While all the three previous
studies were done in English which is a morpho-phonemic language and which has stress-timed rhythm, Kannada is an alphasyllabary
language (simple CVCV syllabic structure) and has mora-timed rhythm (Savithri, Goswami, & Kedarnath, 2007; White & Mattys,
2007). This diﬀerence in the syllabic and rhythmic structure may be the reason for changes in speech rate. Overall, the second
conclusion which can be drawn from the current work is that in Kannada speaking AWS there is a signiﬁcant reduction in the rate of
reading in choral reading when compared to the solo reading condition. This might be one of the reasons for the decrease in the
stuttered syllables. However, further studies need to be done to corroborate the current ﬁndings. Further, it also needs to be in-
vestigated to see whether the decrease in stuttering during choral reading in Kannada speakers also occurs when the rate of speech is
kept unchanged. This can be taken up by asking the normal speaker by providing the second (choral) speech signal to read at faster
rates.

56

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

4.3. Envelope Modulation Spectral (EMS) analyses of speech rhythm

To fulﬁll the third aim of the study, a comparison of speech rhythm was done between the two reading conditions in AWS using
Envelope Modulation Spectra (EMS). Further, we also compared the solo reading samples of AWS with typical adults to test the
hypothesis whether the decrease in stuttering during choral reading is because the speech rhythm of AWS is dictated by the speech of
a normal speaker. As mentioned previously EMS is a method of measuring the amplitude variations across multiple frequencies in a
speech sample. The EMS is the depiction of the slowly varying amplitude changes that occur within a signal. These amplitude
modulations at diﬀerent frequency regions are a complex representation of speech rhythm and provide information about diﬀerent
aspects of speech production such as rhythmic patterns due to vowel nuclei, voicing of speech sounds, burst duration, and frication
(Liss et al., 2010). Twenty-two sentences were recorded from each AWS participant during both the reading conditions. From these
recorded sentences, the amplitude envelope modulation spectra were extracted across eight frequencies. The modulation spectra
from these bands were used to obtain six variables: Peak frequency, Peak amplitude, Energy 3–6 Hz, Energy 0–4 Hz, Energy 4–10 Hz
and Energy ratio.

In the current study, the results of peak frequency and peak amplitude measures showed considerable changes between both the
reading conditions. However, the other variables failed to demonstrate a signiﬁcant eﬀect of conditions. The peak frequency is the
frequency of the peak with the largest amplitude, and peak amplitude is the amplitude of this peak normalized to the total energy in
the spectrum (up to 10 Hz). These measures indicate the dominant rate (of modulation in the signal) and how dominant it is,
respectively (Liss et al., 2010). Thus, based on the methods used here, signiﬁcant diﬀerences observed between both the reading
conditions for two predictor variables strongly suggest that there is a signiﬁcant alteration at least in some of the aspects of the speech
rhythm during the choral reading condition when compared to the solo reading condition. And this alteration in the speech rhythm
could be one of the major factors for inducing ﬂuency during choral reading condition. This statement was further supported by our
results where we found a signiﬁcant diﬀerence between AWS and typical adults during solo reading for all the predictor variables.
Current results support our hypothesis that the speech rhythm of AWS is dictated by the speech of the normal speaker.

As suggested previously, PWS may have deﬁcits in their ability to generate regular rhythmic speech gestures at the sentence level
(Maruthy et al., 2017). During choral reading, the external speech stimuli may behave as a pacesetter for the PWS. PWS possibly
indulge in some manipulations, concerning the timing and temporal patterning of stressed and unstressed syllables contributing to
the prosodic aspects in one’s speech during choral reading. Thus, it is possible that the synchronization of speech between the PWS
and the normal reader enhances ﬂuency by altering the disrupted rhythm. Alterations in the frequency and amplitude of speech in a
PWS indulging in choral reading might suggest that modulating these aspects in one’s speech or being in tune with an external model
that rectiﬁes the timing asynchrony in these individuals leads to perfectly ﬂuent speech.

Evidence for the afore-mentioned hypothesis can be obtained from the variable syllable stress model (V model) or syllable
initiation theory (Packman, Onlsow, & Menzies, 2000; Packman, Code, & Onslow, 2007). It is suggested that an individual with
stuttering is unable to establish the ‘strong-weak’ pattern of rhythm which is typically seen in speech, due to an underlying deﬁcit in
the speech motor system (Packman et al., 2007). Consequently, rehabilitation with prolonged speech, syllable-timed speech, or
rhythmic speech has been eﬀective in reducing stuttering because they alter the speech rhythm. Researchers explain that these
techniques help PWS reallocate their resources to speak in accordance with rhythmic beat (in case of syllable-timed speech) or
reducing the variability in duration of syllables (in case of prolonged speech) (Alford & Ingham, 1969; Andrews & Harris, 1964;
Coppola & Yairi, 1982; Trajkovski, Andrews, O’Brian, Onslow, & Packman, 2006; Trajkovski et al., 2009). Similarly, the current study
highlights the use of secondary signals like choral reading and how the use of the second speech signal helps alter the speech timing
aspects by altering the speech rate and rhythm.

The deﬁcit in the generation of rhythmic patterns may be because of deﬁciencies in the neural resources which are involved in the
internal timing of syllables as well. Evidence from neuroimaging studies suggest that areas which are found to play an important role
in rhythmic movement timing are a supplementary motor area (SMA), left premotor cortex (PMC), and insula (Grahn & McAuley,
2009; Halsband, Ito, Tanji, & Freund, 1993). Evidence from structural and functional imaging studies also suggests that there is
aberrant activity in the above-mentioned areas in individuals who stutter (Brown, Ingham, Ingham, Laird, & Fox, 2005; Chang,
Horwitz, Ostuni, Reynolds, & Ludlow, 2011; Fox et al., 2000). Given that PWS in the present study had changes in speech rhythm
between two reading conditions, their speech rhythm signiﬁcantly varied compared to typical adults, and previous research suggests
a role of these areas for rhythmic speech timing, it is possible that abnormal motor circuits of these areas might be responsible for
abnormal rhythm and choral reading may be changing the activity of these areas.

The evidence is available for this proposition from the past research. Wu et al. (1995), conducted one of the initial studies
concerning choral reading and the neural substrates of stuttering. The persons with severe developmental stuttering were given two
tasks, one of reading alone (solo) and the other of reading in unison (choral). A signiﬁcant decrease in the regional glucose meta-
bolism in Broca's area, Wernicke's area, and frontal lobe were noted in the solo reading condition as compared to the choral reading
condition which was also observed to be free of stuttering events. Lower levels of activity were observed in the left caudate nucleus
(in the basal ganglia) during solo reading and choral reading conditions when compared to the normal subjects. Falk, Müller, and
Dalla Bella, (2015), in their study, highlighted that the stuttering symptoms are eradicated or reduced when the speech production of
PWS is paced by an externally provided synchronous tone sequence which is either in pace with another speaker or with a metronome
or synced with the speech of another person like in choral reading and shadowed speech. The ﬂuency induced by externally provided
rhythm cues has been observed to result in a normalization of hyper- and hypo-activation of neural circuitry that controls temporal
processing and initiation of movements namely, the basal ganglia, SMA, and the cerebellum (Toyomura, Fujii, & Kuriki, 2011). It is
also possible that a cerebellar mechanism which focuses on multimodal sensory-motor integration is accountable for the voluntary

57

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

control of timing aspects which inﬂuences some rhythmic events in PWS. Thus, the third conclusion which can be drawn from the
current study is that when compared to solo reading during choral reading there is a signiﬁcant alteration in the some of the aspects
of the speech rhythm.

In conclusion, the current study aimed at explaining the induced ﬂuency in PWS during choral reading. Firstly, it was observed
that choral reading is successful in marked reductions in stuttering frequency even in Kannada speaking AWS. Secondly, the choral
reading had a slower rate of speech compared to solo reading indicating changes in the duration of all segments in the sample. Lastly,
the use of EMS to quantify speech rhythm in solo and choral reading revealed signiﬁcant changes in peak frequency and peak
amplitude predictor variables in the amplitude envelope, highlighting a change in the rhythm type during the choral reading con-
dition. Further, the signiﬁcant diﬀerence noted between two groups for all predictor variables during solo reading highlights that
AWS attempt to correct their disrupted rhythm mechanism by synchronizing with the correct mechanism of the external speaker in
choral reading. Future research in this ﬁeld is warranted to study the eﬀects of the “second speech signal” in PWS and whether it can
be relied upon during stuttering intervention. Further, it is important to conduct EMS analysis under two diﬀerent choral reading
conditions that signiﬁcantly diﬀer in their speech rhythm parameters.

Declaration of conﬂict of interest

Authors report no conﬂict of interest.

References

Abercrombie, D. (1967). Elements of general phonetics, Vol. 203. Edinburgh: Edinburgh University Press.
Alford, J., & Ingham, R. J. (1969). The application of a token reinforcement system to the treatment of stuttering in children. Journal of the Australian College of Speech

Therapists, 19(2), 53–57. https://doi.org/10.3109/asl1.1969.19.issue-2.05.

Andrews, G., & Harris, M. (1964). The syndrome of stuttering. Oxford, England: Spastics Society Medical Education.
Andrews, G., Hoddinott, S., Craig, A., Howie, P., Feyer, A. M., & Neilson, M. (1983). Stuttering: A review of research ﬁndings and theories circa 1982. The Journal of

Speech and Hearing Disorders, 48(3), 226–246. https://doi.org/10.1044/jshd.4803.226.

Andrews, G., Howie, P. M., Dozsa, M., & Guitar, B. E. (1982). Stuttering: Speech pattern characteristics under ﬂuency-inducing conditions. Journal of Speech Language

and Hearing Research, 25, 208–216. https://doi.org/10.1044/jshr.2502.208.

Arai, T., & Greenberg, S. (1997). The temporal properties of Japanese are similar to those of English. Proceedings of 5th European Conference on Speech Communication, 2,

1011–1014.

Ballard, K. J., Robin, D. A., McCabe, P., & McDonald, J. (2010). A treatment for dysprosody in childhood apraxia of speech. Journal of Speech Language and Hearing

Research, 53(5), 1227–1245. https://doi.org/10.1044/1092-4388(2010/09-0130).

Barber, V. (1939). Studies in the psychology of stuttering: XV. Chorus reading as a distraction in stuttering. The Journal of Speech Disorders, 4(4), 371–383. https://doi.

org/10.1044/jshd.0404.371.

Bloodstein, O. (1995). A handbook on stuttering. San Diego, CA: Singular Publishing Group.
Bloodstein, O., & Bernstein Ratner, N. (2008). A handbook on stuttering. New York: Delmar.
Boersma, P., & Weenink, D. (2017). Praat: Doing phonetics by computer [Computer program]. Version 6.0.36. retrieved 11 November 2017 fromhttp://www.praat.org/.
Brown, S., Ingham, R. J., Ingham, J. C., Laird, A. R., & Fox, P. T. (2005). Stuttered and ﬂuent speech production: An ALE meta‐analysis of functional neuroimaging

studies. Human Brain Mapping, 25(1), 105–117. https://doi.org/10.1002/hbm.20140.

Chang, S. E., Horwitz, B., Ostuni, J., Reynolds, R., & Ludlow, C. L. (2011). Evidence of left inferior frontal–Premotor structural and functional connectivity deﬁcits in

adults who stutter. Cerebral Cortex, 21(11), 2507–2518. https://doi.org/10.1093/cercor/bhr028.

Cherry, C., & Sayers, B. (1956). Experiments upon the total inhibition of stammering by external control, and some clinical results. Journal of Psychosomatic Research, 1,

233–246. https://doi.org/10.1016/0022-3999(56)90001-0.

Conture, E. G. (1990). Stuttering (2nd ed). Englewood cliﬀs, NJ: Prentice-Hall.
Coppola, V. A., & Yairi, E. (1982). Rhythmic speech training with preschool stuttering children: An experimental study. Journal of Fluency Disorders, 7(4), 447–457.

https://doi.org/10.1016/0094-730X(82)90020-1.

Dahmani, H., Selouani, S.-A., O’Shaughnessy, D., Chetouani, M., & Doghmane, N. (2013). Assessment of dysarthric speech through rhythmic metrics. Journal of King

Saud University - Computer and Information Sciences, 25(1), 43–49. https://doi.org/10.1016/j.jksuci.2012.05.005.

De Nil, L. F., Kroll, R. M., Lafaille, S. J., & Houle, S. (2003). A positron emission tomography study short- and long-term treatment eﬀects on functional brain activity in

adults who stutter. Journal of Fluency Disorders, 28, 357–379.

Dellwo, V. (2006). Rhythm and speech rate: A variation coeﬃcient for delta C. In P. Karnowski, & I. Szigeti (Eds.). Language and language-processing (pp. 231–241). .

http://discovery.ucl.ac.uk/id/eprint/12181.

Drullman, R., Festen, J. M., & Plomp, R. (1994). Eﬀect of temporal envelope smearing on speech reception. The Journal of the Acoustical Society of America, 95,

1053–1064. https://doi.org/10.1121/1.408467.

Eisenson, J., & Wells, C. (1942). A study of the inﬂuence of communicative responsibility in a choral speech situation for stutterers. The Journal of Speech Disorders,

7(3), 259–262.

Falk, S., Müller, T., & Dalla Bella, S. (2015). Non-verbal sensorimotor timing deﬁcits in children and adolescents who stutter. Frontiers in Psychology, 6, 1–12. https://

doi.org/10.3389/fpsyg.2015.00847.

Field, A. (2005). Discovering statistics using SPSS. London: SAGE Publications Inc.
Fox, P. T., Ingham, R. J., Ingham, J. C., Zamarripa, F., Xiong, J. H., & Lancaster, J. L. (2000). Brain correlates of stuttering and syllable production: A PET performance-

correlation analysis. Brain, 123(10), 1985–2004. https://doi.org/10.1093/brain/123.10.1985.

Freeman, K., & Armson, J. (1998). Extent and stability of stuttering reduction during choral reading. Journal of Speech-Language Pathology & Audiology, 22(3), 188–202.
Grabe, E., & Low, E. L. (2002). Durational variability in speech and the rhythm class hypothesis. In C. Gussenhoven, & N. Warner (Vol. Eds.), Laboratory phonology: 7,

(pp. 515–554). Berlin: Mouton de Gruyter.

Grahn, J. A., & McAuley, J. D. (2009). Neural bases of individual diﬀerences in beat perception. NeuroImage, 47(4), 1894–1903. https://doi.org/10.1016/j.

neuroimage.2009.04.039.

Greenberg, S. (1999). Speaking in shorthand–A syllable-centric perspective for understanding pronunciation variation. Speech Communication, 29(2), 159–176. https://

doi.org/10.1016/S0167-6393(99)00050-3.

Greenberg, S., Arai, T., & Silipo, R. (1998). Speech intelligibility derived from exceedingly sparse spectral information. Proceedings of the International Conference on Spoken

Language Processing74–77.

Greenberg, S., Arai, T., & Grant, K. (2006). The role of temporal dynamics in understanding spoken language. In P. Divenyi, K. Vicsi, & G. Meyer (Eds.). Dynamics of

speech production and perception (pp. 171–193). .

Guntupalli, V. K., Kalinowski, J., Saltuklaroglu, T., & Nanjundeswaran, C. (2005). The eﬀects of temporal modiﬁcation of second speech signals on stuttering inhibition

58

D. Dechamma, S. Maruthy

Journal of Fluency Disorders 58 (2018) 47–60

at two speech rates in adults. Neuroscience Letters, 385(1), 7–12. https://doi.org/10.1016/j.neulet.2005.05.010.

Halsband, U., Ito, N., Tanji, J., & Freund, H. J. (1993). The role of premotor cortex and the supplementary motor area in the temporal control of movement in man.

Brain, 116(1), 243–266. https://doi.org/10.1093/brain/116.1.243.

Houtgast, T., & Steeneken, J. M. (1985). A review of the MTF concept in room acoustics and its use for estimating speech intelligibility in auditoria. The Journal of the

Acoustical Society of America, 77(3), 1069–1077. https://doi.org/10.1121/1.392224.

Howell, P., & Powell, D. J. (1987). Delayed auditory feedback with delayed sounds varying in duration. Perception & Psychophysics, 42(2), 166–172. https://doi.org/10.

3758/BF03210505.

Ingham, R. J. (1984). Stuttering and behavior therapy: Current status and empirical foundations. San Diego, CA: College-Hill Press.
Ingham, R. J., & Carroll, P. J. (1977). Listener judgment of diﬀerences in stutterers’ nonstuttered speech during chorus- and nonchorus-reading conditions. Journal of

Speech Language and Hearing Research, 20(2), 293–302. https://doi.org/10.1044/jshr.2002.293.

Ingham, R. J., & Pakman, A. (1979). A further evaluation of the speech of stutterers during chorus- and nonchorus reading conditions. Journal of Speech and Hearing

Research, 22, 784–793. https://doi.org/10.1044/jshr.2204.784.

Ingham, R. J., Warner, A., Byrd, A., & Cotton, J. (2006). Speech eﬀort measurement and stuttering: Investigating the chorus reading eﬀect. Journal of Speech Language

and Hearing Research, 49, 660–670. https://doi.org/10.1044/1092-4388(2006/048).

Johnson, W., & Rosen, L. (1937). Studies in the psychology of stuttering VII: Eﬀect of certain changes in speech pattern upon frequency of stuttering. The Journal of

Speech Disorders, 2, 105–109. https://doi.org/10.1044/jshd.0202.105.

Kalinowski, J., Guntupalli, V. K., Stuart, A., & Saltuklaroglu, T. (2004). Self-reported eﬃcacy of an ear-level prosthetic device that delivers altered auditory feedback
for the management of stuttering. International Journal of Rehabilitation Research, 27(2), 167–170. https://doi.org/10.1097/01.mrr.0000128063.76934.df.
Kiefte, M., & Armson, J. (2008). Dissecting choral speech: Properties of the accompanist critical to stuttering reduction. Journal of Communication Disorders, 41, 33–48.

https://doi.org/10.1016/j.jcomdis.2007.03.002.

Kochanski, G., Grabe, E., Coleman, J., & Rosner, B. (2005). Loudness predicts prominence: Fundamental frequency lends little. The Journal of the Acoustical Society of

America, 118(2), 1038–1054. https://doi.org/10.1121/1.1923349.

Kroll, R. M., De Nil, L. F., Kapur, S., & Houle, S. (1997). A positron emission tomography investigation of post-treatment brain activation in stutterers. In H. F. M.
Peters, & W. Hulstijin (Eds.). Proceedings of the Third International Conference on Speech motor Production and Fluency Disorders (pp. 307–320). Amsterdam. The
Netherlands: Elsevier Science Publishers.

Leong, V., & Goswami, U. (2014). Impaired extraction of speech rhythm from temporal modulation patterns in speech in developmental dyslexia. Frontiers in Human

Neuroscience, 8, 96. https://doi.org/10.3389/fnhum.2014.00096.

Ling, E. E. L., Grabe, E., & Nolan, F. (2000). Quantitative characterizations of speech rhythm: Syllable-timing in Singapore english. Language and Speech, 43(34),

377–401. https://doi.org/10.1177/00238309000430040301.

Liss, J. M., Legendre, S., & Lotto, A. J. (2010). Discriminating dysarthria type from envelope modulation spectra. Journal of Speech Language and Hearing Research, 53,

1246–1255. https://doi.org/10.1044/1092-4388(2010/09-0121).

Macleod, J., Kalinowski, J., Stuart, A., & Armson, J. (1995). Eﬀect of single and combined altered auditory feedback on stuttering frequency at two speech rates.

Journal of Communication Disorders, 28, 217–228.

Martin, R., & Haroldson, S. K. (1979). Eﬀects of ﬁve experimental treatments of stuttering. Journal of Speech and Hearing Research, 22, 132–146.
Martin, R., Johnson, L., Siegel, G., & Haroldson, S. (1985). Auditory stimulation, rhythm, and stuttering. Journal of Speech and Hearing Research, 28, 487–495.
Maruthy, S., Venugopal, S., & Parakh, P. (2017). Speech rhythm in Kannada speaking adults who stutter. International Journal of Speech-language Pathology, 19(5),

529–537. https://doi.org/10.1080/17549507.2016.1221459.

Max, L., Caruso, A. J., & Vandevenne, A. (1997). Decreased stuttering frequency during repeated readings: A motor learning perspective. Journal of Fluency Disorders,

22, 1–17.

Packman, A., Code, C., & Onslow, M. (2007). On the cause of stuttering: Integrating theory with brain and behavioral research. Journal of Neurolinguistics, 20(5),

353–362. https://doi.org/10.1016/j.jneuroling.2006.11.001.

Packman, A., Onlsow, M., & Menzies, R. (2000). Novel speech patterns and the treatment of stuttering. Disability and Rehabilitation, 22, 65–79.
Park, J., & Logan, K. J. (2015). The role of temporal speech cues in facilitating the ﬂuency of adults who stutter. Journal of Fluency Disorders, 46, 41–55. https://doi.

org/10.1016/j.jﬂudis.2015.07.001.

Pattie, F. A., & Knight, B. B. (1944). Why does the speech of stutterers improve in chorus reading? Journal of Abnormal and Social Psychology, 39(3), 362–367. https://

doi.org/10.1037/h0054206.

Pike, K. L. (1945). The intonation of american english. Ann Arbor: University of Michigan Press.
Rami, M. K., & Diederich, E. (2005). Eﬀect of reading with reversed speech on frequency of stuttering in adults. Perceptual and Motor Skills, 100(2), 387–393. https://

doi.org/10.2466/pms.100.2.387-393.

Rami, M. K., Kalinowski, J., Rastatter, M. P., Holbert, D., & Allen, M. (2005). Choral reading with ﬁltered speech: Eﬀect on stuttering. Perceptual and Motor Skills,

100(2), 421–431. https://doi.org/10.2466/pms.100.2.421-431.

Ramus, F., Nespor, M., & Mehler, J. (1999). Correlates of linguistic rhythm in the speech signal. Cognition, 73(3), 265–292. https://doi.org/10.1016/S0010-0277(00)

00101-3.

Riley, G. (2009). The stuttering severity instrument for adults and children (SSI-4) (4th ed.). Austin: TX: PRO-ED.
Savithri, S. R., Goswami, S., & Kedarnath, D. (2007). Speech rhythm in Indo–Aryan and dravidian language. Proceedings of the International Symposium on Frontiers of

Research on Speech and Music, 170–174.

Schane, S. A. (1979). Rhythm, accent, and stress in english words. Linguistic Inquiry, 10(3), 483–502. http://www.jstor.org/stable/4178123.
Shannon, R. V., Zeng, F. G., Kamath, V., Wygonski, J., & Ekelid, M. (1995). Speech recognition with primarily temporal cues. Science, 270(5234), 303–304. https://doi.

org/10.1126/science.270.5234.303.

Soderberg, G. A. (1969). Delayed auditory feedback and the speech of stutterers: A review of studies. The Journal of Speech and Hearing Disorders, 34, 20–29.
Steeneken, H. J. M., & Houtgast, T. (1980). A physical method for measuring speech-transmission quality. The Journal of the Acoustical Society of America, 67, 318–326.

https://doi.org/10.1121/1.384464.

Stuart, A., Frazier, C. L., Kalinowski, J., & Vos, P. W. (2008). The eﬀect of frequency altered feedback on stuttering duration and type. Journal of Speech Language and

Hearing Research, 51, 889–897.

Stuart, A., Kalinowski, J., Armson, J., Stenstrom, R., & Jones, K. (1996). Fluency eﬀect of frequency alterations of plus/minus one-half and one-quarter octave shifts in

auditory feedback of people who stutter. Journal of Speech and Hearing Research, 39, 396–401.

Tilsen, S., & Johnson, K. (2008). Low-frequency fourier analysis of speech rhythm. The Journal of the Acoustical Society of America, 124, EL34–39. https://doi.org/10.

1121/1.2947626.

Toussaint, G. T. (2012). The pairwise variability index as a tool in musical rhythm analysis. Proceedings of the 12th International Conference on Music Perception and

Cognition (ICMPC) and 8th Triennial Conference of the European Society for the Cognitive Sciences of Music (ESCOM), 1001–1008.

Toyomura, A., Fujii, T., & Kuriki, S. (2011). Eﬀect of external auditory pacing on the neural activity of stuttering speakers. Neuroimage, 57(4), 1507–1516. https://doi.

org/10.1016/j.neuroimage.2011.05.039.

Trajkovski, N., Andrews, C., O’Brian, S., Onslow, M., & Packman, A. (2006). Treating stuttering in a preschool child with syllable timed speech: A case report. Behaviour

Change, 23(4), 270–277. https://doi.org/10.1375/bech.23.4.270.

Trajkovski, N., Andrews, C., Onslow, M., Packman, A., O’Brian, S., & Menzies, R. (2009). Using syllable-timed speech to treat preschool children who stutter: A

multiple baseline experiment. Journal of Fluency Disorders, 34(1), 1–10. https://doi.org/10.1016/j.jﬂudis.2009.01.001.

Webster, R. L., & Lubker, B. B. (1968). Interrelationships among ﬂuency producing variables in stuttered speech. Journal of Speech Language and Hearing Research,

11(4), 754–766. https://doi.org/10.1044/jshr.1104.754.

White, L., & Mattys, S. L. (2007). Calibrating rhythm: First language and second language studies. Journal of Phonetics, 35(4), 501–522. https://doi.org/10.1016/j.

59

D. Dechamma, S. Maruthy

wocn.2007.02.003.

Journal of Fluency Disorders 58 (2018) 47–60

Wingate, M. E. (1969). Sound and pattern in "Artiﬁcial" ﬂuency. Journal of Speech and Hearing Research, 12, 677–686. https://doi.org/10.1044/jshr.1204.677.
Wingate, M. E. (1970). Eﬀect on stuttering of changes in audition. Journal of Speech Language and Hearing Research, 13(4), 861–873. https://doi.org/10.1044/jshr.

1304.861.

Wingate, M. E. (1976). Stuttering: Theory and treatment. England: Irvington: Oxford.
Wu, J. C., Maguire, G., Riley, G., Fallon, J., LaCasse, L., Chin, S., et al. (1995). A positron emission tomography [18F] deoxyglucose study of developmental stuttering.

Neuroreport, 6(3), 501–505.

Deepthi Dechamma is Lecturer at the Samvaad Institute of Speech and Hearing, Bengaluru, India. Her research focuses on the mechanisms underlying stuttering.

Santosh Maruthy, Ph.D., is Associate Professor in the Department of Speech-Language Sciences at the All India Institute of Speech and Hearing, Mysore, India. His
research focuses on the mechanisms underlying stuttering as well as bilingualism and stuttering, speech science, speech perception, and voice disorders in professional
voice users.

60
```