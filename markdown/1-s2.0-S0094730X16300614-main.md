# 1-s2.0-S0094730X16300614-main

```
Journal of Fluency Disorders 54 (2017) 35–49

Contents lists available at ScienceDirect

Journal of Fluency Disorders

journal homepage: www.elsevier.com/locate/jﬂudis

Eﬀects of emotion on the acoustic parameters in adults who stutter:
An exploratory study
Kim R. Bauerlya,⁎

, Jessica Paxtonb

T

a Plattsburgh State University, Department of Communication Sciences and Disorders, Plattsburgh, NY, United States
b Plattsburgh State University, Department of Psychology, Plattsburgh, NY, United States

1. Introduction

Stuttering is characterized by disruptions in the ﬂow of speech and can be a serious obstacle to interpersonal communication in
the aﬀected individual. If chronic, the disorder can result in considerable negative psychological, academic, economic and social
consequences for the adult who stutters (AWS). It is likely that the onset of developmental stuttering results from an interaction of
multiple genetic, neurobiological and environmental variables (Guitar, 2004). The evidence for genetic factors is very strong and
points to underlying neurobiological factors which predispose children to the development of stuttering (Yairi & Ambrose, 2005). The
nature of the hypothesized neurobiological factor(s) is still unclear and explanatory models have focused on various processes,
ranging from motor control
(Conture,
Kelly & Walden, 2013). While both emotion and motor control diﬀerences have been found in AWS compared to adults who do not
stutter (ANS) (Alm, 2014; Eggers, De Nil, & van den Bergh, 2010), little is known about how these processes interact. The purpose of
this study was to assess how emotional processes aﬀect the stability of the speech-motor control system in the stuttering population
using acoustic analysis.

(Namasivayam & van Lieshout, 2011)

to psycholinguistic and emotional

factors

1.1. Emotions and stuttering

Emotions have always been considered to play a role in stuttering and recent empirical evidence suggests that emotion is as-
sociated with childhood stuttering (Conture et al., 2013; Eggers et al., 2010). Behavioral studies coding for positive and negative
aﬀect and expressive nonverbal behaviors (e.g. smiling, frowning or groaning) have revealed that CWS compared to their peers show
less habituation to irrelevant background stimuli, more negative emotional expression upon receiving an undesirable gift and an
increase in stuttering accompanying greater negative emotion during speaking (e.g. Choi, Conture, Walden, Lambert & Tumanova,
2013; Karrass et al., 2006). Physiological responses have supported these behavioral ﬁndings by showing increases in autonomic
arousal in children who stutter compared to peers under emotionally arousing conditions (Jones et al., 2014). Conture et al. (2013)
suggested that children who stutters’ decreased ability to regulate strong emotional reactions leads to interference in their ﬂuent ﬂow
of speech (i.e. increase in stuttering).

In studies of adults, the relationship between emotion and stuttering has focused almost exclusively on anxiety, where higher
levels of both trait and state anxiety have been reported (Alm, 2014). Findings of increased stuttering frequency and/or severity in
AWS when speaking under feared conditions such as a job interview (Brundage, Graap, Gibbons, Ferrer & Brooks, 2006) have also
been reported. Physiological studies of heart rate and skin conductance levels are mixed (Bowers, Saltuklaroglu, & Kalinwoski, 2012;
Caruso, Chodzko-Zajko, Bidinger, & Sommers, 1994; Weber & Smith, 1990). While some have reported no signiﬁcant between-group
diﬀerences in skin conductance levels between AWS and ANS (Weber & Smith, 1990), others have found signiﬁcant between-group

⁎

Corresponding author at: Communication Disorders and Sciences, Plattsburgh State University, 224 Sibley Hall, 101 Broad Street, Plattsburgh, NY 12901, United

States.

E-mail address: szyi1728@plattsburgh.edu (K.R. Bauerly).

http://dx.doi.org/10.1016/j.jﬂudis.2017.09.006
Received 15 July 2016; Received in revised form 13 September 2017; Accepted 13 September 2017

Available online 18 September 2017
0094-730X/ © 2017 Elsevier Inc. All rights reserved.

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

diﬀerences, particularly during anxiety – inducing conditions (e.g. Bowers et al., 2012). Bowers et al. (2012) found increases in skin
conductance levels in AWS when anticipating a feared sound and decreases in skin conductance levels when choral reading, an
anticipated ﬂuency provoking situation. A control sample was not used in this study. Findings from these studies are diﬃcult to
generalize due to diﬀerences in sample size, tasks, gender and methods for collecting physiological changes.

1.2. Emotions and motor control

A growing body of literature suggests that psychological factors such as emotion can strongly inﬂuence our everyday actions.
Recent studies have found that emotions play a role in both the preparation and execution of movement through both implicit and
explicit circuitries (Coombes, Naugle, Barnes, Cauraugh, & Janelle, 2011; Hajcak, Molnar, George, Bolder, Koola, & Nahas, 2007). The
eﬀects of emotion on motor control have been found using a variety of tasks including simple motor tasks such as keyboard typing
(Lee, Tsui, & Hsiao, 2015), contracting the wrist and ﬁnger extensor muscles (Coombes et al., 2006), and pushing and pulling
movements (Chen & Bargh, 1999). In order to gain a better understanding of emotion processes, researchers have organized the large
range of emotions experienced by human beings according to valence (positive and negative) and intensity (arousal levels) (Coombes,
Janelle, & Duley, 2005). Behavioral and neurophysiological studies have shown that emotionally arousing stimuli (increases in in-
tensity) elicit excitability of the corticospinal motor tract (Hajcak et al., 2007), resulting in increased reaction times (Chen & Bargh,
1999) faster movements (Gross, Crane & Fredrickson, 2012), greater movement errors (Coombes et al., 2005), and increases in force
production (Coombes, Cauragugh, & Janelle, 2006; Coombes et al., 2011). Emotional valence has also been shown to aﬀect the motor
system as shown in a study by Coombes et al. (2005) using a pinch grip task where unpleasant, compared to pleasant, stimuli led to
increases in both the speed of movement and error rate.

1.3. Emotion and Fo

Emotions are assumed to aﬀect the ﬂuent ﬂow of speech by interacting with pathways in the central nervous system, particularly
with amygdala and basal ganglia circuitries (Alm, 2004; van Lieshout, Ben-David, Lipski, & Namasivayam, 2014). Although the
extent to which emotions aﬀect ﬂuent speech is not entirely clear, variations in speech parameters under situational changes (e.g.
giving a speech) have been reported in ANS (Hagenaars and van Minnen, 2005; Goberman, Houghs and Haydock, 2011). Speech
parameters most often studied in emotional paradigms are speech rate, loudness levels and pitch. A major contributor to the per-
ception of pitch is fundamental frequency (Fo). Fo is the frequency produced by the vibration of the vocal folds and involves a
complicated mechanism of vocal fold vibration, including both intrinsic and extrinsic laryngeal muscles as well as respiratory control.
An increase in mean and variability of Fo has been observed when speaking under anxiety driven tasks (Hagenaars and van Minner,
2005; Ruiz, Absil, Harmegnies, Legros, and Poch, 1996).

1.4. Emotion, speech-motor control and stuttering

Motor abilities have always been central to theories of stuttering (Guitar, 2004). Evidence supports the assumption that AWS have
limitations (Namasivayam & van Lieshout, 2008) or impairments (Loucks & De Nil, 2001; Max et al., 2004; Smith & Kelly, 1997) in
speech-motor control. This assumption stems from numerous studies reporting slower reaction times (Huinch, Wouters,
Hulstijn, & Peters, 2001) slower movement durations with and without practice (Bauerly & De Nil, 2011; Huinch et al., 2001; Smits-
Bandstra, De Nil, Saint-Cyr, 2006) and greater variability (Smith & Kleinow, 2000), across speech and nonspeech motor systems
(Bauerly & De Nil, 2011; Smits-Bandstra et al., 2006).

If emotion drives the motor system one would suspect to ﬁnd greater eﬀects from emotion on speech-motor control in the
stuttering population. This speculation can be made based on the premise that both children and adults who stutter show increases in
emotional reactivity (e.g. Jones et al., 2014) while at the same time, exhibiting motor control limitations (for review see
Namasivayam & van Lieshout, 2008). Most of the studies so far have focused on processes of emotion and motor control separately.
However, taken together, it can be speculated that AWS will show greater diﬀerences in motor control when performing under
emotionally-charged situations. While studies exploring the eﬀects of emotion on articulatory control are beginning to emerge,
ﬁndings in this area are diﬃcult to generalize as they have often examined intentionally expressed emotions (acted) as opposed to
natural speech (e.g. Kim, Toutios, Lee & Narayanan, 2015). A few studies have assessed the inﬂuence of negative emotions, parti-
cularly anxiety, on the speech motor control abilities in AWS (Hennessey, Dourado & Beilby, 2014; Van Lieshout et al., 2014).
Hennessey et al. (2014) found that AWS’ reaction times to anxiety-driven stimuli were signiﬁcantly slower when responding to threat
words compared to ANS. Caruso et al. (1994) found that although both groups showed longer word and vowel durations when under
cognitively stressful conditions, the diﬀerence in durations between the neutral and stressful conditions was much larger in the AWS’
when compared to controls. Using kinematic analysis, Van Lieshout et al. (2014) found slower reaction times and diﬀerences in lip
amplitude and coordination in AWS compared to ANS when administered the Emotional Stroop task, a task requiring individuals to
name the font color of threat words (e.g. “Attack”). One limitation to the study by Van Lieshout et al. (2014) and others (Caruso et al.,
1994; Hennessey et al., 2014) is that they only used negative, anxiety – driven stimuli and, therefore, little is known about the
inﬂuence from stimuli eliciting positive emotions (e.g. excitation) on the speech – motor control system in AWS.

36

K.R. Bauerly, J. Paxton

1.5. Acoustic analysis

Journal of Fluency Disorders 54 (2017) 35–49

One way to capture diﬀerences in speech-motor control is through acoustic analysis. This level of analysis is based on analyzing
the acoustic parameters of a speech signal for various aspects including changes in formant frequency, amplitude and duration of
movement within the oral cavity. Formant frequencies (range of frequencies within a sound spectrum) provide information regarding
vocal tract geometry and allow us to make inferences about the position of the tongue body inside the oral cavity during the
production of vowels or consonant-vowel combinations. Assessing the second formant (F2) in particular, allow us to make inferences
about the position of the tongue body during the production of vowels or consonant-vowel combinations. Commonly, formant
frequencies are assessed with a consonant + vowel (e.g. ca) or consonant + vowel + consonant (e.g. cat) structure. Using these
contexts, a number of acoustic measurements can be made including formant frequency duration (speed of movement) and formant
frequency extent (articulatory displacement) (Max & Caruso, 1998; Robb, Blomgren & Chen, 1998).

Formant analysis has been a widely used measure to assess articulatory movement in both children and adults who stutter
(Dehqan, Yadegari, Blomgren, & Scherer, 2016; Robb & Blomgren, 1997; Subramanian, Yairi, & Amir, 2003; Yaruss & Conture, 1993).
Several studies assessing stuttered and ﬂuent speech in both children and adults who stutter have found missing or atypical formant
transitions (Howell & Vause, 1986; Robb & Blomgren, 1997; Yaruss & Conture,1993), shorter formant transition times (Subramanian
et al., 2003; Yaruss & Conture, 1993), longer transition duration in F2 (Dehqan, Yadegari, Blombren, & Scherer, 2016), larger F2
frequency extents (Dehqan et al., 2006) and greater variability in the vowel steady state (Robb et al., 1998).

1.6. Research needs

Although both positive and negative emotions have the potential to inﬂuence speech ﬂuency, research has focused exclusively on
negative emotions. However, clinic and self-reports indicate that both children and adults who stutter show an increase in stuttering
frequency under a variety of diﬀerent emotional states including excitation (Guitar, 2004). Also, research assessing speech motor
control and emotion in the stuttering population is limited to behavioral measures of stuttering frequency, with two exceptions from
the more recent studies by Hennessey et al. (2014) and Van Lieshout et al. (2014) described above. Therefore, the current study was
aimed at extending our knowledge of the eﬀect of emotion on the speech-motor control abilities in the stuttering population by
investigating changes in acoustic parameters in the ﬂuent speech of both AWS and ANS.

More speciﬁcally the present study was aimed at assessing whether AWS diﬀer from ﬂuent peers in acoustic parameters when
speaking under emotionally arousing conditions (excited-calm), both positive and negatively valenced. To do this, participants
viewed pictures eliciting three diﬀerent emotional states: neutral (N), increased arousal/pleasant (IA/P), and increased arousal/
unpleasant (IA/UP). Within each condition, participants were required to read out loud a total of 12 sequences of three nonwords
depicted on a computer screen. The nonword sequences were interspersed within each emotion condition so one sequence of three
nonwords was presented after every two pictures. Based on our current understanding of emotional reactivity and regulation abilities
in AWS, it was predicted that higher Fo would be found in the stuttering versus nonstuttering group, reﬂecting an increase in
emotional reactivity to the arousing stimuli. Based on the premise that AWS show limited motor skill (van Lieshout et al., 2014), it
was predicted that the AWS would show greater change in F2 slope compared to controls when speaking under arousing conditions.
Given the evidence that has recently emerged concerning anxiety and motor control in AWS (e.g. Hennessey et al., 2014), it was
hypothesized that AWS’ change in F2 slope would reﬂect a reduction in the speed of articulatory transition. It was predicted that the
change in F2 slope would be larger than the ANS, reﬂecting stronger emotional inﬂuences on the motor system. F2 was focused on in
the current study due to its sensitivity to tongue movement and to adhere to existing studies which have focused on the second
formant (Civier, Tasko, & Guenther, 2010).

2. Methods

2.1. Participants

Participants included 10 males who stutter (21–45; M = 24.4, SD = 2.5) and 10 males who do not stutter (21–45; M = 27.2,
SD = 6.9). All participants presented with the following criteria: (1) self-reported English as their primary language, (2) right handed
by scoring a minimum of 90% on the Oldﬁeld Handedness Inventory (Oldﬁeld, 1971), (3) self-reported negative history of neuro-
logical disorders or drug use aﬀecting speech production, (4) self-reported negative history of speech or language problems (other
than stuttering for the AWS), (5) self-reported good ocular health, (6) no history of visual or auditory pathologies, and (7) pure-tone
conduction hearing thresholds within clinically normal limits (< 20 dB HL from 1000 Hz–3000 Hz). Only males were recruited for
this study in order to avoid confounding variables from gender-related diﬀerences in aﬀect (Coan & Allen, 2007). Only right handed
individuals were recruited in order to avoid confounding variable from hemispheric diﬀerences in processing emotion and motor
control (Cuthbert, Bradley, Zabaldo Martinez & Lang, 1994; Lang, Bradley, & Cuthbert, 2008).

Males classiﬁed as stuttering exhibited the following inclusion criteria: (1) onset of stuttering in childhood (< 7 years of age), (2)
a minimum of 3% within – word disﬂuences in at least one of the speaking situations (reading, conversation) and (3) a score of either
mild, moderate or severe on the Stuttering Severity Instrument (SSI-3; Riley, 1994). Percent syllables stuttered were measured from
the ﬁrst 300 syllables of a spontaneous monolog (M = 11.9, SD = 26.1) and a 240-word reading passage (M = 17.8%, SD = 15.2).
According the SSI-3, participants stuttering severity ranged from very mild (5), mild (2), moderate (2) to moderate-severe (1). In
order to minimize treatment eﬀects, the AWS reported no formal ﬂuency treatment within one year prior to testing. All participants

37

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

were paid volunteers naïve to the purposes of the study. They were recruited from ﬂiers or were previous clients from State University
of New York (SUNY)- Plattsburgh's Speech and Hearing Center. SUNY Plattsburgh's Oﬃce of Human Research IRB approved the study
protocol. Informed consent was obtained from all participants.

2.2. Stimuli

All participants completed three tasks: (1) view images depicted on a computer screen, (2) read words depicted on a computer

screen and (3) rate their feelings in relation to picture viewing.

2.2.1. Emotional stimuli

One hundred and forty-four pictures were selected from the International Aﬀective Picture System (IAPS; Lang et al., 2008), based
on normative ratings. The IAPS is a set of over 1000 emotionally evocative, internationally-acceptable, color photographs that
include normative ratings of pleasure and arousal (Coan & Allen, 2007). Pictures encompass a large set of human experience in-
cluding joyful, sad, fearful, anxious, excitement and so on. Each picture in the IAPS has been rated by a large group of men for the
feelings of hedonic valence and arousal that the picture evokes during or immediately after viewing (Coan & Allen, 2007). Pictures
were ﬁrst grouped into the two categories based on pre-determined, normative ratings (Lang et al., 2008) of arousal: Increased
Arousal (96 images) and Neutral (48 images). A picture previously rated as eliciting feelings of neutral may include a nature
landscape or household object (Lang et al., 2008) and thus received low scores for arousal and neutral scores for pleasantness. Images
falling in the increased arousal category were further divided into two equal groups based on rating of hedonic valence (tone of
feeling): pleasant (48 pictures) and unpleasant (48 pictures). An image previously rated as being pleasant with an increase in arousal
may include a man skydiving or a family on a roller coaster. An image previously rated as being unpleasant with an increase in
arousal may include a hurt animal or a human attack (Lang et al., 2008). Images were then grouped into 24 images each to form the
following emotional conditions: two neutral (N), two increased arousal/pleasant (IA/P), and two increased arousal/unpleasant (IA/
UP). See Fig. 1 for a depiction of where each IAPs image used in the current study fell on a two-dimensional aﬀective space of mean
pleasure and arousal ratings taken from a normative ratings study (Lang et al., 2008). The average arousal ratings on a scale of 1
being low in arousal and 9 being high in arousal for IA/P, IA/UP and N categories were 5.5 (SD = 0.49), 5.8 (SD = 0.57) and 2.7
(SD = 0.41), respectively. The average valence ratings on a scale of 1 being very unpleasant and 9 being very pleasant for the
pleasant, unpleasant and neutral categories were 6.8 (SD = 5.2), 2.7 (SD = 0.41) and 4.9 (SD = 0.37), respectively. Each condition
consisted of 24 pictures, totalling 144 s of picture viewing per condition.

Pictures within each condition were randomized using Superlab 5.0 (Stimulus Presentation Software, Cedrus, 2014) and pre-
sented on a computer monitor for 6 s each. Participants were asked to attend to the picture for the entire time it is displayed on the
computer screen.

2.2.2. Speech sample

Consonant + vowel + consonant (CVt) tokens served as stimuli for acoustic analysis (Robb et al., 1998). CVt tokens consisted of
one of the following initial sounds /p, b, s, z/. An initial stop or fricative sound was chosen in order to facilitate reliable identiﬁcation
and measurements of acoustic segments (Max & Caruso, 1998). CVt words included the following vowels /i/ (e.g.“zeet”), /E/ (e.g.
“sed”) and /u/ (e.g.“soot”). Vowels were chosen based on their representation of tongue position (i.e. front, back) within the oral
cavity. All CVt tokens included the phoneme/t/in ﬁnal position. A ﬁnal/t/was chosen in order to facilitate reliable identiﬁcation of
vowel termination. Each consonant was paired with each vowel, totaling 12 tokens for analysis. Stimuli were identical to Robb et al.
(1998) and Dehqan et al. (2016). Each token was embedded between two nonwords, each consisting of an initial and ﬁnal consonant
– vowel- consonant that was not analyzed (e.g. “mid, peet, nod”), totaling 12 strings of three CVC words for each condition. Each of
the 12 CVt tokens analyzed was randomly assigned a nonword sequence so no participant produced a three CVC sequence twice.

Fig. 1. Image from the International Aﬀective Picture System (IAPS) used in the current study displayed on a 2-dimensiional aﬀective space on the basis of mean
normative ratings of pleasure and arousal (Lang, Bradley & Cuthert, 2008).

38

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

Fig. 2. Example of the SAM questionnaire for self-reported ratings of pleasure (top) and arousal (bottom). Participants were required to place an “x” on the circle that
depicted how they felt while viewing the images.

Initial and ﬁnal CVC nonwords that were not analyzed contained one of the following initial and ﬁnal consonants: s, k, g, t, d, m, n
and one of the following medial vowels: o, u, E, i, a. There is some evidence to suggest that utterance position may inﬂuence the
articulatory shape of the word spoken (Ferrand, 2014). For instance, formant frequency duration and extent may be inﬂuenced by
word ﬁnal position (Kuo, 2013). Therefore, to promote consistency across speakers and to adhere to previous studies using the same
CVt tokens (Dehqan et al., 2016; Robb et al., 1998), tokens under analysis were embedded in a three, nonword utterance. Each string
of three tokens was displayed horizontally on a computer screen for 4 s.

All 12 of the CVt tokens were presented in each emotional condition, one CVt token followed every two consecutive images. The
order of the CVt tokens in each condition was randomized using Superlab Software 5.0 (Stimulus Presentation Software, Cedrus,
2014). Therefore, 24 CVt tokens were presented in the two N conditions, the two IA/P conditions, and the two IA/UP conditions,
totaling 72 CVt tokens for analysis. Only perceptually ﬂuent tokens were used for analysis.

2.3. Evaluative ratings

Self-reported ratings of pleasure and arousal were taken at the end of each condition using the paper and pencil version of the
Self-Assessment Manikin (SAM; Bradley & Lang, 1994). As shown in Fig. 2, SAM is a graphic ﬁgure that, when representing the
dimension of pleasure, is smiling and happy to frowning and unhappy. Participants were told that “if you felt completely happy when
viewing the pictures, then you can indicate this by placing an X over the ﬁgure at the left. If you felt completely unhappy, annoyed,
despaired, you can indicate feeling unhappy by placing an ‘X’ on the ﬁgure on the right”. When SAM is used to represent the
dimension of arousal, it is wide eyed to relaxed and sleepy. Participants were told “if you felt completely aroused, stimulated, excited,
frenzied, jittery, or wide-awake while viewing the picture, place an “X” over the ﬁgure at the left of the row. On the other hand, if you
felt completely relaxed, calm, sluggish, dull, sleepy, or unaroused, you can indicate this by placing an ‘X’ over the ﬁgure at the right of
the row”. Participants indicated feeling neither happy nor unhappy (i.e. neutral), or neither calm nor aroused using the midpoint of
each scale. They were instructed to place an X between the ﬁgures if their judgement fell between any two of the pictures. The
original version of SAM includes a dimension of “dominance” but due to its irrelevance to the study question, this part of the rating
was omitted. The participant ﬁlled in any of the ﬁve ﬁgures depicting emotion or a box between any two ﬁgures, resulting in a 9-point
rating scale. Participants were asked to report how they felt when viewing the pictures and not their overall mood using SAM when
the screen prompted them to do so (i.e. image of SAM appeared on the screen).

2.4. Procedure

In summary, participants were required to view pictures from the IAPS, read sequences of nonwords, and report emotional
reactions using SAM. IAPS stimuli were presented in three separate emotional categories: neutral (N), increased arousal/pleasant (IA/
P) and increased arousal/unpleasant (IA/UP). Each emotional category included 24 IAPS pictures. Each emotion category was
presented twice, resulting in 48 IAPS pictures per emotion. Description of procedures are as follows.

Participants were seated in front of a computer monitor in a sound proof room and placed with a head-mounted microphone
(SONY ECM-55) 10 cm from their lips. The paper and pen SAM, along with a pencil, was placed on the desk for them to complete. At
this time, participants were ready to view the pictures and read the nonwords. Each condition began with a 2 s preparatory cue “Press
any key to begin”. This triggered the presentation of two consecutive images (6 s each), followed by a sequence of three nonwords
which appeared horizontally on the screen (4s). Participants were required to: (1) look at the picture the entire time it appears on the
screen and to (2) read out loud the three, nonword sequence. They were instructed to read at a comfortable rate and loudness level.
Following the reading of one nonword sequence, two more pictures appeared on the screen, followed by another string of three
nonwords, continuing until all 24 images and 12 CVt tokens (embedded in the string of three, nonwords) were presented. Each set of
24 images and 12 CVt tokens consisted of one type of emotional aﬀect (condition). Following each set of 24 images and 12 CVt

39

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

Fig. 3. Study procedures with an example of the (a) presentation order for the 3 emotional conditions and (b) stimuli and order of procedures for a Neutral condition.

tokens, participants completed the SAM. Following this, a three-minute rest period was provided where they were be asked to close
their eyes or just gaze at a neutral picture on the computer monitor. An inter-stimulus interval of three minutes was considered a
conservative time range to avoid emotional carry-over from one condition to the next as previous literature assessing aﬀective
reactions when viewing IAPs pictures (for review see Coan & Allen, 2007) including the electrophysiological measure of event-related
potentials (e.g. Cuthbert, Schupp, Bradley, Birbaumer, & Lang, 2000), skin conductance (Bradley, Codispoti, Cuthbert, & Lang, 2001)
and heart rate (Greenwald, Cook, & Lang, 1989) have all incorporated inter-stimulus intervals that are less than 10 s. The rest period
was followed by another condition that included a 2 s preparatory cue, 24 pictures, 12 CVt tokens and a SAM rating. In total, there
were 6 conditions: 2N, 2 IA/P and 2 IA/UP. The order of conditions were randomized across participants. Please refer to Fig. 3 for
depiction of (a) the entire procedure and (b) an example of one condition.

Speech samples were digitized to a computer at a sampling rate of 22 kHz using a two channel recorder (TASCAMH5) and
Audacity software (Audacity Team, 2014). For both groups, CVt tokens that were stuttered including sound repetitions, prolongations
and/or blockages of a sound were excluded from further analysis. The percentage of CVt tokens containing stutters for both the AWS
and ANS were low: 9.6% and 0.4%, respectively. CVt tokens that contained missing formants or were missing a ﬁnal/t/were excluded
from ﬁnal analysis and included 4% of AWS’ and 5.3% of ANS’ data sets.

2.5. Analysis and dependent variables

Using Praat software version 5.3.13 (Boersma, 2001), a combined waveform and wideband (300–400 Hz) spectrographic display
was used to identify time points and frequencies of the second formant (F2). Standard Praat (Boersma, 2001) settings were used for
measuring F2 characteristics (0–5000 Hz frequency range, 0.025 s window length and 30 dB dynamic range). F2 onset and oﬀset
frequencies were measured from the visual center of the F2 energy bands on the spectrographic display. Linear predictive coding
(LPC) measurements were also used to ensure measurement validity. These two measures were found to be highly correlated for all
acoustic measures including the time point of second formant (F2) onset, the time point of F2 oﬀset, F2 onset frequency and F2 oﬀset
frequency (see below for complete description). Pearson product correlations ranged from 0.81-0.89. All variables were signiﬁcant
(p = 0.01) and thus all temporal and frequency measurement for analysis were used from spectrogram measures.

2.5.1. Error rate and stuttering frequency

Error rate was measured by the number of distortions, incorrect substitutions or missing syllables. Frequency of stuttering was

deﬁned as sound or syllable repetitions, prolongations or blocks (Guitar, 2004).

2.5.2. Acoustic measures of F2 transition

Acoustic analysis included both temporal and frequency measurements of the F2 transition of the vowel in each CVt token. Both
the temporal and frequency measurements of F2 transition were made from predetermined F2 onset and F2 oﬀset criteria using a
wideband spectrographic display (300–400 Hz). F2 onset was measured from the onset of acoustical energy associated with the ﬁrst
glottal pulse (indicating vowel production) succeeding the initial consonant. F2 onset was measured from the visual center of the F2
energy band on the spectrographic display. F2 oﬀset frequency measurements were made in variable positions, depending on the
conﬁguration of the F2 resonance as speciﬁed in Chang, Ohde and Conture (2002) and Sussman, Bessell, Dalston, & Majors (1997).
More speciﬁcally, if the resonance was ﬂat or diagonally rising or falling, a temporal midpoint was determined from the F2 onset
measure to the last discernable glottal pulse of the vowel. The F2 oﬀset frequency was then determined from this temporal midpoint.
If the resonance was U-shaped or the inverse, the minimum or maximum frequency point was taken. Similar to F2 onset, oﬀset
measures were made from the visual center of the F2 energy band. Once the onset and oﬀset of F2 was determined, both temporal and
frequency measurements were made. See Fig. 4 for a depiction of F2 frequency onset and oﬀset measures.

The following measurements were then taken: (1) F2 slope, calculated by dividing the frequency extent by duration (hz/ms), (2)
transition extent, calculated by the frequency change (hz) between F2 onset and oﬀset, (3) transition duration, calculated by the time
(ms) between the transition onset and oﬀset.

40

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

Fig. 4. Example of measurements for F2 onset and oﬀset frequency.

2.5.3. Acoustic measures of fundamental frequency (Fo)

Fundamental

frequency (Fo) of the voice is a measure of a speaker’s rate of vocal

fold vibration during phonation
(Rochman & Amir, 2013). Changes in Fo have been linked to emotion where increases in Fo (higher pitch) has been shown to
accompany increases in emotional reactivity, regardless of whether the stimuli are positive or negative (Owren & Bachorowski,
2007). While several studies have assessed range of Fo or the mean Fo from multi-word utterances (Barrett & Paus, 2002; Goberman,
Hugues, & Haydock, 2011), the current study focused on the vowel steady state in order to remain consistent with the other acoustic
measures for F2. Mean fundamental frequency (Fo) was obtained by combining waveform and narrowband spectrographic displays
(50–400 Hz) with standard Praat settings as described above (Boersma, 2001). Mean Fo measures were computed as the average
frequency of glottal pulses as measured from the ﬁrst glottal pulse associated with the vowel steady state (F2 frequency transition
oﬀset measure described in 2.5.3) to the last discernible glottal pulse of the CVt token.

2.6. Statistical analysis

Data was analyzed with SPSS 21.0 for windows (SPSS Corp., Chicago, IL, USA). Separate two-way mixed ANOVAs were run for Fo
(CVt tokens collapsed across condition), errors and stutters in order to determine the eﬀect of emotion (N versus IA/P versus IA/UP)
on group (AWS versus ANS). Two-way mixed ANOVAs were run for F2 slope (hz/ms) for each CVt token separately in order to
determine the eﬀect of emotion (N versus IA/P versus IA/UP) on groups (AWS versus ANS). Due to the variability in place, manner,
and voicing across CVt tokens, separate analysis were taken to avoid neutralizing the values under analysis. Performing separate
analysis is consistent with the literature assessing F2 slope from consonant-vowel combinations (e.g. Dehqan et al., 2016; Robb et al.,
1998). F2 slope is derived from measures of F2 transition duration and F2 transition extent. In order to determine which of these
variables played a larger role in F2 slope changes, the CVt tokens that elicited signiﬁcant group × condition interaction for F2 slope
were further analyzed using two-way mixed ANOVAs for F2 frequency duration and F2 frequency extent separately.

Three of the CVt tokens (i.e./sut/,/zut/,/set/) showed negative values for F2 transition extent. That is, F2 formants transitioned
from a high to low frequency. The purpose of this study was to assess the extent of movement, regardless of the direction, and
therefore only absolute values were used for analysis (Max & Caruso, 1998). Prior to analysis, the shape of the distribution was
evaluated for each variable using box plots. There were a total of 39 outliers (approximately 2%) that were excluded from the data
(greater than three box-lengths from edge of box) for F2 slope, F2 transition extent, and F2 transition duration. Analysis of the
studentized residuals showed that there was normality, as assessed by the Shapiro-Wilk test; however, F2 transition duration, extent
and slope variables appeared to show positively skewed distributions. To normalize these distributions they were square-root
transformed. All descriptive data reported in the results section is from untransformed data. Due to the study’s small sample size and
its exploratory nature, no Bonferroni corrections were employed to reduce Type I errors.

2.7. Reliability

To assess interjudge and intrajudge reliability measurements, 10% of the CVt tokens from each participant’s sample (144 total)
were re-assessed by the ﬁrst author and another individual trained in acoustic analysis for the variables Fo, error rate, stutters, time
point of F2 onset, time point of F2 oﬀset, F2 onset frequency, and F2 oﬀset frequency. Pearson product correlations ranged from 0.82
to 0.94 for interjudge reliability measurements and 0.89–0.98 for intrajudge reliability measures. All variables were signiﬁcant
(p < 0.001).

3. Results

The results are presented in three sections. The ﬁrst section reports SAM ratings of valence and arousal. The second section reports
results for group diﬀerences across conditions for Fo, error rate and stuttering frequency. The third section compares the average F2
slopes, F2 formant frequency extents, and F2 formant duration between the AWS and ANS for each CVt token separately across
conditions.

41

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

Table 1
Overall means and standard deviations (in parenthesis) of fundamental frequency (Fo; hz) for 10 AWS and 10 ANS under Neutral (N),
Increased Arousal/Pleasant (IA/P) and Increased Arousal/Unpleasant (IA/UP) conditions.

AWS
ANS

3.1. SAM ratings

N

121.32 (30.7)
122.23 (22.1)

IA/P

128.00 (35.7)
127.20 (23.9)

IA/UP

127.38 (34.2)
127.90 (25.1)

The average valence ratings for pleasant, unpleasant, and neutral IAPS pictures for the AWS were 5.8 (SD = 1.0), 2.3 (SD = 1.4),
and 4.2 (SD = 0.9), respectively and for the ANS were 6.8 (SD = 1.1), 3.1 (SD = 1.3) and 4.5 (SD = 1.0), respectively. A repeated
measures ANOVA conﬁrmed that these valence ratings diﬀered signiﬁcantly from one another for the AWS, F (2,38) = 43.28,
p < 0.001, ή2 = 0.695 and ANS, F (2,38) = 44.04, p < 0.001, ή2 = 699. The average arousal ratings for the pleasant, unpleasant
and neutral IAPS pictures for the AWS were 5.5 (SD = 0.99), 6.77 (SD = 1.4), and 2.8 (SD = 0.85), respectively and for the ANS
were 6.45 (SD = 0.88), 6.6 (SD = 0.92), and 3.07 (SD = 1.2), respectively. Paired sample t tests conﬁrmed that both the pleasant
and unpleasant pictures were rated as more arousing than the neutral pictures for the AWS, t(19) = 25.17, p < 0.001, and t(19)
= 20.69, p < 0.001, respectively and ANS, t(19) = 32.51, p < 0.001, and t(19) = 31.86, p < 0.001. No signiﬁcant diﬀerences
were found between groups.

3.2. Fundamental frequency (Fo), stuttering frequency, errors

3.2.1. Fundamental frequency (Fo)

A two-way mixed design ANOVA for group × condition was used to compare the mean of all 24 CVt tokens (12 tokens per
conditions) from each condition (2N; 2 IA/P; 2 IA/UP), totaling 240 tokens in each condition for AWS and ANS separately.
Descriptive analysis (Table 1) showed that both AWS and ANS increased their Fo from the N to arousing conditions. However, no
main eﬀect for condition was found (p > 0.05). No signiﬁcant group x condition interaction or group main eﬀect was found.

3.2.2. Errors and stuttering frequency

Errors remained relatively consistent for the AWS under N (M = 2.3, SD = 2.1), IA/P (M = 2.0 (SD = 2.7) and IA/UP (M = 1.7,
SD = 2.1) conditions. ANS also showed no diﬀerences in errors across the N (M = 1.1, SD = 1.0), IA/P (M = 1.1 (SD = 2.1) and IA/
UP (M = 1.2, SD = 2.0) conditions. No signiﬁcant group × condition interaction was found (p > 0.05), nor were there signiﬁcant
main eﬀects for condition or group (p > 0.05). AWS did not diﬀer in their frequency of stutters across conditions (p > 0.05), N
(M = 1.0, SD = 1.4), IA/P (M = 1.0 SD = 2.0), IA/UP (M = 0.40, SD = 0.84).

3.3. F2 slope, frequency extent and duration

Two-way mixed design ANOVAs were conducted for F2 slope for each CVt token separately. For these tokens, post hoc analysis

assessing simple main eﬀects of group and condition were conducted for the CVt tokens that yielded a signiﬁcant interaction.

3.3.1. F2 slope

There was homogeneity of variances for all CVt tokens (p > 0.05) as assessed by Levene’s test for equality of variances. There
was sphericity for the interaction term, as assessed by Mauchly’s test of spericity (p > 0.05) for all CVt tokens with the exception of/
put/, X2(2) = 9.53, p > 0.05, therefore, degrees of freedom were corrected using Greenhouse-Geisser estimates of sphericity
(e = 0.815). Main eﬀects for group showed signiﬁcantly steeper slopes in four of the 12 CVt tokens in the AWS compared to the
ANS:/bet/F(1,17) = 4.60, p = 0.038, ή2 = 0.111,/bit/F(1,18) = 65.14, p < 0.001, ή2 = 0.632,/pit/F(1,18) = 47.91, p < 0.001,
ή2 = 0.558,/zut/F(1,17) = 165.70, p < 0.05, ή2 = 0.817. ANS showed signiﬁcantly steeper slopes for the CVt token/put/F(1,38)
= 76.38, p < 0.001, ή2 = 0.668. Main eﬀects for condition were found for the CVt tokens/pet/F(2,36) = 3.57, p = 0.033,
ή2 = 0.086,/set/F(2,36) = 3.038, p = 0.045, ή2 = 0.074 and/zut/F(2,34) = 3.58, p = 0.033, ή2 = 0.088. Statistically signiﬁcant
condition × group interactions were found for 7 out of the 12 CVt tokens (see Table 2 for results). All of the 7 signiﬁcant interaction
showed medium to large eﬀect sizes (0.08–0.18). Post hoc analysis was only conducted for tokens showing a signiﬁcant interaction,
results are described below.

3.3.2. Between-condition comparison:

As indicated in Table 2, there were more instances of greater changes in slope, positive or negative, for the AWS compared to the
ANS. Paired sample t-tests showed signiﬁcantly steeper F2 slopes in the AWS as they transitioned from the N to IA/P condition for/
pet/(t (19) = 2.18, p = 0.041) and/zet/(t (19) = 2.49, p = 0.022) and from the N to IA/UP condition for/but/(t (19) = 3.02,
p = 0.007), /pet/(t (19) = 3.06, p = 0.006) and/zet/(t (19) = 5.12, p = 0.022). Signiﬁcant decreases in F2 slope were found in the
AWS for the CVt token/sut/as they transitioned from N to IA/P (t (19) = 2.41, p = 0.026) and N to IA/UP (t (19) = 2.54, p = 0.026)
conditions. ANS showed only one signiﬁcant diﬀerence in F2 slope across condition and that was an increase in F2 slope from the N to

42

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

Table 2
Absolute values of the raw means and standard deviations (in parenthesis) for F2 slopes (Hz/ms) for 10 AWS and 10 ANS under Neutral (N), Increased Arousal/
Pleasant (IA/P), Increased Arousal/Unpleasant (IA/UP) conditions for all CVt tokens. Results from 2-way mixed design ANOVAs for the group x condition interactions
are included.

N
AWS

2.0 (1.4)
4.1 (3.0)
0.9 (0.05)
2.3 (1.6)
1.9 (0.8)
2.0 (1.8)
3.3 (1.7)
4.5 (2.5)
1.7 (2.1)
0.6 (0.3)
6.9 (3.1)
5.5 (2.0)

ANS

2.4 (2.5)
1.7 (0.9)
1.0 (0.5)
0.9 (0.6)
4.6 (3.9)
3.6 (3.7)
5.2 (4.7)
4.7 (2.4)
1.4 (1.5)
1.6 (1.8)
4.3 (2.7)
4.7 (4.8)

IA/P
AWS

2.4(1.2)
5.1 (3.0)
2.4 (0.54)
2.0 (1.2)
2.0 (1.0)
3.4 (2.4)
3.5 (1.9)
5.6 (4.1)
0.8 (0.63)
1.4 (1.1)
5.3 (3.2)
5.0 (2.6)

ANS

1.6 (1.1)
2.6 (1.6)
1.7 (0.8)
1.1 (0.7)
2.3 (1.5)
3.6 (3.7)
3.7 (2.6)
5.1 (3.8)
1.2 (0.5)
1.5 (1.3)
6.2 (3.0)
6.8 (4.0)

IA/UP
AWS

1.9 (1.8)
4.4 (3.8)
1.8 (0.9)
4.1 (3.0)
2.3 (1.6)
3.1 (1.5)
3.8 (1.4)
3.7 (3.4)
1.2 (0.66)
1.4 (0.7)
5.3 (2.8)
5.6 (4.5)

ANS

1.6 (0.7)
2.1 (1.6)
0.9 (0.3)
0.9 (0.4)
5.6 (4.1)
1.3 (0.67)
5.4 (6.2)
6.2 (4.3)
0.8 (0.4)
1.2 (0.6)
7.1 (4.9)
2.5 (1.6)

/pit/
/bit/
/pet/
/bet/
/put/
/but/
/sit/
/zit/
/set/
/zet/
/sut/
/zut/

F

1.52
0.50
2.99
2.02
0.91
7.95
0.21
5.06
6.90
3.21
6.16
3.58

df

36
36
36
34
36
34
36
30
36
34
36
34

p Value

ή2

0.22
0.61
0.033*
0.14
0.41
0.001*
0.21
0.009*
0.002*
0.046*
0.003*
0.033*

0.04
0.01
0.09
0.05
0.02
0.18
0.01
0.12
0.15
0.08
0.14
0.09

Note. df = degrees of freedom.

* p < 0.05.

IA/UP condition for the CVt token/sut/(t (19) = 2.12, p = 0.047).

3.3.3. Between – group comparisons.

Independent sample t-tests showed signiﬁcantly steeper F2 slopes in the AWS compared to the ANS for 6 tokens including/sut/
(p = 0.006) and/bet/(p = 0.021) under N conditions,/bit/(p = 0.03) under
IA/P conditions and/but/(p = 0 .001),/pet/
(p = 0.027), and/zut/(p = 0.003) under IA/UP conditions. Three CVt tokens showed signiﬁcantly steeper slopes in the ANS in-
cluding/zet/(p = 0.004) under N conditions,/set/(p = 0.002) under IA/P conditions and/zit/(p = 0.038) under IA/UP conditions.
In summary, a signiﬁcant group × condition interaction was found in 7 out of the 12 CVt tokens. Post-hoc analysis indicated that
the signiﬁcant group × condition interaction can be partly attributed to the AWS showing signiﬁcant main eﬀects for condition as
they showed greater changes in F2 slope (either a rising or falling trajectory) under arousing (IA/P and/or IA/UP) versus N conditions
(7 instances) compared to the ANS (one instance). Also, out of the 7 CVt tokens yielding a signiﬁcant interaction, four showed
signiﬁcantly steeper F2 slopes in the AWS (group eﬀects) during at least one of the arousing conditions. It is important to note that
this trend for steeper F2 slopes in the AWS under arousing conditions was not exhibited for all the CVt tokens. More speciﬁcally, the
steeper F2 slopes for/sut/found in the AWS under N conditions did not remain as they transitioned to shallower F2 slopes compared
to controls under both IA/P and IA/UP conditions. Also, the ANS showed steeper F2 slopes under arousing conditions for/zit/(IA/UP)
and/set/(IA/P) and this may explain the group x condition interaction for these tokens.

It is diﬃcult to explain changes in F2 slope without looking more closely at the extent and duration of F2 frequency change as a
speaker transitions the vowel from onset to a steady state. Therefore, in order to determine which of these two factors was the most
inﬂuential to changes in F2 slope, the variables F2 frequency extent and F2 frequency duration were measured separately and
described below. Only the CVt tokens that showed a signiﬁcant group x condition interaction for F2 slope were included in the
following measures.

3.3.4. F2 frequency extent

Two-way mixed design ANOVAs for F2 frequency extent were conducted for those 7 CVt tokens that yielded a signiﬁcant con-
dition x group interaction for F2 slope (Table 2). Levene’s test for equality of variances indicated homogeneity of variances for all CVt
tokens (p > 0.05) across conditions. There was sphericity for the interaction term, as assessed by Mauchly’s test (p > 0.05) for all
but two CVt tokens,/but/, (X2(2) = 8.71, p = 0.01) and/pet/, (X2(2) = 7.02, p = 0.03), therefore the degrees of freedom were
corrected using Greenhouse-Geisser estimates of sphericity, E = 0.82 and E = 0.85, respectively.

Statistically signiﬁcant condition × group interactions were found for ﬁve of the 7 CVt tokens:/but/F(2, 34) = 6.52, p < 0.002,
ή2 = 0.150,/set/F(2, 36) = 7.85, p = 0.001, ή2 = 0.171,/sut/F(2,36) = 5.04, p < 0.009, ή2 = 0.117,/zet/F(2,34) = 5.56,
p = 0.006, partial ή2 = 0.130 and/zit/F(2,30) = 4.72, p = 0.007, ή2 = 0.132. Main eﬀects for group showed signiﬁcantly larger F2
frequency extents in AWS compared to ANS for the CVt tokens:/but/F(1,17) = 4.52, p = 0.040,/pet/F(1,18) = 4.04, p = 0.052,
ή2 = 0.096,/sut/F(1,18) = 15.06, p < 0.001 and/zut/F(1,17) = 28.49, p < 0.001, ή2 = 0.435. Main eﬀects for conditions were
found for the CVt token/zut/F(2,34) = 7.20, p = 0.01, ή2 = 0.163. Post hoc analysis assessing simple main eﬀects for group and
conditions for the ﬁve tokens showing a signiﬁcant interaction are discussed below.

3.3.5. Between-condition comparisons

Paired sample t-tests indicated that the same CVt tokens showing signiﬁcantly steeper F2 slopes for the AWS also showed sig-
niﬁcantly larger F2 transition extent under arousing conditions, including/zet/(t (19) = 2.62, p = 0.017) from N to IA/P conditions
and/but/(t (19) = 2.99, p = 0.008) from N to IA/UP conditions. In addition, the same CVt tokens showing signiﬁcantly shallower F2

43

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

Table 3
Absolute values of the raw means and standard deviations (in parenthesis) of F2 frequency transition extent (Hz) for 10 AWS and 10 ANS under Neutral (N), Increased
Arousal/Pleasant (IA/P) and Increased Arousal/Unpleasant (IA/UP) conditions for all 12 CVt tokens.

N

AWS

112.3 (61.6)
295.1 (92.5)
49.5 (17.2)
170.2 (102.6)
136.4 (56.1)
140.3 (73.2)
226.4 (114.7)
416.2 (178.0)
101.6 (60.4)
45.3 (16.6)
510.3 (183.5)
399.4 (135.9)

/pit/
/bit/
/pet/
/bet/
/put/
/but/*
/sit/
/zit/*
/set/*
/zet/*
/sut/*
/zut/

ANS

124.1 (43.5)
95.2 (33.6)
53.7 (23.6)
54.6 (32.2)
260.2 (60.0)
232.3 (53.6)
188.2 (73.0)
277.3 (156.9)
90.1 (62.4)
110.5 (41.4)
225.1 (105.4)
275.7 (111.3)

IA/P

AWS

122.2 (55.3)
360.6 (115.8)
128.9 (53.0)
140.9 (106.6)
134.1 (77.3)
279.7 (62.2)
257.1 (146.8)
382.8 (190.8)
46.2 (21.9)
100.4 (67.5)
365.1 (118.5)
481.1 (178.5)

ANS

76.3 (38.1)
148.1 (62.5)
80.3 (59.3)
63.8 (41.7)
116.5 (70.4)
220.3 (54.7)
174.7 (85.5)
290.9 (118.3)
77.1 (36.5)
83.1 (47.5)
290.3 (126.9)
480.1 (195.3)

IA/UP

AWS

104.1 (49.4)
321.1 (92.7)
91.6 (18.4)
261.2 (61.2)
162.1 (61.8)
219.6 (57.0)
250.3 (111.2)
260.4 (91.1)
78.2 (37.2)
105.4 (61.6)
403.1 (102.1)
396.1 (163.9)

ANS

81.4 (36.9)
128.2 (28.1)
46.7 (15.1)
55.5 (35.3)
337.1 (68.1)
83.5 (32.1)
199.3 (54.28)
315.4 (156.4)
49.1 (21.4)
66.6 (36.5)
234.5 (120.1)
128.7 (78.61)

Note: Hz = Hertz.

* Signiﬁcant group × condition interaction from separate two-way mixed design ANOVAs (p < 0.05).

slopes in the AWS showed a decrease in F2 transition extent under arousing conditions, including/sut/(t (19) = 2.98, p = 0.008)
from N to IA/P conditions and/set/(t (19) = 3.03, p = 0.007),/sut/(t (19) = 2.61, p = 0.017), and/zit/(t (19) = 2.63, p = 0.018)
from N to IA/UP conditions. ANS showed only two signiﬁcant changes in F2 transition extent where a decrease was found from N to
IA/UP for the CVt tokens/but/(t (19) = 3.02, p = 0.007) and/set/(t (19) = 2.12, p = 0.047).

3.3.6. Between-group comparisons:

As indicated in Table 3, independent sample t-tests revealed signiﬁcantly larger F2 transition extents in the AWS compared to the
ANS for the CVt tokens/sut/(p = 0.001) and/zit (p = 0.037) and signiﬁcantly smaller F2 transition extents for the CVt tokens/but/
(p = 0.030) and/zet/(p = 0.007) in the N condition. For the IA/P condition, AWS exhibited signiﬁcantly larger F2 transition extents
compared to the ANS for the CVt token/but/(p = 0.04) and/zit/(p = 0.037) and for the IA/UP condition, signiﬁcantly larger F2
extents in the AWS were found for the CVt tokens/set/(p = 0.003),/sut/(p = 0.012), and/zet/(p = 0.016).

In summary, ﬁve of the 7 CVt tokens showing a signiﬁcant group x condition interaction for F2 slope also showed signiﬁcant
interactions for F2 transition extent including/but/,/set/,/sut/,/zet/, and/zit/. Post hoc analysis for condition eﬀects showed more
instances of changes in F2 frequency extent in the AWS (6 instances) compared to the ANS (2 instances); however the direction of this
change varied with CVt token. More speciﬁcally, when comparing N to arousing conditions in the AWS, the tokens/but/and/zet/
showed an increase in F2 transition extent, while/set/,/sut/and/zit/showed decreases (Table 3). When comparing across groups, post
hoc analysis showed greater F2 transitions extent in the AWS compared to controls (group eﬀect) in two of the CVt tokens in the N
condition increasing to all ﬁve of the CVt tokens in the arousing conditions, the same ﬁve tokens that showed an interaction for F2
transition extent.

3.3.7. F2 frequency duration

F2 frequency duration was conducted for those 7 CVt tokens that yielded signiﬁcant group × condition interactions for F2 slopes.
There was homogeneity of variances for all CVt words (p > 0.05) as assessed by Levene’s test for equality of variances. There was
sphericity for the interaction term, as assessed by Mauchly’s test of sphericity (p > 0.05) for all CVt tokens.

Main eﬀects for condition were found for the CVt token/zut/, F (2,34) = 7.65, p = 0.001, ή2 = 0.168. No other signiﬁcant eﬀects
for condition were found (p > 0.05). Descriptive analysis showed (Table 4) that all 7 of the CVt tokens that yielded an interaction for
F2 slope were produced at a slower rate in the AWS compared to the ANS and three of the CVt tokens showed signiﬁcant group main
eﬀects including/but/, F(1,17) = 23.16, p < 0.001, ή2 = 0.385,/zit/, F(1, 15) = 21.55, p < 0.001, ή2 = 0.362, and/zut/, F(1,17)
= 10.11, p = 0.003, ή2 = 0.211. There was a statistically signiﬁcant group x condition interaction for F2 transition duration for the
CVt tokens/sut/, F (2, 36) = 9.31, p = 0.001, ή2 = 0.197 and/zet/, F(2,34) = 3.07, p = 0.034, ή2 = 0.075. Post hoc analysis as-
sessing group or condition eﬀects did not show signiﬁcant diﬀerences in F2 frequency duration when compared across conditions or
between groups.

In summary, descriptive analysis showed slower F2 frequency duration in the AWS compared to the ANS; however, only two CVt

tokens showed a signiﬁcant group × condition interaction. There were no signiﬁcant diﬀerences across groups or condition.

4. Discussion

The primary purpose of this study was to assess the changes in acoustic parameters associated with F2 slope in response to
emotion in AWS compared to ANS. It was predicted that AWS would show greater change in F2 slope when speaking under arousing
conditions. More speciﬁcally, it was thought that AWS would show slower movements in response to arousal that would subsequently
lead to decreases in F2 slopes. This was based on the premise that AWS show slower reaction times under anxiety driven tasks (e.g.

44

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

Table 4
Overall means and standard deviations (in parenthesis) of F2 frequency transition durations(ms) from raw data for 10 AWS and 10 ANS under Neutral (N), Increased
Arousal/Pleasant (IA/P) and Increased Arousal/Unpleasant (IA/UP) conditions for all 12 CVt tokens.

N

AWS

60.1 (14.9)
71.6 (29.1)
56.4 (14.3)
72.2 (16.5)
73.5 (15.0)
77.6 (15.2)
71.6 (20.8)
84.2 (18.0)
63.5 (14.9)
69.4 (13.5)
79.2 (29.0)
73.2 (13.3)

ANS

52.3 (14.2)
57.5 (13.1)
50.7 (11.4)
68.1 (32.2)
58.2 (16.2)
60.6 (17.6)
47.9 (15.7)
63.3 (34.4)
56.5 (10.5)
65.8 (14.5)
58.3 (17.5)
58.6 (25.7)

IA/P

AWS

52.9 (17.3)
71.1 (25.4)
55.2 (10.4)
67.1 (19.6)
65.3 (17.5)
71.1 (19.9)
70.1 (15.0)
79.5 (42.4)
65.2 (16.8)
69.6 (18.2)
69.4 (22.5)
101.6(47.0)

ANS

51.3 (16.0)
56.7 (11.1)
48.7 (10.1)
62.8 (12.6)
51.7 (19.7)
57.8 (6.3)
47.8 (13.1)
59.6 (34.1)
59.5 (11.5)
56.1 (14.3)
49.7 (10.4)
77.8 (37.0)

IA/UP

AWS

58.7 (18.9)
70.3 (10.1)
53.1 (12.8)
62.5 (21.4)
71.1 (16.0)
73.6 (10.5)
66.4 (15.5)
80.8 (23.3)
65.2 (16.9)
78.6 (24.5)
78.6 (22.6)
91.1 (16.6)

ANS

51.7 (12.5)
56.5 (12.5)
48.9 (10.8)
60.3 (8.2)
60.1 (19.5)
60.5 (8.3)
46.9 (14.0)
60.3 (21.9)
57.8 (17.7)
58.4 (14.7)
42.4 (22.4)
55.6 (17.2)

/pit/
/bit/
/pet/
/bet/
/put/
/but/
/sit/
/zit/
/set/
/zet/*
/sut/*
/zut/

Note: ms = milliseconds.

* Signiﬁcant group × condition interaction from separate two-way mixed design ANOVAs (p < 0.05).

Hennessey et al., 2014), perhaps due to limitations in speech motor skills (Namasivayam & van Lieshout, 2011), which would lead
them to be more susceptible to motoric breakdown under emotional inﬂuences. The main ﬁndings emerging from this study partly
support this hypothesis as the AWS showed greater changes in F2 slope under emotional conditions when compared to controls.
However, contrary to our assumption, AWS showed steeper slopes, with either a rising or falling trajectory, for 7 out of 12 CVt tokens
when they performed under emotional versus N conditions. Further analysis of F2 transition extent and F2 transition duration showed
that the steeper slopes were primarily due to the AWS showing larger extent of movement when speaking under arousing (positive
and negative) versus N conditions. More speciﬁcally results showed all ﬁve of the CVt tokens showing a signiﬁcant group x condition
interaction for F2 slope showed signiﬁcantly larger F2 transition extent in at least one of the arousing conditions. Descriptive analysis
revealed that this was due to the AWS showing either signiﬁcant increases or decreases in their extent of movement in response to
emotion. Although descriptive analysis revealed slower F2 transition durations across CVt tokens and emotional conditions in the
AWS compared to controls, their speed of movement did not appear to change with emotion. Group diﬀerences in emotional re-
activity could not be veriﬁed with Fo measures as AWS did not signiﬁcantly diﬀer from ANS when speaking under arousing con-
ditions.

4.1. Impact of emotion on Fo

Previous research has found increases in Fo to be associated with an increase in emotional reactivity (Ruiz, Absil, Harmegnies,
Legros, & Poch, 1996; Hagenaars & van Minnen, 2005). The current ﬁndings do not support these studies as the increases in Fo in both
groups when speaking under the arousing versus N conditions were nonsigniﬁcant. At the same time, both groups self-reported (i.e.
SAM) that the images in IA/P and IA/UP conditions were more arousing than the images in the N conditions. Results are consistent
with Goberman et al. (2011) where no signiﬁcant correlations were found between mean Fo across two diﬀerent public speaking
tasks. Goberman et al. (2011) suggested that the emotional stimuli used in their study may not have elicited high enough levels of
anxiety to be detected by measures of mean Fo. Many of the participants in their study were college students with no pre-existing
anxiety disorders and who may have had previous experiences with classroom presentations. This suggestion may explain why no
signiﬁcant diﬀerences were found in the current study. Future studies incorporating physiological measures such as skin conductance
and heart rate would allow direct comparisons of changes in autonomic arousal and vocal fold vibration frequency.

4.2. Impact of emotion on error rate and stuttering frequency

No signiﬁcant diﬀerences in errors were found for either group across conditions, nor were there diﬀerences in stuttering fre-
quency for the AWS. This is most likely due to the relatively simple nature of the task. These results were expected as the goal was to
assess the eﬀects of emotion on the integrity of the speech-motor system and to not tap into changes associated with added motoric or
cognitive demands.

4.3. Changes in F2 slope in response to emotion

While either a rising or falling trajectory was observed for F2 slope, the overall trend was for AWS to show more instances of
change across conditions compared to the ANS. Post hoc analysis for between condition comparisons indicated that ﬁve of the 7 CVt
tokens eliciting signiﬁcant interactions were due to the AWS showing either signiﬁcantly steeper F2 slopes under the IA/P (i.e./pet/
,/zet/) and/or IA/UP (i.e./but/,/pet/,/zet/) or shallower F2 slopes under the IA/P (i.e./sut/) and IA/UP (i.e./sut/) conditions
compared to the N condition. ANS only showed one instance of an F2 slope increase and that was from the N and IA/UP condition

45

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

for/sut/. Post hoc analysis assessing between group comparisons also indicated signiﬁcantly steeper F2 slopes in the AWS compared
to the ANS for 6 tokens during N (/sut/, IA/P (/bit/), and IA/UP (/but/,/pet/,/zut/) conditions; while ANS showed signiﬁcantly
steeper slopes for three tokens during N (/zet/), IA/P (/set/) and IA/UP/zit/). More instances of change in F2 slope in the AWS
suggest that their speech-motor systems were more susceptible to changes from emotion compared to controls. Given that F2 slope is
a reﬂection of the rate change in F2 frequency extent and duration with, in this case, a consonant-vowel transition, a discussion of
these two variables are provided with an attempt to explain the changes observed in F2 slope.

4.4. Changes in F2 transition extent and duration in response to emotion

When considering changes in F2 transition extent and duration of articulatory movement, the most notable group diﬀerence was
found in the AWS’ change in extent of articulatory movement when producing CVt tokens under N versus arousing conditions. Five
out of the 7 CVt tokens that showed a signiﬁcant group x condition interaction for F2 slope also showed a group x interaction for F2
frequency extent (i.e./but/,/zit/,/set/,/zet/,/sut/) and post hoc analysis of condition contrasts indicated this was largely due to the
AWS showing greater changes in F2 extent across conditions compared to controls. Consistent with previous studies (Dehqan et al.,
2016; Robb & Blomgren, 1997; Subramanian et al., 2003), larger articulatory displacement further support speech-motor control
limitations (Namasivayam & van Lieshout, 2008) in AWS that render them more vulnerable to emotional inﬂuences. Supporting
evidence can be found in Caruso et al. (1994), where larger articulatory displacements were found in AWS when producing the word
“blue” under cognitively stressful conditions. It is possible that larger articulatory changes, either increasing or decreasing, was a
strategy used by the AWS in an attempt to stabilize the speech-motor system (Van Lieshout et al., 2004; Namasivayam & van Lieshout,
2011). Their increases in speed of movement, although nonsigniﬁcant suggests that their response to the emotional stimuli was
similar to controls. However, the demand to increase their speed of movement may have exceeded their motoric capacity
(Starkweather & Gottwald, 1990), resulting in a potential breakdown to occur. It is possible that changes in articulatory extent was an
attempt to stabilize the system.

Not all the CVt tokens exhibited larger F2 extent in the AWS, however. A diﬀerent pattern for the CVt tokens/zit/and/set/emerged
where a decrease in F2 transition extents in the AWS occurred during the arousing conditions. While smaller articulatory extents in
AWS is not consistent with previous literature (e.g. Dehqan et al., 2012), more recent evidence suggests that a decrease in articulatory
movement may reﬂect an increase in muscle tension when speaking under cognitively stressful tasks (Jackson, Tiede, Beal, & Whalen,
2016).

F2 transition extent is an indirect measure of articulatory movement and as a result leave questions as to what articulator (s) are
showing the displacement diﬀerences. When reviewing studies employing kinematic analysis, larger articulatory displacements in
response to anxiety have been reported (Kleinlow & Smith, 2005) but not in all cases. Van Lieshout et al. (2014) found reduced upper
lip amplitude in AWS when producing “stuttering-speciﬁc” stress words, a modiﬁed emotional Stroop test. While the current study
did not employ a cognitively stressful task, it used images that elicited similar feelings of arousal that ranged in valence. Many images
falling within the IA/UP condition, for instance, were similar in content to the “threat” words used in van Lieshout et al.’s (2014)
emotional Stroop task such as “attack”, “mutilation”, and “death”. One reason why larger movement extents were found in the
current study may be due to the diﬀerences in stimuli. The images used in the current study have been standardized on the basis of
valence and arousal and have been proven to have a strong evocative ability (Bradley & Lang, 2007).

Although nonsigniﬁcant, F2 frequency duration revealed an overall trend for the ANS to increase their speed in response to
speaking under arousing conditions. This was not always the case for the AWS. Faster movement is what is generally reported in
motor control studies assessing the eﬀects of arousal on motor control in the non-disordered population using tasks ranging from
ﬁnger tapping (Lee et al., 2015) to pinch-grip tasks (Coombes et al., 2005). It is assumed that heightened emotion increases sym-
pathetic nervous system activity, which in turn elicits faster movement in the case of increased arousal. This is what was expected in
the ANS but due to previous studies reporting slower reaction times in AWS when speaking under anxiety − driven conditions
(Hennessey et al., 2014), it was predicted that the AWS would slow down their consonant-vowel transitions when speaking under
arousing conditions. This was not always the case, however, as descriptive analysis showed that for the majority of the CVt tokens, the
AWS exhibited faster F2 frequency durations under arousing versus N conditions, albeit at a slower rate than the ANS.

4.5. Diﬀerences between CVt tokens

The majority of CVt tokens showing a group x condition interaction for slope included an initial fricative sound with alveolar
placement (/s/or/z/). These phonemes are considered strident fricatives with a high frequency noise. It may be possible that the
coordination required to transition in frequency from a very high frequency fricative to a low frequency vowel may have challenged
the motor system in the AWS. Diﬀerences in F2 transition, particularly with words containing an initial fricative, have been reported
in other studies assessing both children and adults who stutter (Robb et al., 1997; Subramanian et al., 2003). Therefore, group
diﬀerences may reﬂect diﬀerences in co-articulation in the AWS, a diﬀerence that may surface when under emotional challenge.

4.6. Diﬀerences between positive and negatively valenced stimuli

Although the IAPs images used in the current study have been shown through normative ratings to elicit similar levels of arousal,
post hoc analysis showed no diﬀerences in F2 extent, duration or slope between the IA/P and IA/UP conditions. Also measures of
mean Fo between the pleasant and unpleasant conditions were nonsigniﬁcant. Diﬀerences in physiological and motor behavior in

46

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

response to viewing pleasant versus unpleasant images have not been clearly deﬁned in the literature (Bradley, Codispoti,
Sbatinelli, & Lang, 2001; Coombes et al., 2011). Studies assessing heart rate changes in response to emotional stimuli have reported
that when viewing pictures of increased arousal, the pattern of acceleration and deceleration of heart rate was aﬀected by hedonic
valence. When including a movement task, Coombes et al. (2005) found that negatively valenced cues result in faster movement,
suggesting that while both pleasant and unpleasant stimuli aﬀect movement, the defensive circuitry triggered by unpleasant stimuli
elicits a stronger response on the motor control system. The inclusion of physiological measures such as heart rate may help
strengthen an understanding of the eﬀects of emotional valence on the speech-motor system.

4.7. Limitations

Future investigations assessing the relationship between emotion and speech-motor control is warranted using larger sample sizes.
One of the reasons why there were inconsistencies across CVt tokens may be due to the inherent diﬀerences in articulatory move-
ments required to produce the range of consonant – vowel combinations under analysis. This has been the case in previous studies
(e.g. Dehqan et al., 2016). Also, the CVt tokens may have been too simplistic in nature to elicit large enough changes across groups.
This assumption stems from the low number of errors and frequency of stuttering that was found across conditions. Future research
may, therefore, want to consider assessing formant changes using consonant-vowel transitions that are embedded in longer and/or
more complex utterances. Also, the formant analysis used in the current study may not have been sensitive enough to track subtle
changes in articulatory movement across conditions. Perhaps kinematic analysis measuring lip and/or tongue movement would have
revealed more robust diﬀerences across CVt tokens (e.g. Yunusova et al., 2012). Finally, the incorporation of physiological measures
of sympathetic and parasympathetic activity into future study paradigms will provide a more objective measure of emotional re-
activity and regulation and allow a more advanced understanding of how these processes eﬀect speech-motor control in both the
stuttering and nonstuttering populations.

5. Conclusions

While the majority of research assessing emotion and stuttering has focused on behavioral changes (e.g. stuttering frequency) in
response to anxiety, the current study indicated that AWS show diﬀerences in articulatory movement under heightened arousal,
regardless of valence. Main ﬁndings indicated that when speaking under arousing versus N conditions, the AWS showed greater
changes in articulatory movement compared to the ANS. Descriptive analysis revealed an increase in speed of movement for both
groups, although mostly nonsigniﬁcant when comparing across groups and conditions. Perhaps the increase in speed of movement
shown in the AWS may have placed added demands on their speech motor system, thus rendering them more vulnerable to
breakdown. In response, AWS made adjustments in their extent of movement in an attempt to maintain stability. Findings from this
study are preliminary in nature but lend support for future investigations into the relationship between emotion and speech-motor
control in the stuttering population.

Conﬂict of interest

There is no ﬁnancial/personal interest or belief that could aﬀect the objectively of this study.

Acknowledgements

This work was supported by the Oﬃce of Sponsored Research at State University of New York, Plattsburgh. Portions of this work
were presented at the 2015 ASHA convention. The authors thank Ashley Dasilva-Leclerc for her help in data analysis. The authors
also thank the participants of this study for their time.

References

Alm, P. (2004). Stuttering, emotions, and heart rate during anticipatory anxiety: a critical review, 29, 123–133.
Alm, P. A. (2014). Stuttering in relation to anxiety, temperament: and personality. Review andanalysis with focus on causality. Journal of Fluency Disorders, 40, 5–21.
AudacityTeam (2014). Audacity
: Free audio editor and recorder [computer program]. Version 2.0.0. Retrieved September, 2014 from http://audacity.sourceforge.

®

net.

Bauerly, K. R., & De Nil, L. F. (2011). Speech sequence skill learning in adults who stutter. Journal of Fluency Disorders, 36, 349–360.
Boersma, P. (2001). PRAAT, a system for doing phonetics by computer. Glot International, 5(9/10), 341–345.
Bowers, A., Saltuklaroglu, T., & Kalinwoski, J. (2012). Autonmic arousal in adults who stutter prior to various reading tasks intended to elicit changes in stuttering

frequency. Journal of Psychophysiology, 83, 45–55.

Bradley, M. M., & Lang, P. J. (1994). Measuring emotion: The self-assessment manikin and the semantic diﬀerential. Journal of Behavioral Therapy and Experimental

Psychiatry, 25, 49–59.

Bradley, M., & Lang, P. (2007). The International Aﬀective Picture System (IAPS) in the Study of Emotion and Attention. In J. Coan, & J. Allen (Eds.). Handbook of

Emotion Elicitation and Assessment (pp. 29–46). New York: Oxford University Press.

Brundage, S. B., Graap, K., Gibbons, K. F., Ferrer, M., & Brooks, J. (2006). Frequency of stuttering during challenging and supportive virtual reality job interviews.

Journal of Fluency Disorders, 31(4), 325–339.

Caruso, A., Chodzko-Zajki, W. J., Bidinger, D. A., & Sommers, R. K. (1994). Adults who stutter: Responses to cognitive stress. Journal of Speech and Hearing Research, 37,

746–754.

Chang, S., Ohde, R., & Conture, E. (2002). Coarticulation and formant transition rate in young children who stutter. Journal of Speech, Language, and Hearing Research,

45, 676–688.

47

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

Chen, M., & Bargh, J. A. (1999). Consequences of automatic evaluation: Immediate behavioral predispositions to approach or avoid the stimulus. Personality and Social

Psychology Bulletin, 25(2), 215–224.

Choi, D., Conture, E. G., Walden, T. A., Lambert, W. E., & Tumanova, V. (2013). Behavioral inhibition and childhood stuttering. Journal of Fluency Disorders, 38(2) 171-

171-183.

Civier, O., Tasko, S. M., & Guenther, F. H. (2010). Overreliance on auditory feedback may lead to sound/syllable repetitions: Simulations of stuttering and ﬂuency-

inducing conditions with a neural model of speech production. Journal of Fluency Disorders, 35(3), 246–279.
Coan, J., & Allen, J. (2007). Handbook of Emotion Elicitation and Assessment. New York: Oxford University Press.
Conture, E. G., Kelly, E. M., & Walden, T. A. (2013). Temperament, speech and language: An overview. Journal of Communication Disorders, 46(2), 125–142.
Coombes, S. A., Cauraugh, J. H., & Janelle, C. M. (2006). Emotion and movement: Activation of defensive circuitry alters the magnitude of a sustained muscle

contractions. Neuroscience Letters, 396(3), 192–196.

Coombes, S. A., Janelle, C. M., & Duley, A. R. (2005). Emotion and motor control: Movement attributes following aﬀective picture processing. Journal of Motor

Behavior, 37(6), 425–436.

Coombes, S. A., Naugle, K. M., Barnes, R., Cauraugh, J., & Janelle, C. (2011). Emotional reactivity and force control: The inﬂuence of behavioral inhibition. Human

Movement Science, 30, 1052–1061.

Cuthbert, B. N., Bradley, M. M., Zabaldo, D., Martinez, S., & Lang, P. J. (1994). Images for all ages: Women and emotional reactions. Psychophysiology, 31, S37.
Cuthbert, B. N., Schupp, H. T., Bradley, M. M., Birbaumer, N., & Lang, P. J. (2000). Brain potentials in aﬀective picture processing: Covariation with autonomic arousal

and aﬀective report. Biological Psychology, 52, 95–111.

Dehqan, A., Yadegari, F., Blomgren, M., & Scherer, R. (2016). Formant transitions in theﬂuent speech of Farsi-speaking people who stutter. Journal of Fluency Disorders,

48, 1–15.

Ferrand, C. (2014). Speech Science: An Integrated Approach to Theory and Clinical Practice. NJ: Pearson Education: Upper Saddle River.
Goberman, A. M., Hugues, S., & Haydock, T. (2011). Acoustic characteristics of public speaking: Anxiety and practice eﬀects. Speech Communication, 53(2), 867–876.
Greenwald, M. K., Cook, E. W., & Lang, P. J. (1989). Aﬀective judgment and psycophysiological response: Dimensional co-variation in the evaluation of pictorial

stimuli. Journal of Psychophysiology, 3, 51–64.

Gross, M. M., Crane, E. A., & Fredrickson, B. L. (2012). Eﬀort-Shape and kinematic assessment of bodily expression of emotion during gait. Human Movement Science,

31(1), 202–221.

Guitar, B. (2004). Stuttering (3rd ed.). Baltimore, MD: Lippincott Williams & Williams.
Hagenaars, M. A., & van Minnen, A. (2005). The eﬀect of fear on paralinguistic aspects of speech in patients with panic disorders with agrophobia. Anxiety Disorders,

19, 521–537.

Hajcak, G., Molnar, C., George, M., Bolger, K., Koola, J., & Nahas, Z. (2007). Emotion facilitates action: A transcranial magnetic stimulation study of motor cortex

excitability during picture viewing. Psychophysiology, 44, 91–97.

Hennessey, N., Dourado, E., & Beilby, J. (2014). Anxiety and speaking in people who stutter: An investigation using the emotional Stroop task. Journal of Fluency

Disorders, 40, 44–57.

Howell, P., & Vause, L. (1986). Acoustic analysis and perception of vowels in stuttered speech. Journal of the Aoucstical Society of America, 79, 1571–1579.
Huinch, W. J., Wouters, E. H. A., Hulstijn, W., & Peters, H. F. M. (2001). Diﬀerences between stuttering and non-stuttering people: Comparing diadochokinesis,

sentence repetition, and reaction time tasks. In B. Maasen, W. Hulstijn, R. D. Kent, H. F. M. Peters, & P. H. H. M. van Lieshout (Eds.). Speech motor control in normal
and disordered speech: Proceedings from the fourth international speech motor conference (pp. 311–315). Nijmegen, The Netherlands: Uitgeverij Vantilt.

Jones, Buhr, A., Conture, E., Tumanova, V., Walden, T., & Porges, S. (2014). Autonomic nervous system activity of preschool-age children who stutter. Journal of

Fluency Disorders, 41, 12–31.

Karrass, J., Walden, T. A., Conture, E. G., Graham, C. G., Arnold, H. S., Hartﬁeld, K. N., et al. (2006). Relation of emotional reactivity and regulation to children who

stutter. Journal of Communication Disorders, 48, 38–51.

Kim, J., Toutios, A., Lee, S., & Narayanan, S. (2015). A kinematic study of critical and non-critical articulators in emotional speech production. Journal of Acoustic

Society of America, 137, 1411–1415.

Kuo, C. (2013). Format transitions in varied utterance positions. Folia Phoniatrica et Logopaedica, 65, 178–184.
Lang, P. J., Bradley, M. M., & Cuthbert, B. N. (2008). International aﬀective picturesystem (IAPS): Aﬀective ratings of pictures and instruction manual. Technical Report A-

8Gainesville, FL: University of Florida.

Lee, P., Tsui, W., & Hsiao, T. (2015). The inﬂuence of emotion on keyboard typing: An experimental study using visual stimuli. PLos One, 10(6), 1–16.
Loucks, T. M. J., & De Nil, L. F. (2001). Oral kinesthetic deﬁcit in stuttering evaluated by movement accuracy and tendon vibration. In B. Maassen, W. Hulstijn, R. Kent,

H. F. M. Peters, & P. H. H. M. Van Lieshout (Eds.). Speech motor control in normal and disordered speech. New York, NY: Oxford University Press.

Max, L., & Caruso, A. J. (1998). Adaptation of stuttering frequency during repeated readings: Associated changes in acoustic parameters of perceptually ﬂuency speech.

Journal of Speech, Language, 41, 1265–1281.

Max, L., Guenther, F. H., Gracco, V. L., Ghosh, S. S., & Wallace, M. E. (2004). Unstable or insuﬃciently activated internal models and feedback-biased motor-control as

sources of dysﬂuency: A theoretical model of stuttering. Contemporary Issues in Communication Science and Disorders, 31, 105–122.

Namasivayam, A., & van Lieshout, P. (2008). Investigating speech motor practice and learning in people who stutter. Journal of Fluency Disorders, 33(1), 32–51.
Namasivayam, A., & van Lieshout, P. (2011). Speech motor skill and stuttering. Journal of Motor Behavior, 43, 477–489.
Oldﬁeld, R. (1971). The assessment and analysis of handedness. The Edinburgh Inventory.
Owren, M. J., & Bachorowski, J. (2007). Measuring emotion-related vocal acoustics. In J. Coan, & J. Allen (Eds.). Handbook of Emotion Elicitation and Assessment (pp.

29–46). New York: Oxford University Press.

Riley, G. D. (1994). Stuttering severity instrument for children and adults. Austin, TX: Pro-Ed.
Robb, M., & Blomgren, M. (1997). Analysis of F2 transitions in the speech of stutterers and nonstutterers. Journal of Fluency Disorders, 22, 1–16.
Robb, M., Blombren, M., & Chen, Y. (1998). Formant frequency ﬂuectuation in stuttering and nonstuttering adults. Journal of Fluency Disorders, 23, 73–84.
Ruiz, R., Absil, E., Harmegnies, B., Legros, C., & Poch, D. (1996). Time- and specrum-related variability in stressed speech under laboratory and real conditions. Speech

Communication, 20, 111–129.

Smith, A., & Kelly, E. (1997). Stuttering: A dynamic, multifactoral model. In R. Curlee, & Siegal (Eds.). Nature and treatment of stuttering: New directions (pp. 204–218).

(2nd ed.). Boston: Allyn & Bacon.

Smith, A., & Kleinow, J. (2000). Kinematic correlates of speaking rate changes inn stuttering and normally ﬂuent adults. Journal of Speech, Language, and Hearing

Research, 43, 521–536.

Smits-Bandstra, S., De Nil, L. F., & Saint-Cyr, J. A. (2006). Speech and nonspeech sequence skill learning in adults who stutter. Journal of Fluency Disorders, 31,

116–136.

Subramanian, A., Yairi, E., & Amir, O. (2003). Second formant transitions in ﬂuent speech of persistent and recovered preschool children who stutter. Journal of

Communication Disorders, 36, 59–75.

Sussman, H. M., Bessell, N., Dalston, E., & Majors, T. (1997). An investigation of stop place of articulation as a function of syllable function: A locus equation

perspective. Journal of the Acoustical Society of America, 101, 2826–2838.

Starkweather, C. W., & Gottwald, S. R. (1990). The demands and capacities model II: Clinical applications. Journal of Fluency Disorders, 15, 143–157.
Van Lieshout, P. H. H. M., Hulstijn, W., & Peters, H. F. M. (2004). Searching for the weak link in the speech production chain of people who stutter: A motor skill
approach. In B. Maassen, R. Kent, H. F. M. Peters, P. van Lieshout, & W. Hulstijn (Eds.). Speech motor control in normal and disordered speech (pp. 313–356). Oxford,
UK: Oxford University Press.

Van Lieshout, P., Ben-David, B., Lipski, M., & Namasivayam, A. (2014). The impact of threat and cognitive stress on speech motor control in people who stutter. Journal

of Fluency Disorder, 40, 93–109.

Weber, C. M., & Smith, A. (1990). Autonomic correlates for stuttering and speech assessed in a range of experimental tasks. Journal of Speech and Hearing Research, 33,

690–706.

48

K.R. Bauerly, J. Paxton

Journal of Fluency Disorders 54 (2017) 35–49

Yairi, E., & Ambrose, N. (2005). Early childhood stuttering: For clinicians by clinicians. Austin, TX: Pro-Ed.
Yaruss, S., & Conture, E. (1993). F2 transitions during sound/syllable repetitions of children who stutter and predictions of stuttering chronicity. Journal of Speech and

Hearing Research, 36, 883–896.

Yunusova, Y., Green, J. R., Greenwood, L., Wang, J., Pattee, G. L., & Zinman, L. (2012). Tongue movements and their acoustic consequences in Amyotrophic Lateral

Scherosis. Folia Phoniatrica et Logopaedica, 64, 94–102.

Kim Bauerly, Ph.D., is an Assistant Professor at the Department of Communication Sciences and Disorders at SUNY Plattsburgh. Her research interests include
investigating the relationship between emotion and cognitive demands on the speech-motor systems in children and adults who stutter.

Jessica Paxton is an Assistant Professor of Psychology at SUNY Plattsburgh. She has a Ph.D. in Clinical Psychology from Washington University in St. Louis. Dr. Paxton
currently teaches classes in Biopsychology and Neuropsychology and conducts neuropsychological evaluations in an outpatient clinic. Her research focuses on ex-
ecutive control abilities in healthy and clinical populations using neuropsychological and experimental measures.

49
```