# 1-s2.0-S0094730X17300438-main (1)

```
Journal of Fluency Disorders 57 (2018) 11–21

Contents lists available at ScienceDirect

Journal of Fluency Disorders

journal homepage: www.elsevier.com/locate/jﬂudis

Backward masking of tones and speech in people who do and do
not stutter
⁎

Shriya Basu

, Robert S. Schlauch, Jayanthi Sasisekaran

T

Department of Speech -Language-Hearing Sciences, University of Minnesota, United States

A R T I C L E I N F O

A B S T R A C T

Keywords:
Backward masking
Stuttering
PWS

Purpose: There is evidence of an auditory-perceptual component of stuttering, and backward
masking (BM) is a task to explore that role. Prior research reported poorer thresholds for BM
tones in a group of children who persisted in stuttering compared to those for a group that did not
persist. This study examined BM for adults who stutter for tones and for speech, which tests a
phonetic aspect of hearing.
Method: Eight persons who stutter (PWS) were closely matched with eight controls (PNS) in
terms of phonological abilities, verbal span tasks, age, sex and non-verbal intelligence. These
participants were examined for their ability to recognize vowel-consonant (VC) speech syllables
and tones in BM paradigm with 0 ms and 300 ms masker to signal onset conditions.
Results: PWS showed signiﬁcantly poorer performance for speech syllable recognition in quiet
and in conditions with masking noise. The pattern of speech errors was similar in both groups,
but the PWS produced more errors. A signiﬁcant condition by group interaction in backward
masking for tones was attributed to higher masked thresholds in PWS than in PNS in the 0 ms
delay condition for BM for tones.
Conclusion: This was the ﬁrst study to examine BM for speech in PWS. Results provide support for
a small auditory-perceptual deﬁcit for speech understanding in adults who stutter that was re-
vealed in the absence of a lexical context. The speech results are explained in terms of possible
indistinct phoneme boundaries in PWS and the eﬀects of vowel context in speech recognition.

1. Introduction

Stuttering is deﬁned as disruptions in the ﬂuency of verbal expression that are characterized by involuntary silent or audible
repetitions and prolongation of speech elements that are frequent and not readily controllable (Wingate, 1988). Stuttering is a
multifactorial, neurodevelopmental disorder that involves motor, linguistic, social and emotional factors (Yairi & Seery, 2011).

Physiological studies show diﬀerences in brain activation (Braun et al., 1997; Etchell, Civier, Ballard, & Sowman, 2018) and
neuroanatomical studies show diﬀerences in white matter and connecting tracks (Chang, Erickson, Ambrose, Hasegawa-Johnson, &
Ludlow, 2008; Kronfeld-Duenias, Civier, Amir, Ezrati-Vinacour, & Ben-Shachar, 2018; Loucks, Kraft, Choo, Sharma, & Ambrose,
2011) when comparing persons who stutter (PWS) and persons who do not stutter (PNS). There are widespread brain diﬀerences but
the largest diﬀerences are noted in motor and pre-motor areas associated with speech production in auditory-motor integration and
the corresponding interconnecting tracts (Chang et al., 2008, 2017; Kell et al., 2009; Kell, Neumann, Behrens, von Gudenberg, &

⁎

Corresponding author at: Department of Speech-Language-Hearing Sciences, University of Minnesota, 115 Shevlin Hall, 164 Pillsbury Drive,

Minneapolis, MN, 55414, United States.

E-mail address: basux045@umn.edu (S. Basu).

https://doi.org/10.1016/j.jﬂudis.2018.07.001
Received 17 April 2017; Received in revised form 31 May 2018; Accepted 18 July 2018

Available online 20 July 2018
0094-730X/ © 2018 Elsevier Inc. All rights reserved.

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

Giraud, 2017; Chang et al., 2018; Watkins, Smith, Davis, & Howell, 2008).

Although most of the physiological and anatomical evidence reveals the greatest diﬀerences between PWS and PNS in areas of the
brain associated with speech-motor planning, there is evidence of an auditory-perceptual component. Auditory-perceptual connec-
tions to stuttering are based on reports from disparate kinds of anecdotal survey observations and experimental evidence. For in-
stance, surveys of teachers revealed that stuttering has an extremely low prevalence in children with hearing impairment (Harms &
Malone, 1942; Montgomery & Fitch, 1988). Additional evidence comes from studies that evaluate speech with altered auditory
feedback, such as a delay (Goldiamond, 1965), altered frequency (Howell, El-Yaniv, & Powell, 1987) or the presence of a noise
masker (Maraist & Hutton, 1957). Many studies have reported that dysﬂuencies are decreased in PWS when presented with delayed
auditory feedback (DAF) (Stuart, Kalinowski, & Rastatter, 1997; Stuart, Kalinowski, Rastatter, Saltuklaroglu, & Dayalu, 2004). DAF
reduces dysﬂuencies and also results in a slower speech rate in PWS. The slower rate of speech production by itself does not explain
the reduced rate of dysﬂuencies in PWS because Kalinowski, Armson, Stuart, and Gracco, (1993) found the reduction even when the
altered speech was produced at a rapid rate.

For decades, researchers have sought experimental evidence of an auditory perceptual task that uniquely separates PWS from
PNS. Stuttering is thought of as a disorder of speech production so an auditory perceptual ﬁnding would provide insights into the
mechanisms of stuttering. Prior auditory perceptual studies have used stimuli containing speech and non-speech sounds. The stimuli
in these perceptual studies are designed to assess temporal processing and/or brainstem integration from the two ears.

The speech task most commonly assessed in prior studies is synthetic sentence identiﬁcation. The stimuli for this test are a closed
set of grammatically correct artiﬁcial sentences that were designed to have the same length and information content (Hall & Jerger,
1978). These sentences are presented along with a competing message of continuous discourse, either to the same ear as the target
sentences or to the opposite ear. Performance is documented for diﬀerent signal to noise ratios which are also referred to as message
to competition ratios (MCRs). As the MCR becomes smaller in decibels, the task of listening for the target sentence in the presence of
the time varying competition talker’s speech becomes more diﬃcult. Some studies found that PWS show poorer scores than PNS for a
given MCR, but only when the sentences and competing talker are presented to the same ear (Toscher & Rupp, 1978). Other studies
showed no diﬀerence for either condition (Kramer, Green, & Guitar, 1987).

One non-speech auditory task is the determination of the tonal masking level diﬀerence (MLD). The MLD is a binaural measure of
the ability to detect a tone or speech in the presence of noise (Olsen, Noﬀsinger, & Carhart, 1974). The typical setup in studies of PWS
report the thresholds for a low-frequency tone measured under two conditions. In a baseline condition, the noise is in-phase at the
two ears and so is the tone. In the “masking release” condition, the tone is presented to the two ears 180 degrees out of phase while
the noise remains in-phase. In typical listeners, the auditory system can take advantage of the timing or phase diﬀerence from the two
ears and thresholds improve by as much as 10 dB or more. Some studies have reported a smaller masking release in PWS (Kramer
et al., 1987; Liebetrau & Daly, 1981), while others have failed to do so (Asal & Abdou, 2014). Since ﬁndings from the older studies
were not replicated in most recent study, it is inconclusive that PWS are diﬀerent in masking level diﬀerence tasks from typically
ﬂuent individuals.

Another non-speech auditory task is backward masking. In a backward masking task, the detection threshold for a target stimulus,
usually a tone, is found in a quiet background and in the presence of a masking noise that is presented immediately after the tone is
terminated. The decibel diﬀerence in the thresholds for the two conditions (quiet and in the presence of the noise masker) represents
the amount of “backward” masking.

Howell and colleagues have published three studies of backward masking using children as participants. Howell, Rosen,
Hannigan, and Rustin, (2000), with a sample size of 10 children, found a greater amount of masking in children who stutter (CWS)
than in the control group. Although the two groups had some overlap in the amount of masking observed, statistically signiﬁcantly
greater amount of masking was found in CWS. A second study of backward masking in children examined its developmental trends
and the amount of masking in CWS and a typically ﬂuent group (Howell & Williams, 2004). CWS showed continued improvement of
backward masking with age late into their teens, which was a diﬀerent pattern than observed for the typically ﬂuent children who
reached asymptotic performance at an earlier age. In this study of 37 CWS and 44 typically ﬂuent children, backward masked
thresholds were not signiﬁcantly diﬀerent in the two groups. A third study (Howell, Davis, & Williams, 2006) followed 30 children
who were initially diagnosed as stutterers and, as they aged, split into two groups: children who persisted in stuttering and those who
recovered. Thresholds were obtained for ﬁve diﬀerent listening conditions that involved pure tones as stimuli and diﬀerent maskers
for the backward masking that included a notched noise. A comparison of the backward masked thresholds in the children who
persisted (n = 12) were signiﬁcantly higher than those who recovered (n = 18). The backward-masked thresholds of the children
who persisted also had a wider range of thresholds than those in the group that recovered. That is, on average CWS had poorer
masked thresholds but there was still some overlap in the thresholds for the two groups. Howell et al. (2006) concluded from these
results that elevated backward masked thresholds in the group of persistent stutterers “is suﬃcient but not necessary for the disorder
to persist.”

Data from the auditory perceptual studies reviewed above reveal a complex interaction of factors that often lead to ambiguous
results. Most of the older studies relied on poorly developed norms and poorly matched control participants (Hannley & Dorman,
1982). Data from children are noisy because of potential diﬀerences in the time course of development of auditory perceptual abilities
and the issue of whether stuttering persists in adulthood or recovers as they age. Children are also more likely to be inattentive in an
auditory task than adults, which can also contribute to the overlap in results from PWS and PNS. Nonetheless, a promising auditory
task, to date, to study auditory perception in PWS appears to be backward masking.

Backward masking is believed to be a central phenomenon. One explanation for the eﬀect is that a later presented high-level
stimulus (masking noise) has a shorter latency than the low-level signal which results in the high-level sound catching up and

12

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

dominating perception. A greater amount of masking in PWS could be evidence of a problem with the temporal processing or
processing of non-simultaneous sounds. Instead of hearing them separately their representation is smeared. A second explanation is
that the masker “interrupts” the memory of the signal or erases it. For instance, children’s thresholds can remain elevated in
backward masking even after the delay between the signal and the masker is increased, which would be consistent with an inter-
ference with memory. These two explanations will be examined in this study to learn more about the threshold elevation caused by
backward masking in PWS.

1.1. Purposes of the study

The present study was an exploratory one designed to assess backward masking for tones in the presence of a noise masker, as in
Howell et al.’s studies, and to assess backward masking for speech in PWS using a carefully matched control group. We hypothesized
that a backward masking of speech task could be a sensitive measure for separating adults who stutter from ones who do not. The
backward making of speech task requires a participant to recognize a vowel-consonant (VC) syllable whereas the backward masking of
tones is a detection task. We believe that the backward masking of speech task may be a sensitive measure because stuttering is a
disorder involving speech. There are brain diﬀerences observed in regions associated with speech recognition in PWS, such as the
arcuate fasciculus (Cieslak, Ingham, Ingham, & Grafton, 2015); bilateral inferior frontal gyrus and left Heschl's gyrus have been
shown to be more activated in fMRI during speech perception in PWS than in PNS (Halag-Milo et al., 2016). Attributing these
diﬀerences to behavior is somewhat speculative, but the preponderance of neuroanatomical and neurophysiological diﬀerences
between PWS and PNS is in the regions of the brain associated with speech-language circuits (Cieslak et al., 2015).

1.2. Research questions and hypotheses

The aims for the present study were to see if there were any diﬀerences in auditory temporal abilities in PWS from typically ﬂuent

persons measured using backward masking tasks for speech and for tones.

First, we hypothesized as in the Howell and Williams (2004) and Howell et al. (2000), 2006) studies, that adult PWS will have
higher backward masked thresholds than PNS. Howell et al. (2006) reported elevated backward masking thresholds distinguished
between children who persist in stuttering and those who do not as they reached adulthood. Because all of our participants are adults
who have persisted, we predict that their backward-masked tonal thresholds will be elevated compared to those of PNS.

Second, we hypothesized that backward masking for speech will produce robust diﬀerences between PWS and PNS groups be-

cause stuttering is deﬁned by diﬀerences in speech behavior.

There is another reason why a backward masking of speech task may be helpful for separating PWS from PNS. Our behavioral data
are possibly more stable than those from children (Howell et al., 2006), because adults are not as prone to lapses in attention. A
backward masking of speech measure also controls for attention better than a tonal masking task with thresholds obtained using a
forced-choice procedure. In forced-choice detection procedures, participant votes following each presentation of multiple observation
intervals (often 3), only one of which contains the signal. A vote for one of the intervals can occur even if a participant did not attend
to the task. The non-sensory variable of inattention cannot be monitored easily in this kind of situation. By contrast, for a speech task,
a partially correct response (which includes, for instance, a correctly identiﬁed vowel in a target VC syllable) demonstrates some level
of attention directed to the target stimulus.

We also examined the time course of backward masking by assessing the amount of masking for two diﬀerent times between
signal oﬀset and the onset of the masker. Hill, Glasberg, Moore, and Moore (2004) suggested that evaluating backward masking with
diﬀerent delays between the signal and the masker provides a means to separate cognitive aspects of the auditory task from an
estimate of temporal processing ability. If task eﬃciency is poor or the masker overwrites the memory for the signal rather than
interfering with the neural coding of the physical aspects of the stimulus, increasing the delay of the onset of the masker from
immediate to 300 ms should not show complete recovery in the detection threshold for the tone or the recognition of speech. A 300-
ms delay in typical cases will lead to thresholds equivalent to those in the quiet (unmasked) condition (Kallman & Massaro, 1979).

2. Method

2.1. Participants

The participants for the study were 8 persons who stutter (PWS) and 8 controls (PNS) with 6 males and 2 females in each group.
The groups were in the age range of 18–35 years. The mean age for the PWS group was 28.4 years (SD. 4.8), and for the PNS was 27.6
years (SD. 4.6). All participants in the PWS group were recruited through the local National Stuttering Association chapter and/or
had attended individual therapy for stuttering at Julia Davis Clinic at the Department of Speech Language and Hearing Sciences,
University of Minnesota. These participants also reported a history of diagnosed developmental stuttering that persisted into
adulthood. All the participants in the PWS received scores between 16 and 23 (a severity ranging from “very mild” and “mild”) on the
Stuttering Severity Instrument for Children and Adults – Fourth edition (SSI-4; Riley, 2009); See Table 1 for details. Participants in the
PNS group were recruited through ﬂiers posted around the university campus. The protocol was approved by the Institutional Review
Board. All participants were native English speakers. The participants completed an initial case-history screening form to rule out
Attention Deﬁcit Disorder(ADD), motor, and neurological disorders. The PWS group reported stuttering as their only speech-related
diagnosis and the participants in this group did not have any history of language delay, motor or neurological disorder. The

13

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

Table 1
Demographic, and subtest results from PWS and matched PNS for CTOPP-2, TONI, Digit Recall (WISC-4) and Sentence Recall (CELF-4).

Group

Age/Gender

SSI scores

Phonological
Awareness

Phonological
Memory

Alternate Phonological
Awareness

TONI

Digit Forward

Digit Backward

Sentence recall

PWS1
PNS1
PWS2
PNS2
PWS3
PNS3
PWS4
PNS4
PWS5
PNS5
PWS6
PNS6
PWS7
PNS7
PWS8
PNS8

30/M
28/M
27/M
27/M
27/F
28/F
19/M
19/M
26/M
24/M
35/M
35/M
31/M
31/M
31/F
29/F

20
–

18
–

23
–

21
–

18
–

16
–

20
–

22
–

116
118
120
125
114
127
131
116
118
118
116
127
120
122
122
122

107
110
107
116
110
116
128
110
119
116
107
125
113
113
107
110

137
122
128
130
119
130
128
137
116
131
128
134
116
122
131
134

113
112
119
119
113
115
118
110
116
115
116
113
114
116
114
113

13
12
12
14
14
13
16
12
12
12
12
13
14
13
15
10

6
7
6
13
7
9
11
6
9
9
8
10
9
8
7
7

85
84
86
94
90
92
95
90
85
92
94
96
90
86
91
92

participants were screened for their audiological thresholds. All participants, who were included in the study passed hearing
screening at 20 dB HL for the frequencies 500 Hz, 1000 Hz, 2000 Hz and 4000 Hz.

2.2. Screening tests

Participants in both groups were administered several tests prior to participating in the experimental protocol. The phonological
awareness, phonological memory, and alternate phonological awareness subtests of the Comprehensive Test of Phonological
Processing-2 (CTOPP-2; Wagner, Torgesen, Rashotte, & Pearson, 2013) were administered to all participants. This was done to rule
out the presence of concomitant phonological processing deﬁcits. The groups were compared in non- verbal intelligence using the
Test of Nonverbal Intelligence- 4 (TONI -4) (Brown, Sherbenou, & Johnsen, 2010). Furthermore, Sentence Recall Test from Clinical
Evaluation of Language Fundamentals- 4 (CELF-4; Semel, Wiig, & Secord, 2006), and forward and backward digit span subtests of the
Wechsler Intelligence Scale for Children- IV (Wechsler, 1974) were administered to rule out any possible short-term and working
memory impairments. The results are summarized in Table 1.
The Mann -Whitney U test was performed using IBM SPSS

20 to examine group diﬀerences for the above-mentioned subtest
scores and results revealed no signiﬁcant group diﬀerences (p > 0.05). The mean and SD of the standardized tests, and the p- values
have been summarized in Table 2.

®

2.3. Stimuli

2.3.1. Tonal detection task

Stimuli were generated using a custom designed 16-bit digital- to- analog converter with a sampling rate of 22 kHz. The anti-
aliasing ﬁlter was set at 10 kHz. The signal was a 1 kHz tone with a duration of 20 ms. This tone was gated (turned on and oﬀ) using a
Blackman ramp with 10-ms rise and 10-ms fall times. The noise stimulus for the tonal backward masking condition was a digitally
generated 10 kHz wide band noise that was band pass ﬁltered (Krohn- Hite, Model #3202) between 600–1400 Hz. Noise outside the
ﬁlter passband was attenuated at 24 dB/octave. The noise was rectangular gated (it had an abrupt onset and oﬀset) and its duration
was 300 ms. The noise level was 70 dB SPL in the masking, detection tasks.

2.3.2. Syllable recognition task

Speech stimuli that were used for this task were recorded from a single male talker. The stimuli were vowel-consonant (VC)

Table 2
Mean, SD and P Values (Mann-Whitney U) of the subtest Screening tests for PWS and PNS group.

Tests

Phonological Awareness
Phonological memory
Alternate Phonological Awareness
TONI
Digit Forward
Digit Backward
Sentence Recall

PNS

121.7(4.2)
114.5(5.1)
130(5.4)
114.1(2.7)
12.3(1.18)
8.69(2.19)
90.75(3.99)

14

PWS

119.6(5.2)
112.2(7.6)
125.3(7.5)
115.3(2.2)
13.5(1.51)
7.8(1.72)
89.5(3.89)

p - value

0.279
0.234
0.161
0.328
0.234
0.328
0.505

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

syllables (45 syllables), with 15 diﬀerent consonants in three vowel contexts (/a/, /i/ and /u/) modeled after the Nonsense Syllable
Test (Edgerton & Danhauer, 1979). These monosyllables were all legal combinations in English. The stimuli were digitized using
Broadway 2.5 software (Data Translation Co.) with a sample rate of 22 kHz. These digitized syllables were normalized for equal root-
mean-square amplitude.

Since backward masking normally has a short time course of recovery, the VC stimuli were edited to control for the time that they
ended. Stop consonants in the VC syllables were truncated 10 ms after end of the consonant burst. Fricatives and nasals were
terminated when the level of the consonants was within 6 dB of the noise ﬂoor. All 45 tokens in the speech task were presented at
80 dB SPL. The noise stimulus for the speech task was a broadband noise (10 kHz wide) presented at 93 dB SPL. Stimulus levels were
calibrated using a sound-level meter (Brüel & Kjær, model 2260) with an artiﬁcial ear (Brüel & Kjær, model 4153) coupled with an
adapter plate for circumaural headphones (Brüel & Kjær, model DB-0843).

2.4. Procedure

The participants were seated in a double-walled sound treated room, and were instructed separately for each task. The stimuli and
masker were presented monoaurally through Sennheiser HD 250 earphones to the right ear for both tonal detection and speech
syllable recognition tasks.

2.4.1. For tonal detection task

The tonal detection task estimated thresholds for tones in quiet and in the presence of a noise masker. The masked conditions
included a 0 ms delay and a 300 ms delay. The delay refers to the time between the termination of the tone and the onset of the
masker. In other words, the masker and the tone did not overlap in time for either condition.

The thresholds were estimated using a three-alternative, forced-choice (3AFC) adaptive procedure (Levitt, 1971; Schlauch & Rose,
1990). During a single trial in the task, the participant was presented with a sequence of three observation intervals, which were
signaled by lights on a custom designed response box. Each observation interval was separated by 500 ms. The participant was
instructed to push a touch-sensitive button that denoted the interval in which the signal occurred. Depressing a button began a new
trial following a short delay. For the threshold condition in quiet, the tone was presented randomly with equal probability in one of
the intervals and the participant was instructed to listen for that interval and push the corresponding touch sensitive button. For the
backward masking conditions, one of the intervals contained the signal in addition to the noise masker, and the other two intervals
contained the noise masker only. The participant’s task was to identify which interval was diﬀerent from the other two, and to
indicate it by pushing the corresponding button. For the initial blocks, the adaptive procedure was begun at an expected supra-
threshold level which was 50 dB SPL or 70 dB SPL for the quiet/300 ms condition and the 0 ms masking condition, respectively.
Subsequent blocks for the same condition were begun 10 dB above the previously measured threshold. Following each trial in all
detection tasks, the participant was given correct answer feedback regarding the signal interval. During this procedure, when the
participant gave an incorrect response the signal level increased. After three consecutive correct responses, the signal level was
reduced. This rule targets 79.4% correct detections. The stimulus changed with a step size of 4 dB initially, but after the ﬁrst two
reversals in stimulus level direction the step size reduced to 2 dB. Thresholds were based on the mean of the remaining number of
stimulus level reversals in a track following the ﬁrst two reversals in an 80-trial block. This rule lead to thresholds being based on
roughly 14 reversals per threshold estimate. Each participant was tested for a block for the quiet condition, initially as practice, to
familiarize them with the task. This was followed by two blocks of 80-trials, that were measured for each condition. The participant’s
threshold in quiet was established ﬁrst and followed by the backward masking conditions, which were randomized. No learning or
fatigue eﬀects were observed.

2.4.2. For speech syllable recognition task

The speech syllable recognition task followed the tonal detection task. The speech stimuli were presented with or without the
masking noise. The masked condition was either with the masking noise with 0 ms delay or 300 ms delay. Each block contained 45 VC
monosyllables. The participants controlled the rate of presentation of the stimuli by pushing a single button on the control box to start
the presentation of the next nonsense syllable, and they were asked to repeat aloud what they heard. Each of these three conditions
(in quiet, 0 ms delay and 300 ms delay) was presented three times, thus making it a total of nine blocks. The presentation order of
these nine blocks was randomized.

The examiner was present in the booth with the participants during this task. The oral response from each trial of the speech task
was transcribed by the examiner who also monitored visually the talker's lips (Han, Schlauch, & Rao, 2014). Additionally, the stimuli
and responses were recorded digitally using a Marantz digital recorder and used for oﬄine computing of reliability and response
latency. For the participants who stutter, none of the trials included a moment of stutter (block, repetition, prolongation, tense
pause); all the responses were produced ﬂuently. Also, all the trials elicited a response with minimal delay.

2.5. Reliability

The responses that were recorded from the backward masking of speech conditions were subjected to inter-rater reliability
assessment. 20% of the sample from both the groups, i.e., two subjects from each group, was analyzed by a trained research assistant.
Results from the reliability assessment are summarized in the next section.

15

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

Fig. 1. Thresholds for Backward masking for Tones in the PWS and PNS groups for the three listening conditions. The y axis represents the hearing
thresholds of the participants in dB SPL. The x axis represents the three listening conditions: in quiet, with the masker onset 0 ms after the oﬀset of
the tone, and with masker onset 300 ms after the oﬀset of the tone. Each threshold on the graph represents the mean threshold from two blocks for
each participant for each listening condition. The squares represent the thresholds from participants who do not stutter, whereas the circles
represent thresholds of the participants who stutter.

3. Results

3.1. Results for tonal detection task

Fig. 1 represents individual thresholds from the participant groups for the tonal detection conditions. Tonal detection thresholds
for both groups obtained in quiet for the short duration tone were within normal limits. Thresholds for a 20 ms duration tone in quiet
were expected to be about 9 to 12 dB higher than the ones obtained with a 500 ms or longer tone due to temporal integration (Moore,
2012). This consideration of temporal integration, the improvement in thresholds as duration is increased, predicts that the
thresholds for a long duration tone in quiet would be roughly 10 dB HL or lower, which represents excellent hearing sensitivity. This
consideration of temporal integration and conversion from SPL to HL is intended to provide context relative to normal hearing.
Masked thresholds in the 0 ms delay condition were elevated signiﬁcantly compared to the ones in quiet and in the 300 ms delay
condition. Group mean thresholds for PWS in the 0 ms delay condition were 7.04 dB higher than those for the PNS group.

The pattern observed in Fig. 1 is supported by the results from a repeated measures ANOVA to identify possible eﬀects of the two
groups and the listening conditions. The results revealed signiﬁcant eﬀect of Condition (F (2, 28) = 208.58, p < 0.001, ηp
2 = 0.94)
between quiet, 0 ms and 300 ms, and signiﬁcant Condition × Group interaction (F (2, 28) = 4.66, p < 0.018, ηp
2 = 0.25). To
identify the source of interaction, further post hoc analyses were done. Three independent t-tests comparing groups in quiet and 0 and
300 ms backward masking were performed. No signiﬁcant diﬀerence was noted between the groups for the quiet condition, t
(14) = 0.529, p > 0.05, d = 0.27); backward masking condition with the 0 ms delay, t(14) = −1.90, p = 0.07, d=0.95; backward
masking condition with 300 ms delay, t(14) = 0.182, p > 0.05, d=0.09. Although the diﬀerences in mean were not signiﬁcant, the
0 ms backward masking condition had a suﬃciently smaller p -value. To understand these eﬀects, we did an additional analysis by
estimating the eﬀect of masking for the 0 ms condition. We created a new variable by subtracting the thresholds at quiet from the
thresholds for backward masking at 0 ms condition, for both the groups. An independent t-test was performed and results revealed
signiﬁcant diﬀerence between the groups, t(14)= −2.24, p=0.04, d = 1.12. The signiﬁcant diﬀerence in amount of masking for the
0 ms condition is a likely contributor to the interaction in the ANOVA model.

3.1.1. Results for speech syllable recognition task

Fig. 2 illustrates the individual scores for the speech syllable recognition task. A repeated measures ANOVA was performed to
examine the results from backward masking of speech conditions. The data was transformed using the arcsine transformation
(Studebaker, 1985). Results revealed a signiﬁcant eﬀect for Condition (F (2, 28) = 128.6, p < 0.001, ηp
2 = 0.90); Condition ×
Group interaction was not signiﬁcant (F (2, 28) = 0.69, p = 0.5, ηp
2 = 0.04). The between-subject Group eﬀect was signiﬁcant (p
< 0.001, ηp

2 = 0.86).

3.2. Reliability measures

To evaluate inter-rater reliability for the speech recognition task, twenty percent of the sample from both groups (i.e., two subjects
from each group) was analyzed oﬄine by a research assistant, a trained listener who is familiar with International Phonetic Alphabet

16

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

Fig. 2. Syllables Percentage Correct for Backward masking for Speech in the PWS and PNS groups for the three listening conditions. The y- axis
represents the performance for the speech recognition task in percentage correct syllables and the x axis represents the listening conditions. For the
speech tasks, the stimulus was syllables, in quiet and in the presence of backward masking, and each listening condition was based on performance
for three blocks. Each point in the ﬁgure represents the mean percentage correct syllables for the three blocks for each condition. The circles
represent the scores from the PWS whereas the squares represent scores from PNS.

(IPA) transcription. The original transcription was completed by the ﬁrst author during data collection; the research assistant used a
recording of the sessions. Two participants from the control group and 2 of their matched controls from the PWS group were
analyzed. Inter-rater reliability was estimated using the Cohen’s Kappa, and results revealed Cohen’s Kappa (κ) to be 0.84 which
indicated excellent agreement between the raters.

3.3. Additional analysis

3.3.1. Error analysis

To get a detailed idea about the error characteristics, the errors were analyzed by plotting them in a consonant confusion matrix
(Wang, Reed, & Bilger, 1978). There were 15 diﬀerent consonants that were presented in a block of trials and each consonant was
presented in each of three vowel contexts (/a/, /i/, and /u/) for a total of 45 trials within a block. The performance for each condition
was based on three blocks and given that there were eight participants in each group, each consonant was presented 72 times for each
condition and group. Overall, the pattern of errors is similar for both the groups but the PWS group had a higher error rate than the
control group. Among the consonants, bilabial unvoiced stop (/p/), unvoiced labiodental (/f/) and lingua-dental fricative (/ɵ/) were
the most common types of error seen in both groups, together accounting for about 41.7% of the total errors even though these
consonants only represent 20% of the sounds. Also, there was no speciﬁc consonant that the participants always got wrong, in either
group (the participants could produce the consonants accurately in at least one of the tokens out of the three vowel contexts). We also
looked at the accuracy of production for high frequency consonants /s/ and /ʃ/ and we found that both groups had nearly perfect
identiﬁcation for these two consonants in the quiet and 300 ms delay condition. Both groups had perfect scores for the 144 pre-
sentations of /ʃ/ each group missed one of the 144 /s/ trials. This is evidence that high-frequency sounds were audible because /s/
and /ʃ/ are phonemes with the highest spectral mean frequency (Jongman, Wayland, & Wong, 2000). Furthermore, there was a
higher error rate when consonants were paired with vowel /i/ than with the other vowels. For PWS group 47.0% of the total errors
(336 total) occurred on the syllables that had /i/ in the VC syllable combination. For the PNS group, 48.7% of the errors (156)
occurred with the /i/ vowel combination. To examine whether this outcome is signiﬁcant, a simulation was conducted to learn how
likely the observed distribution of errors in the /i/ vowel context could occur by chance. The simulation is based on a program
written in R. Ten million samples of the error count for each group (336 or 156) were placed into 3 bins, representing the 3 vowel
contexts, with equal probability. For each of the 156 (or 336) errors, a random number was drawn which produced a 1/3 chance of
the error being placed in one of the 3 bins. The expected outcome is 33% of the errors will fall into each bin, but, due to chance, there
will be some outliers. The simulation documented these outliers and revealed that error rates of 46% or higher for the PWS group was
only 34 cases out of 10 million (p < 0.0000001). For the PNS group, the error rate of 48% or higher was 2801 out of 10 million
(p < 0.0003). This simulation is evidence that the percentage of errors for consonants paired with the vowel /i/ did not occur by
chance.

4. Discussion

We measured backward masking ability in PWS and PNS. The results from the present study revealed that the PWS were

17

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

signiﬁcantly poorer than the PNS group in masked conditions for tones and speech in the presence of noise maskers.

Thresholds for PWS were signiﬁcantly higher in PWS than in PNS in the 0 ms condition. The 7.04 dB average threshold diﬀerence
for the adults in our study agrees with Howell et al. (2006) ﬁnding of about a 10 dB diﬀerence in backward masked thresholds with
higher thresholds in children who persist in stuttering compared to those who recovered. Howell et al., reported that this threshold
diﬀerence diﬀerentiated speakers who persist in stuttering from those who do not. Our study contains fewer participants than those in
Howell et al. (30 vs 16), but the present study found signiﬁcant overlap in the masked thresholds for the two groups with some
masked thresholds for the PNS that were elevated as much as those in the PWS group. Because the present study used adult parti-
cipants, development was not an issue. That stated, the overlap in our ﬁndings is similar to that of Bishop, Carlyon, Deeks, and
Bishop, (1999) who found elevated backward masking thresholds were neither necessary or suﬃcient for distinguishing between
children with Speciﬁc Language Impairment and typical controls.

Speech recognition was poorer overall in the PWS group, and there was no overlap in any speech recognition condition (quiet,
0 ms, 300 ms) across the two groups. The mean diﬀerences between the two groups were signiﬁcant for all listening conditions. The
PWS group showed poorer recognition performance in the presence of the backward masker with a 0 ms delay than the PNS group;
however, this may be a result of the PWS group’s poorer performance in the quiet (no masker) condition.

For speech and tones, both the groups exhibited a signiﬁcant amount of backward masking at the 0 ms condition and both showed
recovery to the baseline, quiet condition in the masker condition with a 300 ms delay. In auditory experiments, the duration of
auditory sensory memory and storage have been examined and the recovery for backward recognition masking is found to be roughly
250 ms (Kallman & Massaro, 1979). The data from the present study suggest that the masker had no residual eﬀect on either group, as
it would in the 300-ms delay condition if the masker had overwritten memory. In the tonal masking experiment, the quiet and the
300 ms condition yielded nearly identical thresholds for both groups, which is evidence that non-sensory factors that are task related
did not play a role (Hill et al., 2004).

An unexpected ﬁnding from this study was that the two groups had little or no overlap in the speech syllable recognition scores in
quiet. Two possible explanations for these ﬁndings are: (a) people who stutter might have indistinct phonemic categories, and /or (b)
there may have been masking of the consonants by the vowels in the VC syllable. These possible explanations are discussed in detail
in the following sections.

4.1. Indistinct phonemic boundaries in PWS

The poorer speech scores in PWS might be a result of them having less distinct phonemic categories than PNS. There is evidence
from behavioral and physiological studies to support this idea, particularly in situations where the speech is not presented in a lexical
context. The absence of a lexical context or of other top down semantic cues make the task of speech-sound identiﬁcation rely nearly
entirely on acoustic diﬀerences and, as such, make tasks based on nonsense syllables more likely to reveal a perceptual deﬁcit (Neef
et al., 2012).

The present study is not the only one to demonstrate poorer recognition of nonsense syllables for a group of PWS than for a control
group of PNS. Sussman and MacNeilage (1975), tested 20 PWS and matched controls to assess the right ear advantage (REA) in a
dichotic CV task. They did not ﬁnd a diﬀerence in the REA between groups, but we noticed that recognition performance appeared
much poorer for the PWS than for PNS (38% vs 46%). A statistical analysis of their data conﬁrmed that the diﬀerence is signiﬁcant
(t = 55.51, p < 0.0001). Poorer performance for PWS for repeating dichotically presented nonsense syllables is not necessarily
related to binaural processing because the present study found poorer performance in a monaural task.

Sussman and MacNeilage (1975) and the present study required vocal responses as part of the experimental task so the observed
deﬁcit in PWS could be related to the speech production requirements. Speech production may not be required to reveal this deﬁcit,
however, because a study by Lu et al. (2016) found perceptual diﬀerences exist between PWS and PNS even when production is not
required. Lu et al. (2016) conducted a brain imaging analysis during speech production and perception tasks, and found anomalous
neural activity for both tasks in motor speech areas and speech perception areas in PWS that correlated with speech perception
performance (reaction times). Their results further revealed that this anomalous neural activity was present in the production and
perception areas of the brain at a resting state when no task was involved.

The poor performance in a speech task for PWS may be a result of having a faulty feed-forward system due to less than optimal
sensory representations (Civier, Tasko, & Guenther, 2010). Based on this idea, Neef et al. (2012) postulated that PWS perceive
categories of sounds less distinctly. To test their hypothesis, Neef et al. (2012) compared 25 individuals who stutter and matched
controls in their ability to identify voicing contrasts of phonemes on a two-syllable, VC continuum (/dǝ/-/tǝ/ and /bǝ/-/pǝ/). This
task did not require speech production; it required a button press for their responses. The authors plotted the probabilities of voiceless
perception (through phoneme identiﬁcation task) against the voice onset time (VOT) for /dǝ/-/tǝ/ and /bǝ/-/pǝ/ in a psychometric
function curve for PWS and PNS. They found that, the section of the VOT continuum where a reliable identiﬁcation of the phoneme
was not possible was more gradual and occurred over longer range of VOT for PWS group. In other words, the psychometric function
curve for phoneme identiﬁcation was shallower in the individuals who stutter. Also, it showed a greater variability compared to that
of the control group. This implies that persons who stutter do not have a distinct category boundary for voicing contrasts compared to
controls. The authors concluded that, the ability to discriminate phoneme boundaries is poorer and less stable in individuals who
stutter (Neef et al., 2012).

Evidence of diminished sensitivity to speech sound diﬀerences in PWS has also been observed in a physiological study of event
related potentials (ERP). Jansson-Verkasalo et al. (2014) evaluated 10 children who stutter and 12 typically ﬂuent children for their
ability to pre-attentively discriminate speech sound contrasts in CV syllables using an auditory mismatch negativity (MMN)

18

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

paradigm. Mismatch negativity is an electrophysiological pre-attentive cortical response to a target stimulus change. The amplitude
of the MMN increases when a stimulus change is processed (Naatanen, Paavilainen, Rinne, & Alho, 2007). Results from this ex-
periment revealed that CWS had signiﬁcantly smaller MMN amplitudes than the typically ﬂuent children for speech sound contrasts
known to be important for speech perception, such as changes in frequency (F0), syllabic intensity, vowel duration, consonant
identity and vowel identity. Only the vowel duration contrast was signiﬁcant for the CWS group whereas all the contrasts were
signiﬁcant in the controls. The smaller MMN for speech sound diﬀerences can be viewed as a physiological correlate to support the
notion of less accurate speech sound representation in PWS than in PNS.

Based on the above evidence it seems that PWS have poorer speech processing than their typically matched controls. This deﬁcit
might not be evident during many other behavioral measures of speech perception because the diﬀerences are often subtle and not
always observed on standardized tests (Kaganovich, Wray, & Weber-Fox, 2010). This applies to speech assessment in the audiology
clinic where speech scores are based on only 25 or 50 monosyllabic words. A score of 90% or higher would be judged as within
normal limits in most clinics (Tillman & Carhart, 1966) and all the PWS in the present study scored higher than 90% on the speech
condition in quiet. Further, it is possible that the presence of lexical cues in the monosyllabic words used in standardized audiological
testing would not reveal diﬀerences seen in the present study with nonsense syllables as the stimuli.

4.2. Vowels acting as maskers in VC syllables

Another possible explanation for the poorer scores in speech tasks might be related to forward masking of the speech by itself. The
stimuli were presented at a high level to insure audibility but this higher-than-normal, conversational-speech level may have resulted
in some masking of unvoiced consonants by the preceding vowels in the VC syllable. Analysis of the vowels, in both the groups
revealed that the VC combinations that started with the vowel /i/ had the highest percentage of errors. The formant characteristics of
vowel /i/ has a low F1 and high F2 and F3. Formants are points of resonance in the vocal tract that are characterized by higher energy
levels in the spectrum. The spectral peaks for the vowel /i/ for an average adult male speaker are 342 Hz for the ﬁrst formant,
2322 Hz for the second and 3000 Hz for the third formant (Hillenbrand, Getty, Clark, & Wheeler, 1995). The stimulus we used was
natural speech by an adult male speaker. This energy concentration of vowel energy in the high frequencies may have masked
important acoustic cues for recognition of consonant sounds.

Gutnick (1982) reported diﬀerences in identiﬁcation of consonants paired with diﬀerent vowels in a group of normal-hearing
listeners and listeners with a high-frequency sensorineural hearing loss. In the experiment, the listeners identiﬁed 17 consonants in a
CV- syllable with /a/ or /i/ as the vowel. The results revealed that consonant recognition at high presentation levels in the context of
vowel /i/ yielded more errors compared to vowel /a/ (Gutnick, 1982). Given these results, it is possible that the vowel /i/ presented
at a high intensity in this test, might have masked the preceding consonant information which made low intensity consonants diﬃcult
to recognize for both groups. The mechanism for a vowel masking a consonant would be backward masking for CVs and forward
masking for VCs. In the present experiment, diﬀerences in temporal processing (forward masking) between the groups could be a
possible explanation for a greater eﬀect for the group of PWS than for the control group.

4.3. Study limitations

This exploratory study yielded interesting results but it has some limitations.
First, the speech stimuli were not presented at the level of normal conversational speech but rather at a level 10 dB higher than
normal conversational speech. This higher level, as noted in the Discussion, may have resulted in forward masking of the consonant in
the VC syllable by its preceding vowel. That leaves uncertainty regarding the mechanism for the poorer speech understanding for the
PWS group. Thus, this study cannot diﬀerentiate between temporal masking and poorly deﬁned phoneme boundaries as possible
mechanisms for the results. Second, the possibility exists that the PWS group had elevated high-frequency thresholds due to hearing
loss which could account for the poorer speech understanding in the PWS group. Hearing screening was only measured up to 4.0 kHz.
Third, only a single ear (right ear) was tested in this study. There has been a long-time interest in ear diﬀerences in PWS, and by
testing on one ear this study is unable to address this topic. Fourth, all the participants in our study were either mild or very mild
stutterers. Ideally, the participant sample would have included a wider range of severity. Since most of the participants were adult
stutterers, who have been in speech therapy of several years, the severity of stuttering that we found was not uncommon.

5. Conclusion and future direction

This is the ﬁrst study to report backward masking for speech. Results reveal only a small reduction in recognition performance for
VC syllables when a high-level backward masker occurred 0 ms after the oﬀset of the consonant in the VC syllable. Performance in the
presence of the masker with 0 ms delay was poorer for PWS than for PNS, but the pattern of errors was similar. Signiﬁcantly more
errors were observed in the context of the vowel /i/ than for /a/ or /u/.

Even though our PWS group comprised of stutterers in the very mild to mild category, they still demonstrated signiﬁcantly poorer
performance in backward masking for speech. Given that even the mild stutterers exhibited a signiﬁcant eﬀect, it is only logical to
assume that persons with a greater stuttering severity would also show similar pattern of deﬁcit in speech recognition in presence of
backward masking.

The poor backward masking for speech observed in the PWS group may not be attributed solely to the presence of the backward
masker. The PWS group produced signiﬁcantly poorer performance for VC recognition than the PNS group in quiet as well as in the

19

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

presence of a backward masker. The masker possibly increased uncertainty about the phoneme category for both groups but because
the PWS group was starting from a lower performance level, the masked condition produced more errors for the PWS group than the
PNS group. One reason that our task was likely able to reveal this diﬀerence is because nonsense syllables do not provide a semantic
context. Nonetheless the eﬀect is small.

Considerable overlap for the threshold was observed in the backward masking for tonal detection task in PWS and PNS groups,
but amount of masking was higher in the PWS group. The ﬁnding that thresholds for three of the PNS participants were higher than
the median for the PWS group suggests that elevated backward masked thresholds are neither necessary nor suﬃcient for distin-
guishing between PNS and PWS. Future studies can be conducted with larger sample sizes, a wider range of masker and speech levels,
and a greater variability in subject pool to ascertain the eﬀects of backward masking of speech in PWS.

Acknowledgements

The authors would like to acknowledge the valuable contributions of Dr. Edward Carney for his help with designing the study and

statistical analysis of the data.

References

Asal, S., & Abdou, R. M. (2014). The study of central auditory processing in stuttering children. The Egyptian Journal of Otolaryngology, 30, 357–361.
Bishop, D. V. M., Carlyon, R. P., Deeks, J. M., & Bishop, S. J. (1999). Auditory temporal processing impairment: Neither necessary nor suﬃcient for causing language

impairment in children. Journal of Speech Language and Hearing Research, 42(6), 1295–1310.

Braun, A. R., Varga, M., Stager, S., Schulz, G., Selbie, S., Maisog, J. M., et al. (1997). Altered patterns of cerebral activity during speech and language production in

developmental stuttering. An H2 (15) O positron emission tomography study. Brain : A Journal of Neurology, 120(5), 761–784.

Brown, L., Sherbenou, R. J., & Johnsen, S. K. (2010). TONI-4, test of nonverbal intelligence. Pro-ed.
Chang, S. E., Erickson, K. I., Ambrose, N. G., Hasegawa-Johnson, M. A., & Ludlow, C. L. (2008). Brain anatomy diﬀerences in childhood stuttering. NeuroImage, 39(3),

1333–1344.

Chang, S. E., Angstadt, M., Chow, H. M., Etchell, A. C., Garnett, E. O., Choo, A. L., et al. (2018). Anomalous network architecture of the resting brain in children who

stutter. Journal of Fluency Disorders, 55, 46–67.

Cieslak, M., Ingham, R. J., Ingham, J. C., & Grafton, S. T. (2015). Anomalous white matter morphology in adults who stutter. Journal of Speech Language and Hearing

Research, 58(2), 268–277.

Civier, O., Tasko, S. M., & Guenther, F. H. (2010). Overreliance on auditory feedback may lead to sound/syllable repetitions: Simulations of stuttering and ﬂuency-

inducing conditions with a neural model of speech production. Journal of Fluency Disorders, 35(3), 246–279.

Edgerton, B. J., & Danhauer, J. L. (1979). Clinical implications of speech discrimination testing using nonsense stimuli. University Park Press.
Etchell, A. C., Civier, O., Ballard, K., & Sowman, P. F. (2018). A systematic literature review of neuroimaging research on developmental stuttering between 1995 and

2016. Journal of Fluency Disorders, 55, 6–45.

Goldiamond, I. (1965). Stuttering and ﬂuency as manipulatable operant response classes. Research in Behavior Modiﬁcation, 17(3), 851–868.
Gutnick, H. N. (1982). Consonant‐feature transmission as a function of presentation level in hearing‐impaired listeners. The Journal of the Acoustical Society of America,

72(4), 1124–1130.

Halag-Milo, T., Stoppelman, N., Kronfeld-Duenias, V., Civier, O., Amir, O., Ezrati-Vinacour, R., et al. (2016). Beyond production: Brain responses during speech

perception in adults who stutter. NeuroImage Clinical, 11, 328–338.

Hall, J. W., & Jerger, J. (1978). Central auditory function in stutterers. Journal of Speech Language and Hearing Research, 21(2), 324–337.
Han, H. J., Schlauch, R. S., & Rao, A. (2014). The eﬀect of visual cues on scoring of clinical word-recognition tests. American Journal of Audiology, 23(4), 385–393.
Hannley, M., & Dorman, M. F. (1982). Some observations on auditory function and stuttering. Journal of Fluency Disorders, 7(1), 93–108.
Harms, M. A., & Malone, J. Y. (1942). The relationship of hearing acuity to stammering. The Journal of Speech and Hearing Disorders, 4, 363–370.
Hill, P. R., Hartley, D. E., Glasberg, B. R., Moore, B. C., & Moore, D. R. (2004). Auditory processing eﬃciency and temporal resolution in children and adults. Journal of

Speech Language and Hearing Research, 47(5), 1022–1029.

Hillenbrand, J., Getty, L. A., Clark, M. J., & Wheeler, K. (1995). Acoustic characteristics of American English vowels. The Journal of the Acoustical Society of America,

97(5), 3099–3111.

Howell, P., & Williams, S. M. (2004). Development of auditory sensitivity in children who stutter and ﬂuent children. Ear and Hearing, 25(3), 265.
Howell, P., El-Yaniv, N., & Powell, D. J. (1987). Factors aﬀecting ﬂuency in stutterers when speaking under altered auditory feedback. Speech motor dynamics in stuttering.

Vienna: Springer361–369.

Howell, P., Rosen, S., Hannigan, G., & Rustin, L. (2000). Auditory backward-masking performance by children who stutter and its relation to dysﬂuency rate. Perceptual

and Motor Skills, 90(2), 355–363.

Howell, P., Davis, S., & Williams, S. M. (2006). Auditory abilities of speakers who persisted, or recovered, from stuttering. Journal of Fluency Disorders, 31(4), 257–270.
Jansson-Verkasalo, E., Eggers, K., Järvenpää, A., Suominen, K., Van den Bergh, B., De Nil, L., et al. (2014). Atypical central auditory speech-sound discrimination in

children who stutter as indexed by the mismatch negativity. Journal of Fluency Disorders, 41, 1–11.

Jongman, A., Wayland, R., & Wong, S. (2000). Acoustic characteristics of English fricatives. The Journal of the Acoustical Society of America, 108(3), 1252–1263.
Kaganovich, N., Wray, A. H., & Weber-Fox, C. (2010). Non-linguistic auditory processing and working memory update in pre-school children who stutter: An

electrophysiological study. Developmental Neuropsychology, 35(6), 712–736.

Kalinowski, J., Armson, J., Stuart, A., & Gracco, V. L. (1993). Eﬀects of alterations in auditory feedback and speech rate on stuttering frequency. Language and Speech,

36(1), 1–16.

Kallman, H. J., & Massaro, D. W. (1979). Similarity eﬀects in backward recognition masking. Journal of Experimental Psychology Human Perception and Performance,

5(1), 110.

Kell, C. A., Neumann, K., von Kriegstein, K., Posenenske, C., von Gudenberg, A. W., Euler, H., et al. (2009). How the brain repairs stuttering. Brain, 132(10),

2747–2760.

Kell, C. A., Neumann, K., Behrens, M., von Gudenberg, A. W., & Giraud, A. L. (2017). Speaking-related changes in cortical functional connectivity associated with

assisted and spontaneous recovery from developmental stuttering. Journal of Fluency Disorders.

Kramer, M. B., Green, D., & Guitar, B. (1987). A comparison of stutterers and nonstutterers on masking level diﬀerences and synthetic sentence identiﬁcation tasks.

Journal of Communication Disorders, 20(5), 379–390.

Kronfeld-Duenias, V., Civier, O., Amir, O., Ezrati-Vinacour, R., & Ben-Shachar, M. (2018). White matter pathways in persistent developmental stuttering: Lessons from

tractography. Journal of Fluency Disorders, 55, 68–83.

Levitt, H. C. C. H. (1971). Transformed up‐down methods in psychoacoustics. The Journal of the Acoustical Society of America, 49(2B), 467–477.
Liebetrau, R. M., & Daly, D. A. (1981). Auditory processing and perceptual abilities of “organic” and “functional” stutterers. Journal of Fluency Disorders, 6(3), 219–231.
Loucks, T., Kraft, S. J., Choo, A. L., Sharma, H., & Ambrose, N. G. (2011). Functional brain activation diﬀerences in stuttering identiﬁed with a rapid fMRI sequence.

Journal of Fluency Disorders, 36(4), 302–307.

20

S. Basu et al.

Journal of Fluency Disorders 57 (2018) 11–21

Lu, C., Long, Y., Zheng, L., Shi, G., Liu, L., Ding, G., et al. (2016). Relationship between speech production and perception in people who stutter. Frontiers in Human

Neuroscience, 10.

Maraist, J. A., & Hutton, C. (1957). Eﬀects of auditory masking upon the speech of stutterers. The Journal of Speech and Hearing Disorders, 22(3), 385–389.
Montgomery, B. M., & Fitch, J. L. (1988). The prevalence of stuttering in the hearing-impaired population. The Journal of Speech and Hearing Disorders, 53, 131–135.
Moore, B. C. (2012). An introduction to the psychology of hearing. Brill.
Naatanen, R., Paavilainen, P., Rinne, T., & Alho, K. (2007). The mismatch negativity(MMN) in basic research of central auditory processing: A review. Clinical

Neurophysiology : Oﬃcial Journal of the International Federation of Clinical Neurophysiology, 118(12), 2544–2590.

Neef, N. E., Sommer, M., Neef, A., Paulus, W., von Gudenberg, A. W., Jung, K., et al. (2012). Reduced speech perceptual acuity for stop consonants in individuals who

stutter. Journal of Speech Language and Hearing Research, 55(1), 276–289.

Olsen, W., Noﬀsinger, D., & Carhart, R. (1974). Masking level diﬀerences encountered in a clinical population. Audiology, 13, 428–443 1.
Riley, G. (2009). Stuttering severity instrument for children and adults fourth edition. Austin,TX: Pro-Ed.
Schlauch, R. S., & Rose, R. M. (1990). Two‐, three‐, and four‐interval forced‐choice staircase procedures: Estimator bias and eﬃciency. The Journal of the Acoustical

Society of America, 88(2), 732–740.

Semel, E. M., Wiig, E. H., & Secord, W. (2006). CELF 4: Clinical evaluation of language fundamentals. Pearson: Psychological Corporation.
Stuart, A., Kalinowski, J., & Rastatter, M. P. (1997). Eﬀect of monaural and binaural altered auditory feedback on stuttering frequency. The Journal of the Acoustical

Society of America, 101(6), 3806–3809.

Stuart, A., Kalinowski, J., Rastatter, M. P., Saltuklaroglu, T., & Dayalu, V. (2004). Investigations of the impact of altered auditory feedback in‐the‐ear devices on the

speech of people who stutter: initial ﬁtting and 4‐month follow‐up. International Journal of Language & Communication Disorders, 39(1), 93–113.

Studebaker, G. A. (1985). A rationalized arcsine transform. Journal of Speech Language and Hearing Research, 28(3), 455–462.
Sussman, H. M., & MacNeilage, P. F. (1975). Studies of hemispheric specialization for speech production. Brain and Language, 2, 131–151.
Tillman, T. W., & Carhart, R. (1966). An expanded test for speech discrimination utilizing CNC monosyllabic words: Northwestern University Auditory Test No. 6.

Northwestern Univ Evanston Il Auditory Research Lab.

Toscher, M. M., & Rupp, R. R. (1978). A study of the central auditory processes in stutterers using the Synthetic Sentence Identiﬁcation (SSI) Test battery. Journal of

Speech Language and Hearing Research, 21(4), 779–792.

Wagner, R. K., Torgesen, J. K., Rashotte, C. A., & Pearson, N. A. (2013). Comprehensive test of phonological processing: CTOPP-2.
Wang, M. D., Reed, C. M., & Bilger, R. C. (1978). A comparison of the eﬀects of ﬁltering and sensorineural hearing loss on patterns of consonant confusions. Journal of

Speech Language and Hearing Research, 21(1), 5–36.

Watkins, K. E., Smith, S. M., Davis, S., & Howell, P. (2008). Structural and functional abnormalities of the motor system in developmental stuttering. Brain, 131(1),

50–59.

Wechsler, D. (1974). Manual for the Wechsler intelligence scale for children, revised. Psychological Corporation.
Wingate, M. (1988). The structure of stuttering. New York: Springer-Verlag.
Yairi, E., & Seery, C. H. (2011). Stuttering: Foundations and clinical applications. Upper Saddle River, NJ: Pearson.

21
```